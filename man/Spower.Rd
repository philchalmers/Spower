% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Spower.R
\name{Spower}
\alias{Spower}
\alias{print.Spower}
\title{Simulation-based Power Analyses}
\usage{
Spower(
  ...,
  power = NA,
  sig.level = 0.05,
  beta_alpha = NULL,
  replications = 10000,
  prior = NULL,
  interval,
  integer,
  summarise = NULL,
  parallel = FALSE,
  cl = NULL,
  packages = NULL,
  ncores = parallelly::availableCores(omit = 1L),
  predCI = 0.95,
  predCI.tol = 0.01,
  verbose = TRUE,
  check.interval = TRUE,
  maxiter = 150,
  wait.time = NULL,
  control = list()
)

\method{print}{Spower}(x, ...)
}
\arguments{
\item{...}{the expression to use in the simulation that returns a single p-value.
Internally this expression is passed to either \code{\link[SimDesign]{SimSolve}} or
\code{\link[SimDesign]{runSimulation}} depending on which element (including
the \code{power} and \code{sig.level} arguments) is set to \code{NA}. For instance,
\code{Spower(p_t.test(n=50, d=.5))} will perform a post-hoc power evaluation since
\code{power = NA} by default, while \code{Spower(p_t.test(n=NA, d=.5), power = .80)}
will perform an a priori power analysis to solve the missing \code{n} argument.

For expected power computations the arguments to this expression can themselves
be specified as a function to reflect the prior uncertainty. For instance, if
\code{d_prior <- function() rnorm(1, mean=.5, sd=1/8)} then
\code{Spower(p_t.test(n=50, d=d_prior())} will compute the expected power
over the prior sampling distribution for \code{d}}

\item{power}{power level to use. If set to \code{NA} then the empirical power
will be estimated given the fixed \code{...} inputs
(e.g., for post-hoc power analysis)}

\item{sig.level}{alpha level to use. If set to \code{NA} then the empirical
alpha will be estimated given the fixed \code{conditions} input
(e.g., for criterion power analysis)}

\item{beta_alpha}{ratio to use in compromise analyses corresponding to
the Type II errors (beta) over the Type I error (alpha). Ratios greater
than 1 indicate that Type I errors are worse than Type II, while ratios
less than one the opposite. A ratio equal to 1 gives an equal trade-off
between Type I and Type II errors}

\item{replications}{number of replications to use when
\code{\link[SimDesign]{runSimulation}} is required}

\item{interval}{search interval to use when \code{\link[SimDesign]{SimSolve}} is required.
Note that for compromise analyses, where the \code{sig.level} is set to
\code{NA}, if not set explicitly then the interval will default to \code{c(0,1)}}

\item{integer}{a logical value indicating whether the search iterations
use integers or doubles.

If missing, automatically set to \code{FALSE} if \code{interval} contains
non-integer numbers or the range is less than 5, as well as
when \code{sig.level = NA}, though in general this should be set explicitly}

\item{summarise}{(optional) user-defined function for the \code{summarise}
step in \code{\link[SimDesign]{runSimulation}}, with the constraint that the first
element returned is should be the empirical detection rate estimate.
If not specified an internal function
will be used where the first element of the analysis output will be
passed to \code{\link[SimDesign]{EDR}} to compute the empirical detection rate}

\item{parallel}{for parallel computing for slower simulation experiments
(see \code{\link[SimDesign]{runSimulation}} for details).}

\item{cl}{see \code{\link[SimDesign]{runSimulation}}}

\item{packages}{see \code{\link[SimDesign]{runSimulation}}}

\item{ncores}{see \code{\link[SimDesign]{runSimulation}}}

\item{predCI}{predicting confidence interval level
(see \code{\link[SimDesign]{SimSolve}})}

\item{predCI.tol}{predicting confidence interval consistency tolerance
for stochastic root solver convergence (see \code{\link[SimDesign]{SimSolve}}).
Default converges when the power rate CI is consistently
within \code{.01/2} of the target power}

\item{verbose}{logical; should information be printed to the console?}

\item{check.interval}{logical; check the interval range validity
(see \code{\link[SimDesign]{SimSolve}})}

\item{maxiter}{maximum number of stochastic root-solving iterations}

\item{wait.time}{(optional) argument to indicate the time to wait
(specified in minutes). See \code{\link[SimDesign]{SimSolve}} for details}

\item{control}{a list of control parameters to pass to
\code{\link[SimDesign]{runSimulation}} or \code{\link[SimDesign]{SimSolve}}}

\item{x}{object of class \code{'Spower'}}
}
\value{
an invisible \code{tibble}/\code{data.frame}-type object of
class \code{'Spower'}
}
\description{
General purpose function that provides power-focused estimates for
a priori, post-hoc, compromise, sensitivity, and criterion power analysis.
Function provides a general wrapper to the
\code{SimDesign} package's \code{\link[SimDesign]{runSimulation}} and
\code{\link[SimDesign]{SimSolve}} functions. As such, parallel processing is
automatically supported, along with progress bars,
confidence/prediction intervals for the results estimates, safety checks,
and more.
}
\details{
Five types of power analysis flavours can be performed with \code{Spower},
which are triggered based on which supplied input is set to missing (\code{NA}):

\describe{
\item{A Priori}{Solve for a missing sample size component
(e.g., \code{n}) to achieve a specific target power rate}
\item{Post-hoc}{Estimate the power rate given a set of fixed conditions}
\item{Sensitivity}{Solve a missing effect size value as a function of
the other supplied constant components}
\item{Criterion}{Solve the error rate (argument \code{sig.level}) as a
function of the other supplied constant components}
\item{Compromise}{Solve a Type I/Type II error trade-off ratio as a
function of the other supplied constant components and the
target ratio \eqn{q = \beta/\alpha} (argument \code{beta_alpha})}
}

Post-hoc and compromise analyses utilize the
\code{\link[SimDesign]{runSimulation}} function, while the remaining three
approaches utilize the stochastic root solving methods in the function
\code{\link[SimDesign]{SimSolve}}.
See the example below for a demonstration with an independent samples t-test
analysis.
}
\examples{

############################
# Independent samples t-test
############################

# Internally defined p_t.test function
args(p_t.test)    # missing arguments required for Spower()
# help(p_t.test)  # additional information

# p_* functions generate data and return single p-value
p_t.test(n=50, d=.5)
p_t.test(n=50, d=.5)

# test that it works
Spower(p_t.test(n = 50, d = .5), replications=10)

# also behaves naturally with a pipe
p_t.test(n = 50, d = .5) |> Spower(replications=10)

\dontrun{

# Estimate power given fixed inputs (post-hoc power analysis)
out <- Spower(p_t.test(n = 50, d = .5))
summary(out)   # extra information

# increase precision
p_t.test(n = 50, d = .5) |> Spower(replications=30000)

# previous analysis not stored to object, but can be retrieved
out <- getLastSpower()
out   # as though it were stored from Spower()

# Same as above, but executed with multiple cores
p_t.test(n = 50, d = .5) |>
  Spower(replications=30000, parallel=TRUE, ncores=2)

# Solve N to get .80 power (a priori power analysis)
p_t.test(n = NA, d = .5) |>
  Spower(power=.8, interval=c(2,500)) -> out
summary(out)  # extra information
plot(out)
plot(out, type = 'history')

# total sample size required
ceiling(out$n) * 2

# same as above, but in parallel with 2 cores
out.par <- p_t.test(n = NA, d = .5) |>
  Spower(power=.8, interval=c(2,500), parallel=TRUE, ncores=2)
summary(out.par)

# similar information from pwr package
(pwr <- pwr::pwr.t.test(d=.5, power=.80))
ceiling(pwr$n) * 2

# If greater precision is required and the user has a specific amount of time
# they are willing to wait (e.g., 5 minutes) then wait.time can be used. Below
# estimates root after searching for 1 minute, and run in parallel with 2 cores
p_t.test(n = NA, d = .5) |>
  Spower(power=.8, interval=c(2,500), wait.time='1', parallel=TRUE, ncores=2)

# Solve d to get .80 power (sensitivity power analysis)
p_t.test(n = 50, d = NA) |> Spower(power=.8, interval=c(.1, 2))
pwr::pwr.t.test(n=50, power=.80) # compare

# Solve alpha that would give power of .80 (criterion power analysis)
#    interval not required (set to interval = c(0, 1))
p_t.test(n = 50, d = .5) |> Spower(power=.80, sig.level=NA)

# Solve beta/alpha ratio to specific error trade-off constant
#   (compromise power analysis)
out <- p_t.test(n = 50, d = .5) |> Spower(beta_alpha = 2)
with(out, (1-power)/sig.level)   # solved ratio

# update beta_alpha criteria without re-simulating
(out2 <- update(out, beta_alpha=4))
with(out2, (1-power)/sig.level)   # solved ratio

##############
# Power Curves
##############

# powerCurve() has similar input, though requires a varying argument
powerCurve(p_t.test, varying=c(30, 60, 90), n = NA, d = .5)

# solve n given power
powerCurve(p_t.test, n = NA, d = .5, power=c(.2, .5, .8), interval=c(2,500))

# multiple varying components
varying <- createDesign(n=c(30, 60, 90),
                        d=c(.2, .5))
powerCurve(p_t.test, varying=varying, replications=2000)

################
# Expected Power
################

# Expected power computed by including effect size uncertainty.
# For instance, belief is that the true d is somewhere around d ~ N(.5, 1/8)
dprior <- function(x, mean=.5, sd=1/8) dnorm(x, mean=mean, sd=sd)
curve(dprior, -1, 2, main=expression(d \%~\% N(0.5, 1/8)),
      xlab='d', ylab='density')

# For Spower, define prior sampler for specific parameter(s)
d_prior <- function() rnorm(1, mean=.5, sd=1/8)
d_prior(); d_prior(); d_prior()

# Replace d constant with d_prior to compute expected power
p_t.test(n = 50, d = d_prior()) |> Spower()

# A priori power analysis using expected power
p_t.test(n = NA, d = d_prior()) |>
  Spower(power=.8, interval=c(2,500))
pwr::pwr.t.test(d=.5, power=.80) # expected power result higher than fixed d


###############
# Customization
###############

#   Make edits to the function for customization
if(interactive()){
    p_my_t.test <- edit(p_t.test)
    args(p_my_t.test)
    body(p_my_t.test)
}

# Alternatively, define a custom function (potentially based on the template)
p_my_t.test <- function(n, d, var.equal=FALSE, n2_n1=1, df=10){

    # Welch power analysis with asymmetric distributions
    # group2 as large as group1 by default

    # degree of skewness controlled via chi-squared distribution's df
    group1 <- rchisq(n, df=df)
    group1 <-  (group1 - df) / sqrt(2*df)   # Adjusted mean to 0, sd = 1
    group2 <- rnorm(n*n2_n1, mean=d)
    dat <- data.frame(group = factor(rep(c('G1', 'G2'),
                                     times = c(n, n*n2_n1))),
    				  DV = c(group1, group2))
    obj <- t.test(DV ~ group, dat, var.equal=var.equal)

    # p-value must be first element when using default summarise()
    with(obj, c(p=p.value,
                mean_diff=unname(estimate[2] - estimate[1]),
                SE=stderr))
}

# Solve N to get .80 power (a priori power analysis), using defaults
p_my_t.test(n = NA, d = .5, n2_n1=2) |>
  Spower(power=.8, interval=c(2,500)) -> out

# total sample size required
with(out, ceiling(n) + ceiling(n * 2))

# Solve N to get .80 power (a priori power analysis), assuming
#   equal variances, group2 2x as large as group1, large skewness
p_my_t.test(n = NA, d=.5, var.equal=TRUE, n2_n1=2, df=3) |>
  Spower(power=.8, interval=c(30,100)) -> out2

# total sample size required
with(out2, ceiling(n) + ceiling(n * 2))

#######
# compute power and associated estimates using customized summarise function

# make template:
# SimDesign::SimFunctions()

Summarise <- function(condition, results, fixed_objects) {
  ret <- c(power = EDR(results[,1], alpha=.05),
           colMeans(results[,2:3]))
  ret
}

# for simulations with many more condition combinations to
#  explore runSimulation() is recommended instead
out <- p_my_t.test(n = 100, d = .5) |> Spower(summarise=Summarise)
out |> as.data.frame()


}
}
\seealso{
\code{\link{update}}, \code{\link{powerCurve}},
\code{\link{getLastSpower}}
}
