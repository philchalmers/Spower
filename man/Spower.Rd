% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Spower.R
\name{Spower}
\alias{Spower}
\title{Simulation-based Power Analysis}
\usage{
Spower(
  sim,
  ...,
  interval,
  power = NA,
  sig.level = 0.05,
  beta_alpha = NULL,
  replications = 10000,
  integer,
  parallel = FALSE,
  cl = NULL,
  ncores = parallelly::availableCores(omit = 1L),
  predCI = 0.95,
  predCI.tol = 0.01,
  verbose = TRUE,
  check.interval = TRUE,
  maxiter = 150,
  control = list()
)
}
\arguments{
\item{sim}{function that both creates the data and returns a single
p-value for the analysis of interest}

\item{...}{a set of conditions to use in the simulation that must match the
arguments in the function \code{sim_function}. Internally these arguments
are passed to either \code{\link{SimSolve}} or
\code{\link{runSimulation}} depending on which element (including
the \code{power} and \code{sig.level} arguments) is set to \code{NA}}

\item{interval}{search interval to use when \code{\link{SimSolve}} is required.
Note that for compromise analyses, where the \code{sig.level} is set to
\code{NA}, if not set explicitly then the interval will default to \code{c(0,1)}}

\item{power}{power level to use. If set to \code{NA} then the empirical power
will be estimated given the fixed \code{conditions} input
(e.g., for post-hoc power analysis)}

\item{sig.level}{alpha level to use. If set to \code{NA} then the empirical
alpha will be estimated given the fixed \code{conditions} input
(e.g., for criterion power analysis)}

\item{beta_alpha}{ratio to use in compromise analyses corresponding to
the Type II errors (beta) over the Type I error (alpha). Ratios greater
than 1 indicate that Type I errors are worse than Type II, while ratios
less than one the opposite. A ratio equal to 1 gives an equal trade-off
between Type I and Type II errors}

\item{replications}{number of replications to use when
\code{\link{runSimulation}} is required}

\item{integer}{a logical value indicating whether the search iterations
use integers or doubles.
Automatically set to \code{FALSE} if \code{interval} contains
non-integer numbers, as well as when \code{sig.level = NA},
though in general this should be set explicitly}

\item{parallel}{for parallel computing for slower simulation experiments
(see \code{\link{runSimulation}} for details)}

\item{cl}{see \code{\link{runSimulation}}}

\item{ncores}{see \code{\link{runSimulation}}}

\item{predCI}{predicting confidence interval level
(see \code{\link{SimSolve}})}

\item{predCI.tol}{predicting confidence interval consistency tolerance
for stochastic root solver convergence (see \code{\link{SimSolve}}).
Default converges when the power rate CI is consistently
within \code{.01/2} of the target power}

\item{verbose}{logical; should information be printed to the console?}

\item{check.interval}{logical; check the interval range validity
(see \code{\link{SimSolve}})}

\item{maxiter}{maximum number of stochastic root-solving iterations}

\item{control}{a list of control parameters to pass to
\code{\link{runSimulation}} or \code{\link{SimSolve}}}
}
\description{
General purpose function that serves as a power-focused wrapper to the
\code{SimDesign} package's \code{\link{runSimulation}} and
\code{\link{SimSolve}} functions.
}
\details{
Five types of power analysis flavors can be performed with \code{Spower},
which are triggered based on which supplied inputs as set to missing (\code{NA}):

\describe{
\item{A priori}{Solve for a missing sample size component
(e.g., \code{n}) to achieve a specific target power rate
(argument \code{power})}
\item{Post-hoc}{Estimate the power rate given a set of fixed conditions}
\item{Sensitivity}{Solve a missing effect size value as a function of
the other supplied constant components}
\item{Criterion}{Solve the error rate (argument \code{sig.level}) as a
function of the other supplied constant components}
\item{Compromise}{Solve a Type I/Type II error trade-off ratio as a
function of the other supplied constant components and the
target ratio \eqn{q = \beta/\alpha} (argument \code{beta_alpha})}
}

Post-hoc and compromise analyses utilize the
\code{\link[SimDesign]{runSimulation}} function, while the remaining three
approaches utilize the stochastic root solving methods in the function
\code{\link[SimDesign]{SimSolve}}.
See the example below for a demonstration with an independent samples t-test
analysis.
}
\examples{

############################
# Independent samples t-test
############################

# Internally defined p_t.test function
args(p_t.test)    # missing arguments required for Spower()
# help(p_t.test)  # additional information

# p_* functions generate data and return single p-value
p_t.test(n=50, d=.5)
p_t.test(n=50, d=.5)

# Estimate power given fixed inputs (post-hoc power analysis)
(out <- Spower(p_t.test, n = 50, d = .5))
summary(out)   # extra information

\dontrun{

# Same as above, but executed with multiple cores (not run)
# (out <- Spower(p_t.test, n = 50, d = .5, parallel=TRUE))

# Solve N to get .80 power (a priori power analysis)
(out <- Spower(p_t.test, n = NA, d = .5, power=.8, interval=c(2,500)))
# total sample size required
ceiling(out$n) * 2

# similar information from pwr package
(pwr <- pwr::pwr.t.test(d=.5, power=.80))
ceiling(pwr$n) * 2

# Solve d to get .80 power (sensitivity power analysis)
Spower(p_t.test, n = 50, d = NA, power=.8, interval=c(.1, 2))

pwr::pwr.t.test(n=50, power=.80) # compare

# Solve alpha that would give power of .80 (criterion power analysis)
#    interval not required (set to interval = c(0, 1))
Spower(p_t.test, n = 50, d = .5, power=.80, sig.level=NA)

# Solve beta/alpha ratio to specific error trade-off constant
#   (compromise power analysis)
Spower(p_t.test, n = 50, d = .5, beta_alpha = 2)


###############
# Customization
###############

#   Make edits to the function for customization
if(interactive()){
    new.p_t.test <- edit(p_t.test)
    args(new.p_t.test)
    body(new.p_t.test)
}

# Alternatively, define a custom function (potentially based on the template)
new.p_t.test <- function(n, d, var.equal=FALSE, n2_n1=1, df=10){

    # Welch power analysis with asymmetric distributions
    # group2 as large as group1 by default

    # degree of skewness controlled via chi-squared distribution's df
    group1 <- rchisq(n, df=df)
    group1 <-  (group1 - df) / sqrt(2*df)   # Adjusted mean to 0, sd = 1
    group2 <- rnorm(n*n2_n1, mean=d)
    dat <- data.frame(group = factor(rep(c('G1', 'G2'),
                                     times = c(n, n*n2_n1))),
    				  DV = c(group1, group2))
    p <- t.test(DV ~ group, dat, var.equal=var.equal)$p.value
    p
}

# Solve N to get .80 power (a priori power analysis), using defaults
Spower(p_t.test, n = NA, d = .5, power=.8, interval=c(2,500))

# Solve N to get .80 power (a priori power analysis), assuming
#   equal variances, group2 2x as large as group1, large skewness
(out <- Spower(p_t.test, n = NA, d = .5, var.equal=TRUE, n2_n1=2, df=3,
               power=.8, interval=c(2,500)))

# total sample size required
ceiling(out$n) + ceiling(out$n) * 2

# should different alpha level be used given the assumption violations?
(TypeI <- Spower(p_t.test, n = 50, d = 0, var.equal=TRUE, n2_n1=2, df=3,
                 replications=30000))
se <- with(TypeI, sqrt(sig.level * (1-sig.level) / REPLICATIONS))
TypeI$sig.level + qnorm(c(.025, .975)) * se  # 95\% CI
TypeI$power


}
}
