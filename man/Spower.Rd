% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Spower.R
\name{Spower}
\alias{Spower}
\alias{print.Spower}
\title{Simulation-based Power Analyses}
\usage{
Spower(
  p_sim,
  ...,
  interval,
  power = NA,
  sig.level = 0.05,
  summarise = NULL,
  beta_alpha = NULL,
  replications = 10000,
  integer,
  prior = NULL,
  parallel = FALSE,
  cl = NULL,
  ncores = parallelly::availableCores(omit = 1L),
  predCI = 0.95,
  predCI.tol = 0.01,
  verbose = TRUE,
  check.interval = TRUE,
  maxiter = 150,
  wait.time = NULL,
  control = list()
)

\method{print}{Spower}(x, ...)
}
\arguments{
\item{p_sim}{function that both creates the data and returns a single
p-value for the analysis of interest}

\item{...}{a set of conditions to use in the simulation that must match the
arguments in the function \code{sim}. Internally these arguments
are passed to either \code{\link[SimDesign]{SimSolve}} or
\code{\link[SimDesign]{runSimulation}} depending on which element (including
the \code{power} and \code{sig.level} arguments) is set to \code{NA}}

\item{interval}{search interval to use when \code{\link[SimDesign]{SimSolve}} is required.
Note that for compromise analyses, where the \code{sig.level} is set to
\code{NA}, if not set explicitly then the interval will default to \code{c(0,1)}}

\item{power}{power level to use. If set to \code{NA} then the empirical power
will be estimated given the fixed \code{...} inputs
(e.g., for post-hoc power analysis)}

\item{sig.level}{alpha level to use. If set to \code{NA} then the empirical
alpha will be estimated given the fixed \code{conditions} input
(e.g., for criterion power analysis)}

\item{summarise}{(optional) user-defined function for the \code{summarise}
step in \code{\link[SimDesign]{runSimulation}}, with the constraint that the first
element returned is should be the empirical detection rate estimate.
If not specified an internal function
will be used where the first element of the analysis output will be
passed to \code{\link[SimDesign]{EDR}} to compute the empirical detection rate}

\item{beta_alpha}{ratio to use in compromise analyses corresponding to
the Type II errors (beta) over the Type I error (alpha). Ratios greater
than 1 indicate that Type I errors are worse than Type II, while ratios
less than one the opposite. A ratio equal to 1 gives an equal trade-off
between Type I and Type II errors}

\item{replications}{number of replications to use when
\code{\link[SimDesign]{runSimulation}} is required}

\item{integer}{a logical value indicating whether the search iterations
use integers or doubles.

If missing, automatically set to \code{FALSE} if \code{interval} contains
non-integer numbers or the range is less than 5, as well as
when \code{sig.level = NA}, though in general this should be set explicitly}

\item{prior}{an optional user-defined function defining any prior distributions
to use in order to compute an expected power output. No arguments are
required for this function, however the return must replace one or more
of the original arguments from the \code{...} input using either
a named \code{list} or \code{numeric} vector.}

\item{parallel}{for parallel computing for slower simulation experiments
(see \code{\link[SimDesign]{runSimulation}} for details).}

\item{cl}{see \code{\link[SimDesign]{runSimulation}}}

\item{ncores}{see \code{\link[SimDesign]{runSimulation}}}

\item{predCI}{predicting confidence interval level
(see \code{\link[SimDesign]{SimSolve}})}

\item{predCI.tol}{predicting confidence interval consistency tolerance
for stochastic root solver convergence (see \code{\link[SimDesign]{SimSolve}}).
Default converges when the power rate CI is consistently
within \code{.01/2} of the target power}

\item{verbose}{logical; should information be printed to the console?}

\item{check.interval}{logical; check the interval range validity
(see \code{\link[SimDesign]{SimSolve}})}

\item{maxiter}{maximum number of stochastic root-solving iterations}

\item{wait.time}{(optional) argument to indicate the time to wait
(specified in minutes). See \code{\link[SimDesign]{SimSolve}} for details}

\item{control}{a list of control parameters to pass to
\code{\link[SimDesign]{runSimulation}} or \code{\link[SimDesign]{SimSolve}}}

\item{x}{object of class \code{'Spower'}}
}
\value{
an invisible \code{tibble}/\code{data.frame}-type object of
class \code{'Spower'}
}
\description{
General purpose function that provides power-focused estimates for
a priori, post-hoc, compromise, sensitivity, and criterion power analysis.
Function provides a general wrapper to the
\code{SimDesign} package's \code{\link[SimDesign]{runSimulation}} and
\code{\link[SimDesign]{SimSolve}} functions. As such, parallel processing is
automatically supported, along with progress bars,
confidence/prediction intervals for the results estimates, safety checks,
and more.
}
\details{
Five types of power analysis flavours can be performed with \code{Spower},
which are triggered based on which supplied input is set to missing (\code{NA}):

\describe{
\item{A Priori}{Solve for a missing sample size component
(e.g., \code{n}) to achieve a specific target power rate}
\item{Post-hoc}{Estimate the power rate given a set of fixed conditions}
\item{Sensitivity}{Solve a missing effect size value as a function of
the other supplied constant components}
\item{Criterion}{Solve the error rate (argument \code{sig.level}) as a
function of the other supplied constant components}
\item{Compromise}{Solve a Type I/Type II error trade-off ratio as a
function of the other supplied constant components and the
target ratio \eqn{q = \beta/\alpha} (argument \code{beta_alpha})}
}

Post-hoc and compromise analyses utilize the
\code{\link[SimDesign]{runSimulation}} function, while the remaining three
approaches utilize the stochastic root solving methods in the function
\code{\link[SimDesign]{SimSolve}}.
See the example below for a demonstration with an independent samples t-test
analysis.
}
\examples{

############################
# Independent samples t-test
############################

# Internally defined p_t.test function
args(p_t.test)    # missing arguments required for Spower()
# help(p_t.test)  # additional information

# p_* functions generate data and return single p-value
p_t.test(n=50, d=.5)
p_t.test(n=50, d=.5)

# test that it works
Spower(p_t.test, n = 50, d = .5, replications=10)

\dontrun{

# Estimate power given fixed inputs (post-hoc power analysis)
out <- Spower(p_t.test, n = 50, d = .5)
summary(out)   # extra information

# increase precision
Spower(p_t.test, n = 50, d = .5, replications=30000)

# Same as above, but executed with multiple cores (not run)
# Spower(p_t.test, n = 50, d = .5, replications=30000, parallel=TRUE)

# Solve N to get .80 power (a priori power analysis)
out <- Spower(p_t.test, n = NA, d = .5, power=.8, interval=c(2,500))
summary(out)  # extra information
plot(out)
plot(out, type = 'history')

# total sample size required
ceiling(out$n) * 2

# similar information from pwr package
(pwr <- pwr::pwr.t.test(d=.5, power=.80))
ceiling(pwr$n) * 2

# If greater precision is required and the user has a specific amount of time
# they are willing to wait (e.g., 5 minutes) then wait.time can be used. Below
# estimates root after searching for 1 minute
Spower(p_t.test, n = NA, d = .5, power=.8, interval=c(2,500), wait.time='1')

# Solve d to get .80 power (sensitivity power analysis)
Spower(p_t.test, n = 50, d = NA, power=.8, interval=c(.1, 2))
pwr::pwr.t.test(n=50, power=.80) # compare

# Solve alpha that would give power of .80 (criterion power analysis)
#    interval not required (set to interval = c(0, 1))
Spower(p_t.test, n = 50, d = .5, power=.80, sig.level=NA)

# Solve beta/alpha ratio to specific error trade-off constant
#   (compromise power analysis)
(out <- Spower(p_t.test, n = 50, d = .5, beta_alpha = 2))
with(out, (1-power)/sig.level)   # check ratio

# update beta_alpha criteria without re-simulating
(out2 <- update(out, beta_alpha=4))
with(out2, (1-power)/sig.level)   # check ratio

##############
# Power Curves
##############

# powerCurve() has similar input, though requires a varying argument
powerCurve(p_t.test, varying=c(30, 60, 90), n = NA, d = .5)

# solve n given power
powerCurve(p_t.test, n = NA, d = .5, power=c(.2, .5, .8), interval=c(2,500))

# multiple varying components
varying <- createDesign(n=c(30, 60, 90),
                        d=c(.2, .5))
powerCurve(p_t.test, varying=varying, replications=2000)

################
# Expected Power
################

# Expected power computed by including effect size uncertainty.
# For instance, belief is that the true d is somewhere around d ~ N(.5, 1/8)
dprior <- function(x, mean=.5, sd=1/8) dnorm(x, mean=mean, sd=sd)
curve(dprior, -1, 2, main=expression(d \%~\% N(0.5, 1/8)),
      xlab='d', ylab='density')

# define prior sampler and returned named object (list or numeric vector)
prior <- function() c(d=rnorm(1, mean=.5, sd=1/8))
prior(); prior(); prior()

# Expected power (d no longer in ... since it's returned from prior())
Spower(p_t.test, n = 50, prior=prior)

# A priori power analysis using expected power
Spower(p_t.test, n = NA, power=.8, interval=c(2,500), prior=prior)
pwr::pwr.t.test(d=.5, power=.80) # expected power result higher than fixed d


###############
# Customization
###############

#   Make edits to the function for customization
if(interactive()){
    sim_t.test <- edit(p_t.test)
    args(sim_t.test)
    body(sim_t.test)
}

# Alternatively, define a custom function (potentially based on the template)
sim_t.test <- function(n, d, var.equal=FALSE, n2_n1=1, df=10){

    # Welch power analysis with asymmetric distributions
    # group2 as large as group1 by default

    # degree of skewness controlled via chi-squared distribution's df
    group1 <- rchisq(n, df=df)
    group1 <-  (group1 - df) / sqrt(2*df)   # Adjusted mean to 0, sd = 1
    group2 <- rnorm(n*n2_n1, mean=d)
    dat <- data.frame(group = factor(rep(c('G1', 'G2'),
                                     times = c(n, n*n2_n1))),
    				  DV = c(group1, group2))
    obj <- t.test(DV ~ group, dat, var.equal=var.equal)

    # p-value must be first element when using default summarise()
    with(obj, c(p=p.value,
                mean_diff=unname(estimate[2] - estimate[1]),
                SE=stderr))
}

# Solve N to get .80 power (a priori power analysis), using defaults
Spower(sim_t.test, n = NA, d = .5, power=.8, interval=c(2,500))

# Solve N to get .80 power (a priori power analysis), assuming
#   equal variances, group2 2x as large as group1, large skewness
(out <- Spower(sim_t.test, n = NA, d = .5, var.equal=TRUE, n2_n1=2, df=3,
               power=.8, interval=c(2,500)))

# total sample size required
with(out, ceiling(n) + ceiling(n * 2))

#######
# compute power and associated estimates using customized summarise function

# make template:
# SimDesign::SimFunctions()

Summarise <- function(condition, results, fixed_objects) {
  ret <- c(power = EDR(results[,1], alpha=.05),
           colMeans(results[,2:3]))
  ret
}

# for simulations with many more conditions using runSimulation() is recommended
out <- Spower(sim_t.test, n = 100, d = .5, summarise=Summarise)
out |> as.data.frame()


}
}
\seealso{
\code{\link{update}}, \code{\link{powerCurve}}
}
