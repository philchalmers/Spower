[{"path":"https://philchalmers.github.io/Spower/articles/SpowerIntro.html","id":"types-of-functions","dir":"Articles","previous_headings":"","what":"Types of functions","title":"Introduction to the Spower package","text":"generally two ways go using Spower. first utilizing one handful build-simulation experiments associated data-generation analysis, flexibility (less user friendly) constructing user-defined simulation experiment way writing simulation code encapsulated inside single function. either case, goal design R code perform given simulation experiment set meaningful (often scalar) functional arguments, output function returns either: suitable pp-value null hypothesis statistical testing (NHST) paradigm, P(D|H0)P(D|H_0), posterior probability (typically alternative) hypothesis, P(H1|D)P(H_1|D), logical value indicating support hypothesis interest first two cases, pp value returned compared suitable cut-defined package (e.g., pp less α=.05\\alpha=.05 first option, second might pp greater α.95\\alpha.95), therefore converted TRUE/FALSE value internally, ladder require transformation. cases, average resulting TRUE/FALSE values reflects something statistical power (e.g., TRUE rejecting null; TRUE supporting alternative; complicated combination involving precision, multiple hypotheses, regions practical equivalence/significance, etc), thereby forming basis subsequent power analysis procedures. internal functions available Spower primarily focuses first approach criteria involving NHST pp-values, historically common similar software (e.g., GPower 3), however nothing precludes Spower complex interesting power analyses. See vignette “Logical Vectors, Bayesian power analyses ROPEs” advanced examples involving confidence intervals (CIs), parameter precision criterion, regions practical equivalences (ROPEs), equivalence tests, Bayes Factors, power analyses involving posterior probabilities. See also vignette “Type S Type M errors” conditional power evaluation information estimate sign (S) magnitude (M) power information respective Type S Type M errors (Gelman Carlin, 2014).","code":""},{"path":"https://philchalmers.github.io/Spower/articles/SpowerIntro.html","id":"built-in-simulation-experiments","dir":"Articles","previous_headings":"Types of functions","what":"Built-in simulation experiments","title":"Introduction to the Spower package","text":"Spower ships several common statistical inference experiments, involving linear regression models, mediation analyses, ANOVAs, tt-tests, correlations, . simulation experiments organized prefix p_, followed name analysis method. instance, performs single simulation experiment reflecting null hypothesis H0:R2=0H_0:\\, R^2=0 linear regression model k=3k=3 predictor variables sample size N=50N=50. Translating information power analysis context now simply requires passing experiment Spower() (details discussed ), default estimate power (1−β̂1-\\hat{\\beta}) returned using default sig.level = .05. p_* functions return pp-value (P(D|H0P(D|H_0) general information required evaluate statistical power Spower(). Alternatively, users may define simulation functions desired experiment defined within package.","code":"p_lm.R2(50, k=3, R2=.3) ## [1] 0.004935905 p_lm.R2(50, k=3, R2=.3) |> Spower() ##  ## Execution time (H:M:S): 00:00:41 ## Design conditions:  ##  ## # A tibble: 1 × 5 ##       n    R2     k sig.level power ##   <dbl> <dbl> <dbl>     <dbl> <lgl> ## 1    50   0.3     3      0.05 NA    ##  ## Estimate of power: 0.971 ## 95% Confidence Interval: [0.968, 0.974]"},{"path":"https://philchalmers.github.io/Spower/articles/SpowerIntro.html","id":"user-defined-simulation-experiments","dir":"Articles","previous_headings":"Types of functions","what":"User-defined simulation experiments","title":"Introduction to the Spower package","text":"simple example, suppose one interested power reject null hypothesis H0:μ=μ0H_0:\\, \\mu = \\mu_0 one-sample tt-test scenario, P(D|H0)P(D|H_0) probability data given null hypothesis interest. Note package already supports type analysis (see help(p_t.test)) instructive see users can write version experiment, help defining simulations outside currently included package. simulation experiment first obtain sample data drawn Gaussian distribution specific mean (μ\\mu), evaluate conditional probability data generated population μ0=0\\mu_0=0 (null; hence, P(D|μ0=0)P(D|\\mu_0=0)). , pp-value returned experiments reflects probability observing data given null hypothesis H0:μ=μ0H_0:\\, \\mu=\\mu_0, specifically H0:μ=0H_0:\\, \\mu=0, single generated dataset. , suitable cut-required evaluate whether experiment ‘significant’, purpose parameter α\\alpha. Specifically, observed data (DD) plausibly drawn population μ0\\mu_0 (hence, P(D|μ0)≥αP(D|\\mu_0) \\ge \\alpha) FALSE significance returned; otherwise, data unlikely observed given (P(D|μ0=0)<αP(D|\\mu_0=0) < \\alpha) TRUE returned, thereby indicating statistical significance. convenience, purpose types specialized power analyses (e.g., compromise analyses), α\\alpha parameter controlled via argument Spower(..., sig.level = .05), creates TRUE/FALSE evaluations internally. saves step writing, users wished defined sig.level within simulation experiment acceptable approach .","code":"p_single.t <- function(n, mean, mu=0){     g <- rnorm(n, mean=mean)     p <- t.test(g, mu=mu)$p.value     p } # a single experiment p_single.t(n=100, mean=.2) ## [1] 0.06328707"},{"path":"https://philchalmers.github.io/Spower/articles/SpowerIntro.html","id":"types-of-power-analyses-to-evaluate","dir":"Articles","previous_headings":"","what":"Types of power analyses to evaluate","title":"Introduction to the Spower package","text":"power analyses typically four parameters can manipulated/solved given experiment: α\\alpha level (Type error, often reflexively set α=.05\\alpha=.05), power (complement Type II error, 1−β1-\\beta), effect size interest, sample size. Given three values, fourth can always solved. Note description reflects general rule--thumb, may multiple effect sizes interest, multiple sample size definitions (e.g., form cluster sizes multi-level models), . Regardless, Spower() switching types power analysis criteria performed simply explicitly specifying parameter missing (NA), demonstrated , therefore specific naming conventions type analysis performed particularly important, though following presentation may instructive nonetheless.","code":""},{"path":"https://philchalmers.github.io/Spower/articles/SpowerIntro.html","id":"prospectivepost-hoc-power-analysis","dir":"Articles","previous_headings":"Types of power analyses to evaluate","what":"Prospective/post-hoc power analysis","title":"Introduction to the Spower package","text":"canonical setup Spower() evaluate prospective post-hoc power, thereby obtaining estimate 1−β̂1-\\hat{\\beta}. default, Spower() uses 10,00010,000 independent simulation replications estimate power target criterion. Given simulation definition, following provides estimate power given null hypothesis H0:μ=0.3H_0:\\, \\mu=0.3 given data generated distribution μ=.5\\mu = .5 n=100n=100.","code":"p_single.t(n=100, mean=.5, mu=.3) |> Spower() -> prospective prospective ##  ## Execution time (H:M:S): 00:00:03 ## Design conditions:  ##  ## # A tibble: 1 × 5 ##       n  mean    mu sig.level power ##   <dbl> <dbl> <dbl>     <dbl> <lgl> ## 1   100   0.5   0.3      0.05 NA    ##  ## Estimate of power: 0.515 ## 95% Confidence Interval: [0.505, 0.525]"},{"path":"https://philchalmers.github.io/Spower/articles/SpowerIntro.html","id":"compromise-power-analysis","dir":"Articles","previous_headings":"Types of power analyses to evaluate","what":"Compromise power analysis","title":"Introduction to the Spower package","text":"Compromise power analysis involves manipulating α\\alpha level sufficient balance Type Type II error rates met, expressed terms ratio q=βαq=\\frac{\\beta}{\\alpha}. Spower, two ways approach criterion. first, focuses beta_alpha ratio outset, requires passing target ratio Spower() using setup previous prospective power analysis. returns estimated sig.level (α̂\\hat{\\alpha}) resulting β̂\\hat{\\beta} satisfies target qq ratio q=β/α=4q = \\beta/\\alpha = 4. second way perform compromise analysis re-use previous evaluation prospective/post-hoc power analysis, contains necessary information obtaining compromise estimates. either case, use S3 generic update() function can beneficial stored result may reused alternative beta_alpha values, thereby avoiding need estimate new experimental data.","code":"p_single.t(n=100, mean=.5, mu=.3) |>      Spower(beta_alpha=4) -> compromise compromise ##  ## Execution time (H:M:S): 00:00:03 ## Design conditions:  ##  ## # A tibble: 1 × 6 ##       n  mean    mu sig.level power beta_alpha ##   <dbl> <dbl> <dbl>     <dbl> <lgl>      <dbl> ## 1   100   0.5   0.3        NA NA             4 ##  ## Estimate of Type I error rate (alpha/sig.level): 0.093 ## 95% Confidence Interval: [0.087, 0.098] ##  ## Estimate of power (1-beta): 0.629 ## 95% Confidence Interval: [0.620, 0.638] # satisfies q = 4 ratio with(compromise, (1 - power) / sig.level) ## [1] 4 # using previous post-hoc/prospective power analysis update(prospective, beta_alpha=4) ##  ## Execution time (H:M:S): 00:00:03 ## Design conditions:  ##  ## # A tibble: 1 × 6 ##       n  mean    mu sig.level power beta_alpha ##   <dbl> <dbl> <dbl>     <dbl> <lgl>      <dbl> ## 1   100   0.5   0.3        NA NA             4 ##  ## Estimate of Type I error rate (alpha/sig.level): 0.093 ## 95% Confidence Interval: [0.088, 0.099] ##  ## Estimate of power (1-beta): 0.627 ## 95% Confidence Interval: [0.617, 0.636]"},{"path":"https://philchalmers.github.io/Spower/articles/SpowerIntro.html","id":"a-priori-power-analysis","dir":"Articles","previous_headings":"Types of power analyses to evaluate","what":"A priori power analysis","title":"Introduction to the Spower package","text":"goal priori power analysis generally obtain sample size (NN) associated specific power rate interest (e.g., 1−β=.901-\\beta=.90), useful context future data collection planning. estimate sample size using Monte Carlo simulation experiments, Spower() performs stochastic root solving using ProBABLI approach SimDesign package (see SimSolve()), therefore requires specific search interval search within. width interval reflect plausible range researcher believes solution lie, however may quite large well ProBABLI less influenced range search interval (Chalmers, 2024). Moreover, algorithm fundamentally based bisections, midpoint specified interval organized reflect researcher’s “best guess” solution likely , though generally worth considering simulation experiment evaluation time consuming. sample size n solved achieve target power 1−β=.801-\\beta=.80, solution NN suspected lie somewhere search interval = c(20, 200), initial starting guess N̂=(20+200)/2=110\\hat{N}=(20 + 200)/2=110 (quite far true solution, case adds little overall computation time). Equivalently, rather placing interval definition within Spower() providing suitable NA placeholder indicate argument interval pertains , function interval() can used directly experiment definition argument. Hence, following identical example, though requires less back--forth reading pipe seperator. course, output still presented terms NA placeholder logic, however case user need specify NA explicitly clear context.","code":"p_single.t(n=NA, mean=.5) |>      Spower(power=.8, interval=c(20,200)) ##  ## Execution time (H:M:S): 00:00:25 ## Design conditions:  ##  ## # A tibble: 1 × 4 ##       n  mean sig.level power ##   <dbl> <dbl>     <dbl> <dbl> ## 1    NA   0.5      0.05   0.8 ##  ## Estimate of n: 32.8 ## 95% Predicted Confidence Interval: [32.4, 33.1] p_single.t(n=interval(20, 200), mean=.5) |> Spower(power=.8) ##  ## Execution time (H:M:S): 00:00:25 ## Design conditions:  ##  ## # A tibble: 1 × 4 ##       n  mean sig.level power ##   <dbl> <dbl>     <dbl> <dbl> ## 1    NA   0.5      0.05   0.8 ##  ## Estimate of n: 32.8 ## 95% Predicted Confidence Interval: [32.4, 33.1]"},{"path":"https://philchalmers.github.io/Spower/articles/SpowerIntro.html","id":"sensitivity-power-analysis","dir":"Articles","previous_headings":"Types of power analyses to evaluate","what":"Sensitivity power analysis","title":"Introduction to the Spower package","text":"Similar priori power analysis, stochastic root solving required, target sensitivity analysis locate specific standardized unstandardized effect size result particular power rate. pertains question large effect size must order reliably detect effect interest, holding constant information sample size. sample size fixed N=100N=100, interval standardized effect size dd searched c(.1, 3). Note use decimals interval tells Spower() use continuous rather discrete search space (cf. priori, uses integer search space simulation replicates). Equivalently, using interval() (run).","code":"p_single.t(n=100, mean=NA) |>      Spower(power=.8, interval=c(.1, 3)) ##  ## Execution time (H:M:S): 00:00:20 ## Design conditions:  ##  ## # A tibble: 1 × 4 ##       n  mean sig.level power ##   <dbl> <dbl>     <dbl> <dbl> ## 1   100    NA      0.05   0.8 ##  ## Estimate of mean: 0.281 ## 95% Predicted Confidence Interval: [0.280, 0.283] # p_single.t(n=100, mean=interval(.1, 3)) |> Spower(power=.8)"},{"path":"https://philchalmers.github.io/Spower/articles/SpowerIntro.html","id":"criterion-power-analysis","dir":"Articles","previous_headings":"Types of power analyses to evaluate","what":"Criterion power analysis","title":"Introduction to the Spower package","text":"Finally, criterion power analysis goal locate associated α\\alpha level (sig.level) required achieve target power output holding constant modeling information. done Spower() setting sig.level input NA providing values parameters. Note technically search interval require context α\\alpha necessarily lies interval [0,1][0,1].","code":"p_single.t(n=50, mean=.5) |>      Spower(power=.8, sig.level=NA) ##  ## Execution time (H:M:S): 00:00:17 ## Design conditions:  ##  ## # A tibble: 1 × 4 ##       n  mean sig.level power ##   <dbl> <dbl>     <dbl> <dbl> ## 1    50   0.5        NA   0.8 ##  ## Estimate of sig.level: 0.010 ## 95% Predicted Confidence Interval: [0.009, 0.010]"},{"path":"https://philchalmers.github.io/Spower/articles/SpowerIntro.html","id":"multiple-power-evaluation-functions","dir":"Articles","previous_headings":"","what":"Multiple power evaluation functions","title":"Introduction to the Spower package","text":"following functions, SpowerBatch() SpowerCurve(), can used evaluate visualize power analysis results across range inputs rather single set fixed inputs. section demonstrates general usage, specifications slightly differ Spower(), despite fact Spower() underlying estimation engine.","code":""},{"path":"https://philchalmers.github.io/Spower/articles/SpowerIntro.html","id":"spowerbatch","dir":"Articles","previous_headings":"Multiple power evaluation functions","what":"SpowerBatch()","title":"Introduction to the Spower package","text":"begin, suppose interest evaluating p_single.t() function across multiple nn inputs obtain estimates 1−β1-\\beta. performed using independent calls Spower(), function SpowerBatch() can used instead, variable inputs can specified suitable vector format. instance, given effect size μ=.5\\mu=.5, power reject null hypothesis H0:μ=0H_0:\\, \\mu=0 across three different sample sizes, N=[30,60,90]N = [30,60,90]? can coerced data.frame object reason (e.g., plotting purposes, though see also SpowerCurve()). Similarly, related priori analyses sample size planning inputs SpowerBatch() modified set n missing quantity.","code":"p_single.t(mean=.5) |>      SpowerBatch(n=c(30, 60, 90)) -> prospective.batch prospective.batch ## $CONDITION_1 ##  ## Execution time (H:M:S): 00:00:03 ## Design conditions:  ##  ## # A tibble: 1 × 4 ##       n  mean sig.level power ##   <dbl> <dbl>     <dbl> <lgl> ## 1    30   0.5      0.05 NA    ##  ## Estimate of power: 0.752 ## 95% Confidence Interval: [0.743, 0.760] ##  ## $CONDITION_2 ##  ## Execution time (H:M:S): 00:00:03 ## Design conditions:  ##  ## # A tibble: 1 × 4 ##       n  mean sig.level power ##   <dbl> <dbl>     <dbl> <lgl> ## 1    60   0.5      0.05 NA    ##  ## Estimate of power: 0.967 ## 95% Confidence Interval: [0.963, 0.970] ##  ## $CONDITION_3 ##  ## Execution time (H:M:S): 00:00:03 ## Design conditions:  ##  ## # A tibble: 1 × 4 ##       n  mean sig.level power ##   <dbl> <dbl>     <dbl> <lgl> ## 1    90   0.5      0.05 NA    ##  ## Estimate of power: 0.996 ## 95% Confidence Interval: [0.995, 0.997] as.data.frame(prospective.batch) ##    n mean sig.level  power    CI_2.5   CI_97.5 ## 1 30  0.5      0.05 0.7516 0.7431313 0.7600687 ## 2 60  0.5      0.05 0.9669 0.9633937 0.9704063 ## 3 90  0.5      0.05 0.9963 0.9951100 0.9974900 apriori.batch <- p_single.t(mean=.5, n=NA) |>      SpowerBatch(power=c(.7, .8, .9), interval=c(20, 200))  apriori.batch ## $CONDITION_1 ##  ## Execution time (H:M:S): 00:00:41 ## Design conditions:  ##  ## # A tibble: 1 × 4 ##       n  mean sig.level power ##   <dbl> <dbl>     <dbl> <dbl> ## 1    NA   0.5      0.05   0.7 ##  ## Estimate of n: 26.7 ## 95% Predicted Confidence Interval: [26.5, 27.0] ##  ## $CONDITION_2 ##  ## Execution time (H:M:S): 00:00:21 ## Design conditions:  ##  ## # A tibble: 1 × 4 ##       n  mean sig.level power ##   <dbl> <dbl>     <dbl> <dbl> ## 1    NA   0.5      0.05   0.8 ##  ## Estimate of n: 33.3 ## 95% Predicted Confidence Interval: [32.9, 33.7] ##  ## $CONDITION_3 ##  ## Execution time (H:M:S): 00:00:33 ## Design conditions:  ##  ## # A tibble: 1 × 4 ##       n  mean sig.level power ##   <dbl> <dbl>     <dbl> <dbl> ## 1    NA   0.5      0.05   0.9 ##  ## Estimate of n: 44.4 ## 95% Predicted Confidence Interval: [43.8, 44.8] as.data.frame(apriori.batch) ##          n mean sig.level power   CI_2.5  CI_97.5 ## 1 26.71726  0.5      0.05   0.7 26.46683 26.96011 ## 2 33.31082  0.5      0.05   0.8 32.90640 33.69844 ## 3 44.36998  0.5      0.05   0.9 43.76155 44.84176"},{"path":"https://philchalmers.github.io/Spower/articles/SpowerIntro.html","id":"spowercurve","dir":"Articles","previous_headings":"Multiple power evaluation functions","what":"SpowerCurve()","title":"Introduction to the Spower package","text":"Often times researchers wish visualize results power analyses form graphical representations. Spower supports various types visualizations function SpowerCurve(), creates power curve plots previously obtained results (e.g., via SpowerBatch()) --explored inputs. Importantly, graphic contains estimates Monte Carlo sampling uncertainty deter -interpretation resulting point-estimates. demonstrate, suppose one interested visualizing power running single-sample tt test across four different sample sizes, N=[30,60,90,120]N=[30,60,90,120]. requires passing simulation experiment varying information function SpowerCurve(), fills variable information supplied simulation experiment plots resulting output.  Alternatively, information already evaluated using SpowerBatch() batch object passed directly SpowerCurve()’s argument batch, thereby avoiding need re-evaluate simulation experiments. SpowerCurve() accept many arguments exists supplied simulation experiment definition, however provide aesthetic mappings first three variable input specifications anything past becomes difficult display automatically. example varies n input well input mean, first input appears xx-axis second mapped default colour aesthetic ggplot2.","code":"p_single.t(mean=.5) |>      SpowerCurve(n=c(30, 60, 90, 120)) # pass previous SpowerBatch() object SpowerCurve(batch=batch) p_single.t() |>      SpowerCurve(n=c(30, 60, 90, 120), mean=c(.2, .5, .8))"},{"path":"https://philchalmers.github.io/Spower/articles/SpowerIntro_logicals.html","id":"logical-returns","dir":"Articles","previous_headings":"","what":"Logical returns","title":"Logical Vectors, Bayesian power analyses, and ROPEs","text":"many applications can advantageous directly return logical values simulation experiment rather letting Spower() perform threshold transformations internally (e.g., using sig.level) can include intricate experimental requirements. following showcases various ways returning logical values works Spower package, average across collected TRUE/FALSE values reflects target power estimate. Note returning logical simulation experiment necessarily implies sig.level argument Spower() friends used, therefore suitable alternatives must defined within context simulation experiment code (e.g., including conf.level sig.level simulation experiment function directly).","code":""},{"path":"https://philchalmers.github.io/Spower/articles/SpowerIntro_logicals.html","id":"confidence-and-credible-intervals","dir":"Articles","previous_headings":"Logical returns","what":"Confidence (and credible) intervals","title":"Logical Vectors, Bayesian power analyses, and ROPEs","text":"Keeping basic tt-test experiment introduction vignette, suppose ’re interested power reject null hypothesis H0:μ=μ0H_0:\\, \\mu = \\mu_0 one-sample tt-test, P(D|H0)P(D|H_0) probability observing data given null hypothesis. Normally, one simply write experiment returns pp-value context, following, However, equivalent way explore power context investigate null hypothesis via confidence intervals given specific α\\alpha level define range, CIμ=[CIα/2,CI1−α/2]CI_\\mu=[CI_{\\alpha/2},CI_{1-\\alpha/2}]. one take approach, defined simulation function return logical value based relation parameter estimate CI, CI used evaluate plausibility μ=μ0\\mu = \\mu_0. Specifically, context using CI’s reflect pp-value logic, CI used evaluate whether μ0\\mu_0 falls outside advertised interval, returning TRUE outside CI FALSE within interval. Alternatively, one Bayesian analysis context, credible interval used instead confidence interval construct logical output. following code demonstrates logic, assuming α=.05\\alpha = .05 (therefore two-tailed, 95% CI used), uses .outside_CI() function evaluate whether μ0\\mu_0 parameter falls outside estimated CI returned t.test(). Evaluating power analysis Spower() works box now, noting l_single.t() ignore Spower(..., sig.level) information altogether longer relevant logical information returned. following compares pp-value logical CI approaches, provide identical inferential information case (always true; tt-test simply reflects special case).","code":"p_single.t <- function(n, mean, mu=0){     g <- rnorm(n, mean=mean)     p <- t.test(g, mu=mu)$p.value     p } l_single.t <- function(n, mean, mu=0, conf.level=.95){     g <- rnorm(n, mean=mean)     out <- t.test(g, mu=mu, conf.level=conf.level)     CI <- out$conf.int     is.outside_CI(mu, CI)   # equivalent to: !(CI[1] < mu && mu < CI[2]) }  l_single.t(100, mean=.2) ## [1] TRUE p_single.t(n=100, mean=.3) |> Spower() ##  ## Execution time (H:M:S): 00:00:03 ## Design conditions:  ##  ## # A tibble: 1 × 4 ##       n  mean sig.level power ##   <dbl> <dbl>     <dbl> <lgl> ## 1   100   0.3      0.05 NA    ##  ## Estimate of power: 0.846 ## 95% Confidence Interval: [0.839, 0.853] l_single.t(n=100, mean=.3) |> Spower() ##  ## Execution time (H:M:S): 00:00:04 ## Design conditions:  ##  ## # A tibble: 1 × 4 ##       n  mean sig.level power ##   <dbl> <dbl>     <dbl> <lgl> ## 1   100   0.3      0.05 NA    ##  ## Estimate of power: 0.841 ## 95% Confidence Interval: [0.834, 0.849]"},{"path":"https://philchalmers.github.io/Spower/articles/SpowerIntro_logicals.html","id":"using-previouls-defined-simulation-code","dir":"Articles","previous_headings":"Logical returns > Confidence (and credible) intervals","what":"Using previouls defined simulation code","title":"Logical Vectors, Bayesian power analyses, and ROPEs","text":"Note even CI context presented , writing user-defined functions may entirely necessary. related, internally defined function p_t.test() can used obtain CI information returning model , subsequently extracting $conf.int element. benefit , shown , users need reinvent data generation analysis portions experiment already available package.","code":"l_single.t <- function(n, mean, mu=0, conf.level=.95){     # return analysis output from t.test() for further extraction     out <- p_t.test(n=n, d=mean, mu=mu, type='one.sample',                      conf.level=conf.level, return_analysis=TRUE)     CI <- out$conf.int     is.outside_CI(mu, CI) }  l_single.t(100, mean=.2) ## [1] FALSE"},{"path":"https://philchalmers.github.io/Spower/articles/SpowerIntro_logicals.html","id":"precision-criterion","dir":"Articles","previous_headings":"Logical returns","what":"Precision criterion","title":"Logical Vectors, Bayesian power analyses, and ROPEs","text":"Using confidence credible intervals also useful contexts specific precision criteria important satisfy. Suppose , addition detecting particular effect interest given sample, results deemed “practically useful” resulting effect size inferences sufficiently precise, precision based magnitude SE, width uncertainty interval, relevant precision-based criterion. case, one may join logic pp-value/CI approaches create joint evaluation power, result deemed “significant useful” null hypothesis significantly rejected CI sufficiently narrow. working example, suppose one-sample tt-test experiment generalized meaningfully significant result require ) rejection null, μ0=0\\mu_0=0, b) CI width less 1/4 standardized mean units. value NN required obtain significant sufficiently accurate inference obtain power 80% given, say, “small” effect size d=0.2d=0.2? Compared required NN power analysis just contains significant result, joint practical significance criteria requires meaningfully higher sample size. Note special case CI.width=Inf CI widths accepted, result power output obtained using p_single.t().","code":"l_precision <- function(n, mean, CI.width, mu=0, alpha=.05){     g <- rnorm(n, mean=mean)     out <- t.test(g, mu=mu)     CI <- out$conf.int     width <- CI[2] - CI[1]     # return TRUE if significant and CI is sufficiently narrow     out$p.value < alpha && width < CI.width    } l_precision(n=NA, mean=.2, CI.width=1/4) |>      Spower(power=.80, interval=c(10, 500)) ##  ## Execution time (H:M:S): 00:00:22 ## Design conditions:  ##  ## # A tibble: 1 × 4 ##       n  mean sig.level power ##   <dbl> <dbl>     <dbl> <dbl> ## 1    NA   0.2      0.05   0.8 ##  ## Estimate of n: 272.6 ## 95% Predicted Confidence Interval: [272.0, 273.2] l_precision(n=NA, mean=.2, CI.width=Inf) |>      Spower(power=.80, interval=c(10, 500)) ##  ## Execution time (H:M:S): 00:00:20 ## Design conditions:  ##  ## # A tibble: 1 × 5 ##       n  mean CI.width sig.level power ##   <dbl> <dbl>    <dbl>     <dbl> <dbl> ## 1    NA   0.2      Inf      0.05   0.8 ##  ## Estimate of n: 198.8 ## 95% Predicted Confidence Interval: [197.2, 200.2]"},{"path":"https://philchalmers.github.io/Spower/articles/SpowerIntro_logicals.html","id":"bayes-factors","dir":"Articles","previous_headings":"Logical returns","what":"Bayes Factors","title":"Logical Vectors, Bayesian power analyses, and ROPEs","text":"one using Bayesian analysis criteria rather pp-value approach, Bayes factor (BFBF) ratio used logical return context . example, returning whether observed BF>3BF>3 given random sample indicate least “moderate” supporting evidence hypothesis interest compared competing hypothesis (often complementary null, P(H0|D)P(H_0|D), though necessarily), average across independent samples indicate degree power using Bayes factor cut-. downside focusing BFs require computation marginal likelihoods, typically via bridge sampling (e.g., via bridgesampling package), addition fitting model using Markov chain Monte Carlo (MCMC) methods (e.g., brms, rstan, rstanarm). Though strict limitation per se, often natural focus directly sample posterior distribution power analysis applications rather marginal Bayes factors; demonstrated next section. Nevertheless, applications possible Spower sufficient interest . simple example, following one-sample tt-test, initially defined , redefined focus output BayesFactor package, returns BFBF criteria log units (hence, exp() used return ratio original metric) assuming non-informative Jeffreys prior μ\\mu. case TRUE returned Bayes factor greater 3 FALSE less equal 3. Finally, ensure nothing important lost simulation experiment code data.frame() object returned instead just logical information, Spower() informed focus logical information purpose power computations. Evaluating simulation N=100N=100, μ=.5\\mu=.5, μ0=.3\\mu_0=.3 gives following power estimate. view complete simulation results use SimResults() resulting output, useful plotted. Note plotting Bayes factors advantageous present plot natural log units.","code":"l_single.Bayes.t_BF <- function(n, mean, mu=0, bf.cut=3){     g <- rnorm(n, mean=mean)     res <- BayesFactor::ttestBF(g, mu=mu)        bf <- exp(as.numeric(res@bayesFactor[1])) # Bayes factor     data.frame(largeBF=bf > bf.cut, bf=bf) } l_single.Bayes.t_BF(n=100, mean=.5, mu=.3) |> Spower(select='largeBF') -> BFsim BFsim ##  ## Execution time (H:M:S): 00:01:27 ## Design conditions:  ##  ## # A tibble: 1 × 5 ##       n  mean    mu sig.level power ##   <dbl> <dbl> <dbl>     <dbl> <lgl> ## 1   100   0.5   0.3      0.05 NA    ##  ## Estimate of power: 0.265 ## 95% Confidence Interval: [0.257, 0.274] BFresults <- SimResults(BFsim) BFresults ## # A tibble: 10,000 × 6 ##        n  mean    mu sig.level largeBF      bf ##    <dbl> <dbl> <dbl>     <dbl> <lgl>     <dbl> ##  1   100   0.5   0.3      0.05 FALSE     0.131 ##  2   100   0.5   0.3      0.05 FALSE     1.04  ##  3   100   0.5   0.3      0.05 FALSE     2.73  ##  4   100   0.5   0.3      0.05 TRUE     43.4   ##  5   100   0.5   0.3      0.05 FALSE     0.168 ##  6   100   0.5   0.3      0.05 FALSE     1.06  ##  7   100   0.5   0.3      0.05 TRUE      3.73  ##  8   100   0.5   0.3      0.05 TRUE    442.    ##  9   100   0.5   0.3      0.05 TRUE     11.3   ## 10   100   0.5   0.3      0.05 TRUE      4.11  ## # ℹ 9,990 more rows # use log-scale for Bayes factors as this is a more useful metric library(ggplot2) ggplot(BFresults, aes(log(bf), fill=largeBF)) +      geom_histogram(bins=50) + geom_vline(xintercept=log(3)) +      ggtitle('log(BF) distribution')"},{"path":"https://philchalmers.github.io/Spower/articles/SpowerIntro_logicals.html","id":"bayesian-power-analysis-via-posterior-probabiltes","dir":"Articles","previous_headings":"","what":"Bayesian power analysis via posterior probabiltes","title":"Logical Vectors, Bayesian power analyses, and ROPEs","text":"canonical way Spower designed focuses primarily pp-values involving null hypothesis tested (P(D|H0)P(D|H_0)). reason setting package way parameter α\\alpha (sig.level) can used “line---sand” threshold flag whether null hypothesis rejected sample data behaviour common among popular power analysis software. Bayesian power analysis, hand, also supported package, instead posterior probability alternative hypothesis, P(H1|D)P(H_1|D), focus simulation experiment. Continuing simple one-sample tt-test example introduction vignette , power analysis context Bayesian analysis conditional probability alternative, P(H1|D)P(H_1|D), may used instead. work Spower though, argument sig.direction = '' supplied, now sig.level indicates “significance” occurs probability observation define sig.level cutoff (hence, default .05 longer reasonable modified). one Bayesian approach using posterior probabilities using BayesFactor package, obtained translating Bayes factor output suitable posterior probability focusing alternative hypothesis (hence, posterior probability returned corresponds P(μ≠μ0|D)P(\\mu \\ne \\mu_0|D)). following also assumes competing hypotheses equally likely obtaining posterior probability (hence, prior odds 1:1, reflected argument prior_odds). Bayesian tt-test definition next code chunk evaluation, “significance” obtained whenever sample posterior greater sig.level = .90, demonstrating strong support H1H_1. Note strict criteria null hypothesis criteria presented introduction vignette, therefore notably lower power. approach power analysis criteria described help(Spower) still possible, instance solving experimental components (sample size n) easy setup providing suitable NA argument flags search intervals Spower().","code":"# assuming P(H1)/P(H0) are equally likely; hence, prior_odds = 1 pp_single.Bayes.t <- function(n, mean, mu, prior_odds = 1){     g <- rnorm(n, mean=mean)     res <- BayesFactor::ttestBF(g, mu=mu)        bf <- exp(as.numeric(res@bayesFactor[1])) # Bayes factor     posterior_odds <- bf * prior_odds     posterior <- posterior_odds / (posterior_odds + 1)        posterior   # P(H_1|D) } # power cut-off for a significantly supportive posterior is > 0.90 pp_single.Bayes.t(n=100, mean=.5, mu=.3) |>      Spower(sig.level = .90, sig.direction = 'above') ##  ## Execution time (H:M:S): 00:01:22 ## Design conditions:  ##  ## # A tibble: 1 × 5 ##       n  mean    mu sig.level power ##   <dbl> <dbl> <dbl>     <dbl> <lgl> ## 1   100   0.5   0.3       0.9 NA    ##  ## Estimate of power: 0.150 ## 95% Confidence Interval: [0.143, 0.157]"},{"path":"https://philchalmers.github.io/Spower/articles/SpowerIntro_logicals.html","id":"regions-of-practical-equivalence-ropes","dir":"Articles","previous_headings":"","what":"Regions of practical equivalence (ROPEs)","title":"Logical Vectors, Bayesian power analyses, and ROPEs","text":"section presents two related concepts estimating power justifiable equivalence interval interest.","code":""},{"path":"https://philchalmers.github.io/Spower/articles/SpowerIntro_logicals.html","id":"equivalence-testing","dir":"Articles","previous_headings":"Regions of practical equivalence (ROPEs)","what":"Equivalence testing","title":"Logical Vectors, Bayesian power analyses, and ROPEs","text":"alternative approach rejection null hypothesis via pp-value CI approaches, may interest evaluating power context establishing equivalence, directional cases superiority non-inferiority. purpose equivalence tests establish , although true differences may exist groups, differences small enough considered “practically equivalent” subsequent applications. running example, suppose independent samples tt-test two groups might considered “equivalent” true mean difference population somewhere ϵL\\epsilon_L ϵU\\epsilon_U, ϵ\\epsilons used define equivalence interval. , instance, two groups deemed statistically equivalent given boundary locations , using two-one sided hypothesis testing approach (TOST), two null hypotheses must evaluated H0a:(μ1−μ2)≤−ϵLH_{0a}:\\, (\\mu_1 - \\mu_2) \\le -\\epsilon_L H0b:(μ1−μ2)≥ϵUH_{0b}:\\,(\\mu_1 - \\mu_2) \\ge \\epsilon_U Rejecting null hypotheses leads induced complementary hypothesis interest H1:ϵL<(μ1−μ2)<ϵUH_1:\\, \\epsilon_L < (\\mu_1 - \\mu_2) < \\epsilon_U words, population mean difference falls within defined region equivalence. Superiority testing non-inferiority testing follow type logic, however rather defining region equivalence one tail equivalence interval interest. put numbers expression, suppose true mean difference groups μd=μ2−μ1=1\\mu_d = \\mu_2 - \\mu_1 = 1 (labeled delta), group SD=2.5SD = 2.5 (labeled sds). Furthermore, suppose true difference fell within equivalence interval [−2.5,2.5][-2.5, 2.5] (labeled equiv) deemed practically equivalent priori. power jointly reject null hypotheses, therefore conclude groups practically equivalence (H1H_1), evaluated following output experiment N=100N=100 observations (n=50n=50 group). case, power conclude two groups equivalent, expressed percentage, 84%. can verify computations correct comparing established software now, via TOSTER package. , type logic can evaluated using CIs alone, built-p_t.test() function, case TRUE returned estimated 90% CI falls within defined equivalence interval.","code":"l_equiv.t <- function(n, delta, equiv, sds = c(1,1),                        sig.level = .025){     g1 <- rnorm(n, mean=0, sd=sds[1])     g2 <- rnorm(n, mean=delta, sd=sds[2])     outL <- t.test(g2, g1, mu=-equiv[1], alternative = \"less\")$p.value     outU <- t.test(g2, g1, mu=equiv[2], alternative = \"less\")$p.value     outL < sig.level && outU < sig.level } l_equiv.t(50, delta=1, equiv=c(-2.5, 2.5),            sds=c(2.5, 2.5)) |> Spower() ##  ## Execution time (H:M:S): 00:00:06 ## Design conditions:  ##  ## # A tibble: 1 × 4 ##       n delta sig.level power ##   <dbl> <dbl>     <dbl> <lgl> ## 1    50     1      0.05 NA    ##  ## Estimate of power: 0.844 ## 95% Confidence Interval: [0.837, 0.851] TOSTER::power_t_TOST(n = 50,              delta = 1,              sd = 2.5,              eqb = 2.5,              alpha = .025,              power = NULL,              type = \"two.sample\") Two-sample TOST power calculation             power = 0.8438747            beta = 0.1561253           alpha = 0.025               n = 50           delta = 1              sd = 2.5          bounds = -2.5, 2.5  NOTE: n is number in *each* group l_equiv.t_CI <- function(n, delta, equiv,                           sds = c(1,1), conf.level = .95){     out <- p_t.test(n, delta, sds=sds, conf.level=conf.level,                      return_analysis=TRUE)     is.CI_within(out$conf.int, interval=equiv)  # returns TRUE if CI is within equiv interval } # an equivalent power analysis for \"equivalence tests\" via CI evaluations l_equiv.t_CI(50, delta=1, equiv=c(-2.5, 2.5),            sds=c(2.5, 2.5)) |> Spower() ##  ## Execution time (H:M:S): 00:00:05 ## Design conditions:  ##  ## # A tibble: 1 × 4 ##       n delta sig.level power ##   <dbl> <dbl>     <dbl> <lgl> ## 1    50     1      0.05 NA    ##  ## Estimate of power: 0.851 ## 95% Confidence Interval: [0.844, 0.858]"},{"path":"https://philchalmers.github.io/Spower/articles/SpowerIntro_logicals.html","id":"bayesian-approach-to-ropes-hdi-rope","dir":"Articles","previous_headings":"Regions of practical equivalence (ROPEs)","what":"Bayesian approach to ROPEs (HDI + ROPE)","title":"Logical Vectors, Bayesian power analyses, and ROPEs","text":"Finally, though exhaustively, one approach topic practical equivalence using Bayesian methods using draws posterior distribution interest, available BUGS HMC samplers (e.g., stan). approach highly similar equivalence testing approach described , uses highest density interval + ROPE Bayesian modeling instead. one example constructs simple linear regression model binary XX term analysed rstanarm::stan_glm(). example, proportion sampled posterior distribution falls within ROPE returned, works well sig.level argument coupled sig.direction = '') Spower() define suitable accept/reject cut-. Specifically, sig.level = .95 sig.direction = '') ROPE accepted percentage posterior distribution falls within defined ROPE greater .95. can course performed manually, returning TRUE satisfied FALSE otherwise, however case necessary. reports power estimate given N=50×2=100N=50\\times 2=100, ROPE criteria deemed satisfied/significant 95% posterior distribution β1=1\\beta_1=1 falls within defined range 1±.2→[.8,1.2]1 \\pm .2\\rightarrow [.8,1.2]. Due slower execution speeds simulations power evaluations computed using parallel=TRUE utilize available cores. Finally, demonstrate might useful, following estimates required sample size achieve 80% power using 95% HDI-ROPE criteria.","code":"library(bayestestR) library(rstanarm)  rope.lm <- function(n, beta0, beta1, range, sigma=1, ...){     # generate data     x <- matrix(rep(0:1, each=n))     y <- beta0 + beta1 * x + rnorm(nrow(x), sd=sigma)     dat <- data.frame(y, x)          # run model, but tell stan_glm() to use its indoor voice     model <- quiet(rstanarm::stan_glm(y ~ x, data = dat))     rope <- bayestestR::rope(model, ci=1, range=range, parameters=\"x\")     as.numeric(rope) } rope.lm(n=50, beta0=2, beta1=1, sigma=1/2, range=c(.8, 1.2)) |>      Spower(sig.level=.95, sig.direction='above', parallel=TRUE) ##  ## Execution time (H:M:S): 00:19:59 ## Design conditions:  ##  ## # A tibble: 1 × 5 ##       n beta0 beta1 sig.level power ##   <dbl> <dbl> <dbl>     <dbl> <lgl> ## 1    50     2     1      0.95 NA    ##  ## Estimate of power: 0.144 ## 95% Confidence Interval: [0.138, 0.151] rope.lm(n=NA, beta0=2, beta1=1, sigma=1/2, range=c(.8, 1.2)) |>      Spower(power=.80, sig.level=.95, sig.direction='above',            interval=c(50, 200), parallel=TRUE) ##  ## Execution time (H:M:S): 00:40:36 ## Design conditions:  ##  ## # A tibble: 1 × 5 ##       n beta0 beta1 sig.level power ##   <dbl> <dbl> <dbl>     <dbl> <dbl> ## 1    NA     2     1      0.95   0.8 ##  ## Estimate of n: 107.7 ## 95% Predicted Confidence Interval: [106.7, 108.7]"},{"path":"https://philchalmers.github.io/Spower/articles/Spower_TypeSM.html","id":"type-s-errors-via-simulation","dir":"Articles","previous_headings":"","what":"Type S errors via simulation","title":"Type M and Type S errors","text":"demonstrate estimate Type S errors via simulation, following simulation experiment performs two-sample tt-test “small” effect size (Cohen’s d=.2d=.2) smaller sample sizes. first implementation demonstrate logic user-defined data generation analysis, second approach demonstrates p_* functions defined within Spower can used instead — provided relevant power analysis investigation.","code":""},{"path":"https://philchalmers.github.io/Spower/articles/Spower_TypeSM.html","id":"manual-specification","dir":"Articles","previous_headings":"Type S errors via simulation","what":"Manual specification","title":"Type M and Type S errors","text":"manual implementation, user write data generation analysis components single function, use () loop required generate analyse experiment significant pp-value observed. observed, () loop terminated generated data matches conditional significance criterion, point subsequent analyses relevant compliment Type S error (correct sign decision) returned logical conditional power reflected output. output Spower(), power information reflects estimated probability correct sign decision made given “significance” observed, 1−power1-power provides estimate associated Type S error (probability incorrect sign given significance). can seen, 0.9241 probability making correct sign decision true effect, complimentary probability estimate 0.0759 making Type S error. Spower, ’s course possible evaluate input properties associated power values. instance, suppose wish know requisite sample size Type S errors made little frequency (hence, high conditional sign power). suppose want make Type S error, say, 1/100 times significant effect observed. following code evaluates obtain nn estimate. Hence, one need sample size approximately 48 per group order Type S error approximately 1%.","code":"l_two.t_correct.sign <- function(n, mean, mu = 0, alpha = .05, ...){     while(TRUE){         g1 <- rnorm(n)         g2 <- rnorm(n, mean=mean)         out <- t.test(g2, g1, mu=mu, ...)         if(out$p.value < alpha) break   # if \"significant\" then break while() loop     }     mean_diff <- unname(out$estimate[1] - out$estimate[2])     mean_diff > mu                      # return TRUE if the correct sign is observed } l_two.t_correct.sign(n=15, mean=.2) |> Spower() ##  ## Execution time (H:M:S): 00:00:22 ## Design conditions:  ##  ## # A tibble: 1 × 4 ##       n  mean sig.level power ##   <dbl> <dbl>     <dbl> <lgl> ## 1    15   0.2      0.05 NA    ##  ## Estimate of power: 0.924 ## 95% Confidence Interval: [0.919, 0.929] typeS <- .01 l_two.t_correct.sign(n=NA, mean=.2) |>      Spower(power=1-typeS, interval=c(10, 200)) ##  ## Execution time (H:M:S): 00:00:18 ## Design conditions:  ##  ## # A tibble: 1 × 4 ##       n  mean sig.level power ##   <dbl> <dbl>     <dbl> <dbl> ## 1    NA   0.2      0.05  0.99 ##  ## Estimate of n: 47.7 ## 95% Predicted Confidence Interval: [44.1, 51.7]"},{"path":"https://philchalmers.github.io/Spower/articles/Spower_TypeSM.html","id":"implementation-using-built-in-p_t-test-function","dir":"Articles","previous_headings":"Type S errors via simulation","what":"Implementation using built-in p_t.test() function","title":"Type M and Type S errors","text":"Alternatively, simulation function analysis already appear context package definition Spower’s internally defined p_* functions can used place complete manual implementation. beneficial data generation analysis components need written front-end user, potentially avoiding implementation issues using previously defined simulation experiment code. reminder, default p_* functions package always return pp-value null hypothesis specified canonical way power analysis via simulation explored (cf. posterior probability approaches). However, simulation experiment functions also contain logical argument return_analysis, set TRUE return complete analysis object instead just extracted pp-value (commonly element p.value, though please use functions like str() inspect fully). Type M/S errors multiple components clearly required, therefore information extracted analysis objects directly accommodate. demonstrate, built-function p_t.test() used return_analysis = TRUE argument. simulation experiment still follows () loop logic ensure “significance” first flagged, however internal function definitions now provide data generation analyses front-end user . Setting sample size N=30N=30 (hence, n=15) leads following power estimates. possible recommended use return_analysis approach simulation experiments defined within package well tested. trade-, higher-level functions R, often slightly overhead user-defined functions, though course latter approach comes cost safety.","code":"l_two.t_correct.sign <- function(n, mean, mu = 0, alpha = .05, ...){     while(TRUE){         # return_analysis argument used to return model object         out <- p_t.test(n=n, d=mean, mu=mu, return_analysis=TRUE, ...)         if(out$p.value < alpha) break     }     mean_diff <- unname(out$estimate[1] - out$estimate[2])     mean_diff > mu } l_two.t_correct.sign(100, mean=.5) ## [1] TRUE l_two.t_correct.sign(n=15, mean=.2) |> Spower() ##  ## Execution time (H:M:S): 00:00:29 ## Design conditions:  ##  ## # A tibble: 1 × 4 ##       n  mean sig.level power ##   <dbl> <dbl>     <dbl> <lgl> ## 1    15   0.2      0.05 NA    ##  ## Estimate of power: 0.925 ## 95% Confidence Interval: [0.920, 0.930]"},{"path":"https://philchalmers.github.io/Spower/articles/Spower_TypeSM.html","id":"type-m-errors-via-simulation","dir":"Articles","previous_headings":"","what":"Type M errors via simulation","title":"Type M and Type S errors","text":"Continuing two-sample tt-test structure, suppose ’re interested minimizing Type M errors ensure significant results weren’t due higher sampling variability, ultimately resulting significance raised unreasonably large effect sizes estimates observed. purpose power demonstration, suppose “unreasonably large” defined ratio absolute (standardized) mean difference two-sample tt-test, flagged significant, larger three times value true (standardized) mean difference (hence, M.ratio = 3). Note focusing M.ratio = 3 provides sufficient means study Type M errors using cut-logic define power, also possible store observed MM values inspection , can done Spower list data.frame returned supplied experiment. behave correctly, however, output information relevant power computations (probability values/logicals) must explicitly specified using Spower(..., select) values returned simulation stored summarised. , first step define experiment using conditional pp-value logic nested within () loop, followed power (extra) criteria interest. N=50N=50 per group “small” standardized effect size .2 gives following. case, power represents probability , given significant result observed, resulting MM ratio less cutoff 3 (hence, less three times true effect size). compliment, reflects Type M error, 0.139, indeed quite high approximately 14% samples flagged significant needed rather large observed effects indicate sample “unusual” statistical significance sense. respect distribution observed MM values , can extracted using SimResults(). Notice plotted, rejection magnitudes normally distributed, expected given nature conditional simulation experiment.  Finally, increasing sample size greatly helps Type M issues, seen doubling sample size . Type M error M.ratio=3M.ratio = 3 cutoff now approximately 1% significant results due overly large effect size estimate. , distributional properties observed MM values can extracted analyzed need arise.  Type M errors course intimately related precision criteria power analyses, sense alternative way looking power planning help relying “extreme” observations. Personally, notion thinking terms “ratios relative true population effect size” feels somewhat unnatural, though point obviously important seeing significance flagged unreasonably large effect sizes occur indeed troubling (e.g., replication issues). contrast , recommend using precision-based power planning focusing explicitly Type M errors power planning seems natural, obtaining greater precision target estimates necessarily decrease number Type M error “extreme” “underwhelming” sense effect size estimates (ladder Type M errors address focus non-significant results definition). importantly, precision criteria framed metric parameters relevant data analyst rather metricless effect size ratio, general natural specify.","code":"l_two.t_typeM <- function(n, mean, mu = 0,                            alpha = .05, M.ratio = 3, ...){     while(TRUE){         # return_analysis argument used to return model object         out <- p_t.test(n=n, d=mean, mu=mu, return_analysis=TRUE, ...)         if(out$p.value < alpha) break     }     diff <- unname(out$estimate[1] - out$estimate[2])     M <- abs(diff)/mean     # return data.frame, where \"retain\" indicates the (logical) power information     data.frame(retain=M < M.ratio, M=M) } # only use the \"retain\" information to compute power, though store the rest l_two.t_typeM(n=50, mean=.2) |> Spower(select='retain') -> typeM typeM ##  ## Execution time (H:M:S): 00:00:19 ## Design conditions:  ##  ## # A tibble: 1 × 4 ##       n  mean sig.level power ##   <dbl> <dbl>     <dbl> <lgl> ## 1    50   0.2      0.05 NA    ##  ## Estimate of power: 0.861 ## 95% Confidence Interval: [0.854, 0.868] results <- SimResults(typeM) results ## # A tibble: 10,000 × 5 ##        n  mean sig.level retain     M ##    <dbl> <dbl>     <dbl> <lgl>  <dbl> ##  1    50   0.2      0.05 TRUE    2.47 ##  2    50   0.2      0.05 TRUE    2.44 ##  3    50   0.2      0.05 TRUE    2.57 ##  4    50   0.2      0.05 TRUE    2.52 ##  5    50   0.2      0.05 TRUE    2.16 ##  6    50   0.2      0.05 FALSE   3.59 ##  7    50   0.2      0.05 TRUE    1.78 ##  8    50   0.2      0.05 TRUE    2.21 ##  9    50   0.2      0.05 TRUE    2.79 ## 10    50   0.2      0.05 FALSE   3.38 ## # ℹ 9,990 more rows with(results, c(mean=mean(M), SD=sd(M), min=min(M), max=max(M))) ##      mean        SD       min       max  ## 2.4863313 0.4696919 1.6198006 5.3105530 hist(results$M, 30) # double the total sample size l_two.t_typeM(n=100, mean=.2) |> Spower(select='retain') -> typeM2 typeM2 ##  ## Execution time (H:M:S): 00:00:14 ## Design conditions:  ##  ## # A tibble: 1 × 4 ##       n  mean sig.level power ##   <dbl> <dbl>     <dbl> <lgl> ## 1   100   0.2      0.05 NA    ##  ## Estimate of power: 0.991 ## 95% Confidence Interval: [0.989, 0.993] last <- getLastSpower() 1 - last$power ## [1] 0.0088 results <- SimResults(typeM2) results ## # A tibble: 10,000 × 5 ##        n  mean sig.level retain     M ##    <dbl> <dbl>     <dbl> <lgl>  <dbl> ##  1   100   0.2      0.05 TRUE    1.43 ##  2   100   0.2      0.05 TRUE    1.45 ##  3   100   0.2      0.05 TRUE    1.83 ##  4   100   0.2      0.05 TRUE    1.72 ##  5   100   0.2      0.05 TRUE    1.98 ##  6   100   0.2      0.05 TRUE    1.61 ##  7   100   0.2      0.05 TRUE    2.01 ##  8   100   0.2      0.05 TRUE    2.52 ##  9   100   0.2      0.05 TRUE    1.48 ## 10   100   0.2      0.05 TRUE    1.49 ## # ℹ 9,990 more rows with(results, c(mean=mean(M), SD=sd(M), min=min(M), max=max(M))) ##      mean        SD       min       max  ## 1.8333941 0.3667748 1.2174419 4.4615467 hist(results$M, 30)"},{"path":"https://philchalmers.github.io/Spower/articles/gpower_examples.html","id":"correlation","dir":"Articles","previous_headings":"","what":"Correlation","title":"G*Power examples evaluated with Spower","text":"Correlation analyses require evaluating power associated hypotheses H0:ρ−ρ0=0H_0:\\, \\rho-\\rho_0=0H1:ρ−ρ0≠0H_1:\\, \\rho-\\rho_0\\ne 0 ρ\\rho population correlation ρ0\\rho_0 null hypothesis constant.","code":""},{"path":"https://philchalmers.github.io/Spower/articles/gpower_examples.html","id":"example-3-3-difference-from-constant-one-sample-case","dir":"Articles","previous_headings":"Correlation","what":"Example 3.3; Difference from constant (one sample case)","title":"G*Power examples evaluated with Spower","text":"following estimates sample size required reject H0:ρ0=.60H_0:\\, \\rho_0=.60 correlation analysis 1−β=.951-\\beta=.95 probability ρ=.65\\rho=.65. G*power estimates nn 1929 using Fisher zz-transformation approximation, used Spower definition well.","code":"p_r(n = NA, r = .65, rho = .60) |>      Spower(power = .95, interval=c(500,3000)) ##  ## Execution time (H:M:S): 00:00:21 ## Design conditions:  ##  ## # A tibble: 1 × 5 ##       n     r   rho sig.level power ##   <dbl> <dbl> <dbl>     <dbl> <dbl> ## 1    NA  0.65   0.6      0.05  0.95 ##  ## Estimate of n: 1931.4 ## 95% Predicted Confidence Interval: [1901.1, 1958.2]"},{"path":"https://philchalmers.github.io/Spower/articles/gpower_examples.html","id":"test-against-constant-rho_00","dir":"Articles","previous_headings":"Correlation","what":"Test against constant ρ0=0\\rho_0=0","title":"G*Power examples evaluated with Spower","text":"canonical version hypotheses involving correlation coefficients appear rho0=0rho_0=0, require Fisher approximation. instance, power associated ρ=.3\\rho = .3 100 pairs observations, tested ρ0=0\\rho_0=0, results following. Next, sample sample size estimate required reject H0:ρ0=0H_0:\\, \\rho_0=0 correlation analysis 1−β=.951-\\beta=.95 probability ρ=.3\\rho=.3 expressed G*power 3.1 provides estimate pwr package case, comparison presented .","code":"p_r(n = 100, r = .3) |> Spower() ##  ## Execution time (H:M:S): 00:00:11 ## Design conditions:  ##  ## # A tibble: 1 × 4 ##       n     r sig.level power ##   <dbl> <dbl>     <dbl> <lgl> ## 1   100   0.3      0.05 NA    ##  ## Estimate of power: 0.861 ## 95% Confidence Interval: [0.854, 0.867] p_r(n = NA, r = .3) |>      Spower(power = .95, interval=c(50,1000)) ##  ## Execution time (H:M:S): 00:00:17 ## Design conditions:  ##  ## # A tibble: 1 × 4 ##       n     r sig.level power ##   <dbl> <dbl>     <dbl> <dbl> ## 1    NA   0.3      0.05  0.95 ##  ## Estimate of n: 138.3 ## 95% Predicted Confidence Interval: [136.1, 140.4] pwr::pwr.r.test(r=.3, power=.95, n=NULL) ##  ##      approximate correlation power calculation (arctangh transformation)  ##  ##               n = 137.8 ##               r = 0.3 ##       sig.level = 0.05 ##           power = 0.95 ##     alternative = two.sided"},{"path":"https://philchalmers.github.io/Spower/articles/gpower_examples.html","id":"example-27-3-correlation---inequality-of-two-independent-pearson-rs","dir":"Articles","previous_headings":"Correlation","what":"Example 27.3; Correlation - inequality of two independent Pearson r’s","title":"G*Power examples evaluated with Spower","text":"correlation two independent samples compared, p_2r() simulation can adopted. sample N1=206N_1=206 observations appeared first sample (r=.75r=.75), second sample (r=.88r=.88) contained N2=51N_2=51 observations (hence, ratio N2/N1=51/206N_2/N_1=51/206). results post-hoc/observed power G*power 3.1 returns power .726 context.","code":"p_2r(n=206, r.ab=.75, r.ab2=.88, n2_n1=51/206) |> Spower() ##  ## Execution time (H:M:S): 00:00:26 ## Design conditions:  ##  ## # A tibble: 1 × 5 ##       n  r.ab r.ab2 sig.level power ##   <dbl> <dbl> <dbl>     <dbl> <lgl> ## 1   206  0.75  0.88      0.05 NA    ##  ## Estimate of power: 0.727 ## 95% Confidence Interval: [0.718, 0.735]"},{"path":"https://philchalmers.github.io/Spower/articles/gpower_examples.html","id":"example-28-3-1-correlation---inequality-of-two-dependent-pearson-rs-no-common-index","dir":"Articles","previous_headings":"Correlation","what":"Example 28.3.1; Correlation - inequality of two dependent Pearson r’s (no common index)","title":"G*Power examples evaluated with Spower","text":"following two examples assume correlation matrix population structure. common index tests elements required, common index form 3×33\\times 3 subset needed. Evaluating null hypothesis H0:ρab=ρcdH_0: \\rho_{ab} = \\rho_{cd} case ρab=.5\\rho_{ab} = .5 ρcd=.8\\rho_{cd} = .8 can explored using p_2r() function. following performs priori analyses determine sample size (NN) required achieve 80% power using Steiger’s (1980) inferential zz approach. G*power 3.1 returns required sample size N=886N=886.","code":"# From Gpower 3.1 manual Cp <- matrix(c(1, .5, .4, .1,                 .5, 1, .2, -.4,                 .4, .2, 1, .8,                 .1, -.4, .8, 1), 4, 4)  # rearrange rows for convenience Cp <- Cp[c(1,4,2,3), c(1,4,2,3)] colnames(Cp) <- rownames(Cp) <- c('x1', 'y1', 'x2', 'y2') Cp ##     x1   y1   x2  y2 ## x1 1.0  0.1  0.5 0.4 ## y1 0.1  1.0 -0.4 0.8 ## x2 0.5 -0.4  1.0 0.2 ## y2 0.4  0.8  0.2 1.0 p_2r(n=NA, r.ab=.1, r.ac=.5, r.ad=.4, r.bc=-.4, r.bd=.8, r.cd=.2,       two.tailed=FALSE) |> Spower(power = .80, interval=c(500, 2000)) ##  ## Execution time (H:M:S): 00:01:35 ## Design conditions:  ##  ## # A tibble: 1 × 9 ##       n  r.ab  r.ac  r.ad  r.bd  r.cd two.tailed sig.level power ##   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <lgl>          <dbl> <dbl> ## 1    NA   0.1   0.5   0.4   0.8   0.2 FALSE           0.05   0.8 ##  ## Estimate of n: 886.2 ## 95% Predicted Confidence Interval: [875.3, 897.3]"},{"path":"https://philchalmers.github.io/Spower/articles/gpower_examples.html","id":"example-28-3-2-correlation---inequality-of-two-dependent-pearson-rs-common-index","dir":"Articles","previous_headings":"Correlation","what":"Example 28.3.2; Correlation - inequality of two dependent Pearson r’s (common index)","title":"G*Power examples evaluated with Spower","text":"information example Example 28.3.1, however assumed common index correlation measures instead complete overlap. , previous Cp object may subset see type correlation structure required common index setup. null instigation case H0:ρab=ρacH_0:\\rho_{ab} = \\rho_{ac} ρab=.2\\rho_{ab} = .2 ρac=.4\\rho_{ac} = .4. Spower, equates following inputs, use Steiger’s (1980) inferential zz approach default. G*power 3.1 returns required sample size N=144N=144, interestingly slightly higher simulation version Spower. Providing N=144N=144 obtain power estimate gives following:","code":"Cp[c(4,3,1),c(4,3,1)] ##     y2  x2  x1 ## y2 1.0 0.2 0.4 ## x2 0.2 1.0 0.5 ## x1 0.4 0.5 1.0 p_2r(n=NA, r.ab=.4, r.ac=.2, r.bc=.5, two.tailed=FALSE) |>      Spower(power = .80, interval=c(50, 500)) ##  ## Execution time (H:M:S): 00:01:19 ## Design conditions:  ##  ## # A tibble: 1 × 7 ##       n  r.ab  r.ac  r.bc two.tailed sig.level power ##   <dbl> <dbl> <dbl> <dbl> <lgl>          <dbl> <dbl> ## 1    NA   0.4   0.2   0.5 FALSE           0.05   0.8 ##  ## Estimate of n: 134.7 ## 95% Predicted Confidence Interval: [133.1, 136.3] p_2r(n=144, r.ab=.4, r.ac=.2, r.bc=.5, two.tailed=FALSE) |> Spower() ##  ## Execution time (H:M:S): 00:00:22 ## Design conditions:  ##  ## # A tibble: 1 × 7 ##       n  r.ab  r.ac  r.bc two.tailed sig.level power ##   <dbl> <dbl> <dbl> <dbl> <lgl>          <dbl> <lgl> ## 1   144   0.4   0.2   0.5 FALSE           0.05 NA    ##  ## Estimate of power: 0.831 ## 95% Confidence Interval: [0.824, 0.839]"},{"path":"https://philchalmers.github.io/Spower/articles/gpower_examples.html","id":"example-28-3-3-sensitivity-analysis","dir":"Articles","previous_headings":"Correlation","what":"Example 28.3.3; sensitivity analysis","title":"G*Power examples evaluated with Spower","text":"also possible perform sensitivity analyses rather priori power analysis. fixes N=144N=144, r.ac solved obtain 80% power. G*power 3.1 reports ρac=0.047702\\rho_{ac} = 0.047702, confirmed using simulation . Obtaining similar estimate using Spower() requires following sensitivity analysis structure: example, Spower G*power 3.1 seem agree.","code":"# confirm solution obtained by G*power (post hoc power estimate) p_2r(n=144, r.ab=.4, r.ac=0.047702, r.bc=-0.6, two.tailed=FALSE) |> Spower() ##  ## Execution time (H:M:S): 00:00:22 ## Design conditions:  ##  ## # A tibble: 1 × 6 ##       n  r.ab     r.ac two.tailed sig.level power ##   <dbl> <dbl>    <dbl> <lgl>          <dbl> <lgl> ## 1   144   0.4 0.047702 FALSE           0.05 NA    ##  ## Estimate of power: 0.815 ## 95% Confidence Interval: [0.808, 0.823] # note that interval is specified as c(upper, lower) as higher values # of r.ac result in lower power in this context p_2r(n=144, r.ab=.4, r.ac=NA, r.bc=-0.6, two.tailed=FALSE) |>      Spower(power = .80, interval=c(.4, .001)) ##  ## Execution time (H:M:S): 00:01:38 ## Design conditions:  ##  ## # A tibble: 1 × 6 ##       n  r.ab  r.ac two.tailed sig.level power ##   <dbl> <dbl> <dbl> <lgl>          <dbl> <dbl> ## 1   144   0.4    NA FALSE           0.05   0.8 ##  ## Estimate of r.ac: 0.048 ## 95% Predicted Confidence Interval: [0.046, 0.050]"},{"path":"https://philchalmers.github.io/Spower/articles/gpower_examples.html","id":"example-16-3-point-biserial-correlation","dir":"Articles","previous_headings":"Correlation","what":"Example 16.3; Point-biserial correlation","title":"G*Power examples evaluated with Spower","text":"following estimates sample size required obtain power 1−β=.951-\\beta=.95 given r=.25r=.25 true correlation, evaluated null H0:ρ≤0H_0:\\rho\\le0 (hence, one-tailed) α=.05\\alpha = .05. G*power gives result N=164N=164. Relatedly, one can specify dd, Cohen’s standardized mean-difference effect size, instead rr since dd converted rr inside p_t.test() function.","code":"# solution per group out <- p_t.test(r = .25, n = NA, two.tailed=FALSE) |>      Spower(power = .95, interval=c(50, 200)) out ##  ## Execution time (H:M:S): 00:00:10 ## Design conditions:  ##  ## # A tibble: 1 × 5 ##       n     r two.tailed sig.level power ##   <dbl> <dbl> <lgl>          <dbl> <dbl> ## 1    NA  0.25 FALSE           0.05  0.95 ##  ## Estimate of n: 81.7 ## 95% Predicted Confidence Interval: [79.1, 85.4] # total sample size required ceiling(out$n) * 2 ## [1] 164"},{"path":"https://philchalmers.github.io/Spower/articles/gpower_examples.html","id":"example-31-3-tetrachoric-correlation","dir":"Articles","previous_headings":"Correlation","what":"Example 31.3; tetrachoric correlation","title":"G*Power examples evaluated with Spower","text":"tetrachoric polychoric correlations, experiment definition p_r.cat() can used. requires specifying associated τ\\tau threshold coefficients population normal truncation processes, well bivariate correlation prior truncation. τ\\tau values correspond along assumed normal p.d.f. truncation took place, XX variable can seen following graphic. Finally, assuming untruncated r=0.2399846r=0.2399846, Score test used evaluate null hypothesis interest (score = TRUE), sample size required reject null hypothesis tetrachoric correlation less equal 0 population (one-tailed) expressed G*power gives n=463n=463, though uses SE value null (Score test). p_r.cat(), hand, defaults Wald approach SE maximum-likelihood estimate (MLE); hence, score = FALSE default. switch, use score=TRUE, though note requires twice many computations second set data generated analyzed r=r0r=r_0 obtain required SE0SE_0 estimate.","code":"F <- matrix(c(203, 186, 167, 374), 2, 2) N <- sum(F) (marginal.x <- colSums(F)/N) ## [1] 0.4183 0.5817 (marginal.y <- rowSums(F)/N) ## [1] 0.3978 0.6022 # converted to intercepts tauX <- qnorm(1-marginal.x)[2] tauY <- qnorm(1-marginal.y)[2] c(tauX, tauY) ## [1] -0.2063 -0.2589 p_r.cat(n=NA, r=0.2399846, tauX=tauX, tauY=tauY,          score=TRUE, two.tailed=FALSE) |>      Spower(power = .95, interval=c(100, 500),             parallel=TRUE, check.interval=FALSE) ##  ## Design conditions:  ##  ## # A tibble: 1 × 8 ##       n     r   tauX   tauY score two.tailed sig.level power ##   <dbl> <dbl> <dbl> <dbl> <lgl> <lgl>          <dbl> <dbl> ## 1    NA 0.240 -0.206 -0.259 FALSE FALSE           0.05  0.95 ##  ## Estimate of n: 462.9 ## 95% Prediction Interval: [458.5, 466.6]"},{"path":[]},{"path":"https://philchalmers.github.io/Spower/articles/gpower_examples.html","id":"example-4-3-one-sample-proportion-tests","dir":"Articles","previous_headings":"Proportions","what":"Example 4.3; One sample proportion tests","title":"G*Power examples evaluated with Spower","text":"one sample, one-tailed proportion test given data generated population π=.80\\pi = .80 tested null hypothesis H0:π0≤.65H_0:\\pi_0\\le.65 n=20n=20 presented following. Note G*power requires term gg specified proportion difference null instead (hence, g=.80−.65=.15g = .80-.65=.15), though p_prop.teset() accepts null alternative probability values -. G*power gives estimate 1−β=.41121-\\beta=.4112. Note p_prop.test(), Fisher’s exact version test also supported passing argument exact = TRUE.","code":"pi <- .65 g <- .15 p <- pi + g  p_prop.test(n=20, prop=p, pi=pi, two.tailed=FALSE) |>     Spower() ##  ## Execution time (H:M:S): 00:00:04 ## Design conditions:  ##  ## # A tibble: 1 × 4 ##       n two.tailed sig.level power ##   <dbl> <lgl>          <dbl> <lgl> ## 1    20 FALSE           0.05 NA    ##  ## Estimate of power: 0.416 ## 95% Confidence Interval: [0.406, 0.425] # Fisher exact test p_prop.test(n=20, prop=p, pi=pi, exact=TRUE,              two.tailed=FALSE) |> Spower() ##  ## Execution time (H:M:S): 00:00:04 ## Design conditions:  ##  ## # A tibble: 1 × 5 ##       n two.tailed exact sig.level power ##   <dbl> <lgl>      <lgl>     <dbl> <lgl> ## 1    20 FALSE      TRUE       0.05 NA    ##  ## Estimate of power: 0.411 ## 95% Confidence Interval: [0.402, 0.421]"},{"path":"https://philchalmers.github.io/Spower/articles/gpower_examples.html","id":"example-22-1-wilcoxon-signed-rank-test","dir":"Articles","previous_headings":"Proportions","what":"Example 22.1; Wilcoxon signed-rank test","title":"G*Power examples evaluated with Spower","text":"following performed one-sample, one-tailed Wilcoxon signed rank test given N=649N=649, d=.1d=.1, parent distribution assumed follow Normal/Gaussian shape (default). G*power gives power estimate .800. following partially recreates simulation results Figure 29 (partially extracted Shieh, Jan, Randles, 2007) Gaussian(μ\\mu,1) distribution varying sample sizes effect sizes. target obtain “approximate power 1−β=.801-\\beta = .80”, though sample sizes decided upon specified. Spower()’s stochastic root-solving approach likely get closer optimal NN estimates target analyses.","code":"p_wilcox.test(n=649, d=.1, type='one.sample', two.tailed=FALSE) |>      Spower() ##  ## Execution time (H:M:S): 00:00:21 ## Design conditions:  ##  ## # A tibble: 1 × 6 ##       n     d type       two.tailed sig.level power ##   <dbl> <dbl> <chr>      <lgl>          <dbl> <lgl> ## 1   649   0.1 one.sample FALSE           0.05 NA    ##  ## Estimate of power: 0.812 ## 95% Confidence Interval: [0.805, 0.820] # For Gaussian(d,1) out <- p_wilcox.test(type='one.sample', two.tailed=FALSE) |>      SpowerBatch(n=c(649, 164, 42, 20, 12, 9),                 d=c(.1, .2, .4, .6, .8, 1.0), replications = 50000, fully.crossed=FALSE) as.data.frame(out) ##     n   d       type two.tailed sig.level  power CI_2.5 CI_97.5 ## 1 649 0.1 one.sample      FALSE      0.05 0.8012 0.7977  0.8047 ## 2 164 0.2 one.sample      FALSE      0.05 0.8027 0.7992  0.8062 ## 3  42 0.4 one.sample      FALSE      0.05 0.8043 0.8009  0.8078 ## 4  20 0.6 one.sample      FALSE      0.05 0.8070 0.8035  0.8105 ## 5  12 0.8 one.sample      FALSE      0.05 0.8018 0.7983  0.8053 ## 6   9 1.0 one.sample      FALSE      0.05 0.8467 0.8435  0.8498"},{"path":"https://philchalmers.github.io/Spower/articles/gpower_examples.html","id":"laplacemu-1-version","dir":"Articles","previous_headings":"Proportions > Example 22.1; Wilcoxon signed-rank test","what":"Laplace(μ\\mu, 1) version","title":"G*Power examples evaluated with Spower","text":"one-sample Wilcoxon signed rank test Laplace distribution parent. Note requires defining parent distribution manually, accepting arguments n d. G*power gives estimate .830, seems somewhat high (see ). following partially recreates simulation results Figure 29 Laplace(μ\\mu, 1) distribution varying sample sizes effect sizes. target obtain “approximate power 1−β=.801-\\beta = .80”, though sample sizes decided upon specified. Spower()’s stochastic root-solving approach likely get closer optimal NN estimates target analyses.","code":"library(extraDistr)  # generate data with scale 0-1 for d effect size to be same as mean # VAR = 2*b^2, so scale should be 1 = 2*b^2 -> sqrt(1/2) parent <- function(n, d, sigma=sqrt(1/2))      extraDistr::rlaplace(n, d, sigma=sigma)  p_wilcox.test(n=11, d=.8, parent1=parent, type='one.sample',               two.tailed=FALSE, correct = FALSE) |> Spower() ##  ## Execution time (H:M:S): 00:00:03 ## Design conditions:  ##  ## # A tibble: 1 × 7 ##       n     d type       correct two.tailed sig.level power ##   <dbl> <dbl> <chr>      <lgl>   <lgl>          <dbl> <lgl> ## 1    11   0.8 one.sample FALSE   FALSE           0.05 NA    ##  ## Estimate of power: 0.801 ## 95% Confidence Interval: [0.793, 0.809] # For Laplace(0,1) out <- p_wilcox.test(parent1=parent, type='one.sample',               two.tailed=FALSE) |>      SpowerBatch(n=c(419, 109, 31, 16, 11, 8),                 d=c(.1, .2, .4, .6, .8, 1.0), replications=50000, fully.crossed=FALSE) as.data.frame(out) ##     n   d       type two.tailed sig.level  power CI_2.5 CI_97.5 ## 1 419 0.1 one.sample      FALSE      0.05 0.8021 0.7986  0.8056 ## 2 109 0.2 one.sample      FALSE      0.05 0.7992 0.7957  0.8028 ## 3  31 0.4 one.sample      FALSE      0.05 0.8031 0.7996  0.8065 ## 4  16 0.6 one.sample      FALSE      0.05 0.8007 0.7972  0.8042 ## 5  11 0.8 one.sample      FALSE      0.05 0.8032 0.7998  0.8067 ## 6   8 1.0 one.sample      FALSE      0.05 0.7771 0.7735  0.7808"},{"path":"https://philchalmers.github.io/Spower/articles/gpower_examples.html","id":"example-5-3-two-dependent-proportions-test-mcnemars-test","dir":"Articles","previous_headings":"Proportions","what":"Example 5.3; Two dependent proportions test (McNemar’s test)","title":"G*Power examples evaluated with Spower","text":"following performs proportions test two dependent groups using McNemar’s test. data O’Brien (2002, p. 161-163). Alternatively, specifying inputs terms proportions rather odds ratio (=π12/π21=.08/.32=.25OR=\\pi_{12}/\\pi_{21}=.08/.32=.25) proportions discordant pairs (πD=π12+π21=.08+.32=.40\\pi_D=\\pi_{12} + \\pi_{21}=.08 + .32=.40) can supplied G*Power gives .839 (α=.032\\alpha = .032). Slightly power can achieved using continuity correction, though general recommended practice.","code":"obrien2002 <- matrix(c(.54, .32, .08, .06), 2, 2,                      dimnames = list('Treatment' = c('Yes', 'No'),                                     'Standard' = c('Yes', 'No'))) obrien2002 ##          Standard ## Treatment  Yes   No ##       Yes 0.54 0.08 ##       No  0.32 0.06 p_mcnemar.test(n=50, prop=obrien2002, two.tailed=FALSE) |> Spower() ##  ## Execution time (H:M:S): 00:00:03 ## Design conditions:  ##  ## # A tibble: 1 × 4 ##       n two.tailed sig.level power ##   <dbl> <lgl>          <dbl> <lgl> ## 1    50 FALSE           0.05 NA    ##  ## Estimate of power: 0.836 ## 95% Confidence Interval: [0.828, 0.843] OR <- obrien2002[1,2] / obrien2002[2,1] disc <- obrien2002[1,2] + obrien2002[2,1] p_mcnemar.test(n=50, OR=OR, prop.disc=disc, two.tailed=FALSE) |> Spower() ##  ## Execution time (H:M:S): 00:00:03 ## Design conditions:  ##  ## # A tibble: 1 × 4 ##       n two.tailed sig.level power ##   <dbl> <lgl>          <dbl> <lgl> ## 1    50 FALSE           0.05 NA    ##  ## Estimate of power: 0.841 ## 95% Confidence Interval: [0.834, 0.848] p_mcnemar.test(n=50, prop=obrien2002, two.tailed=FALSE, correct=FALSE) |> Spower() ##  ## Execution time (H:M:S): 00:00:03 ## Design conditions:  ##  ## # A tibble: 1 × 5 ##       n two.tailed correct sig.level power ##   <dbl> <lgl>      <lgl>       <dbl> <lgl> ## 1    50 FALSE      FALSE        0.05 NA    ##  ## Estimate of power: 0.887 ## 95% Confidence Interval: [0.881, 0.893]"},{"path":[]},{"path":"https://philchalmers.github.io/Spower/articles/gpower_examples.html","id":"example-13-1","dir":"Articles","previous_headings":"Multiple Linear Regression (Fixed IVs)","what":"Example 13.1","title":"G*Power examples evaluated with Spower","text":"Evaluating R2=.1R^2=.1 generated data linear regression model given null hypothesis H0:R02=0H_0:R^2_0=0. evaluated using N=95N=95 observations k=5k=5 predictor variables gives estimate. G*power gives 1−β=.6731-\\beta = .673.","code":"p_lm.R2(n=95, R2=.1, k=5) |> Spower() ##  ## Execution time (H:M:S): 00:00:43 ## Design conditions:  ##  ## # A tibble: 1 × 5 ##       n    R2     k sig.level power ##   <dbl> <dbl> <dbl>     <dbl> <lgl> ## 1    95   0.1     5      0.05 NA    ##  ## Estimate of power: 0.664 ## 95% Confidence Interval: [0.655, 0.674]"},{"path":"https://philchalmers.github.io/Spower/articles/gpower_examples.html","id":"example-14-3","dir":"Articles","previous_headings":"Multiple Linear Regression (Fixed IVs)","what":"Example 14.3","title":"G*Power examples evaluated with Spower","text":"Similarly, comparing nested models changes R2R^2. following, note k total IVs (case, 9), k.R2_0 number IVs baseline model (case, 5). α=.01\\alpha=.01 change ΔR2=.05\\Delta R^2=.05 baseline R02=.25R^2_0=.25 gives G*power gives 1−β=.2411-\\beta = .241. Solving sample size achieve 80% power G*power gives n=242n = 242.","code":"p_lm.R2(n=90, R2=.3, k=9, R2_0=.25, k.R2_0=5) |> Spower(sig.level=.01) ##  ## Execution time (H:M:S): 00:00:56 ## Design conditions:  ##  ## # A tibble: 1 × 7 ##       n    R2     k  R2_0 k.R2_0 sig.level power ##   <dbl> <dbl> <dbl> <dbl>  <dbl>     <dbl> <lgl> ## 1    90   0.3     9  0.25      5      0.01 NA    ##  ## Estimate of power: 0.238 ## 95% Confidence Interval: [0.230, 0.247] p_lm.R2(n=NA, R2=.3, R2_0 = .25, k=9, k.R2_0=5) |>          Spower(sig.level=.01, power=.8, interval=c(100, 400)) ##  ## Execution time (H:M:S): 00:03:06 ## Design conditions:  ##  ## # A tibble: 1 × 7 ##       n    R2     k  R2_0 k.R2_0 sig.level power ##   <dbl> <dbl> <dbl> <dbl>  <dbl>     <dbl> <dbl> ## 1    NA   0.3     9  0.25      5      0.01   0.8 ##  ## Estimate of n: 242.6 ## 95% Predicted Confidence Interval: [240.5, 244.6]"},{"path":"https://philchalmers.github.io/Spower/articles/gpower_examples.html","id":"example-14-3b","dir":"Articles","previous_headings":"Multiple Linear Regression (Fixed IVs)","what":"Example 14.3b","title":"G*Power examples evaluated with Spower","text":"Nested model comparison changes R2R^2 models 12 IVs versus 9 IVs. Requires specification Rresidual2R^2_{residual}. G*power gives 1−β=.7671-\\beta = .767.","code":"p_lm.R2(n=200, R2=.16, R2_0 = .1, k=12, k.R2_0=9, R2.resid=.8) |>      Spower(sig.level=.01) ##  ## Execution time (H:M:S): 00:01:17 ## Design conditions:  ##  ## # A tibble: 1 × 8 ##       n    R2     k  R2_0 k.R2_0 R2.resid sig.level power ##   <dbl> <dbl> <dbl> <dbl>  <dbl>    <dbl>     <dbl> <lgl> ## 1   200  0.16    12   0.1      9      0.8      0.01 NA    ##  ## Estimate of power: 0.756 ## 95% Confidence Interval: [0.748, 0.765]"},{"path":[]},{"path":"https://philchalmers.github.io/Spower/articles/gpower_examples.html","id":"example-7-3","dir":"Articles","previous_headings":"Multiple Linear Regression (Random IVs)","what":"Example 7.3","title":"G*Power examples evaluated with Spower","text":"Example 13.1 , however assuming IVs randomly sampled instead fixed. G*power gives 0.662 using one-tailed test criterion.","code":"p_lm.R2(n=95, R2=.1, k=5, fixed=FALSE) |> Spower() ##  ## Execution time (H:M:S): 00:00:16 ## Design conditions:  ##  ## # A tibble: 1 × 6 ##       n    R2     k fixed sig.level power ##   <dbl> <dbl> <dbl> <lgl>     <dbl> <lgl> ## 1    95   0.1     5 FALSE      0.05 NA    ##  ## Estimate of power: 0.659 ## 95% Confidence Interval: [0.650, 0.669]"},{"path":[]},{"path":"https://philchalmers.github.io/Spower/articles/gpower_examples.html","id":"example-12-3","dir":"Articles","previous_headings":"Simple linear regression","what":"Example 12.3","title":"G*Power examples evaluated with Spower","text":"Evaluate post-hoc power simple linear regression model null hypothesis H0:β1=0H_0:\\beta_1=0 given σx=7.5\\sigma_x = 7.5, σy\\sigma_y, β1=−0.0667\\beta_1=-0.0667, N=100N=100. G*power returns power estimate 1−β=0.23891-\\beta = 0.2389.","code":"p_slr(n=100, beta=-0.0667, sd_x=7.5, sd_y = 4) |> Spower() ##  ## Execution time (H:M:S): 00:00:30 ## Design conditions:  ##  ## # A tibble: 1 × 5 ##       n  sd_x  sd_y sig.level power ##   <dbl> <dbl> <dbl>     <dbl> <lgl> ## 1   100   7.5     4      0.05 NA    ##  ## Estimate of power: 0.243 ## 95% Confidence Interval: [0.234, 0.251]"},{"path":[]},{"path":"https://philchalmers.github.io/Spower/articles/gpower_examples.html","id":"example-10-3","dir":"Articles","previous_headings":"Fixed effects ANOVA - One way (F-test)","what":"Example 10.3","title":"G*Power examples evaluated with Spower","text":"One-way ANOVA example solve nn per group (k=10k=10), using Cohen’s f=.25f=.25, achieve power 1−β=.951-\\beta=.95. G*power gives estimate n=39n=39. Fixing n=200n=200 total (hence, n=200/k=20n=200/k=20) performing compromise analysis assuming q=βα=1q=\\frac{\\beta}{\\alpha}=1, G*Power gives α=β=0.159\\alpha=\\beta=0.159.","code":"p_anova.test(n=NA, k=10, f=.25) |>  Spower(power=.95, interval=c(20, 300)) ##  ## Execution time (H:M:S): 00:00:23 ## Design conditions:  ##  ## # A tibble: 1 × 5 ##       n     k     f sig.level power ##   <dbl> <dbl> <dbl>     <dbl> <dbl> ## 1    NA    10  0.25      0.05  0.95 ##  ## Estimate of n: 38.7 ## 95% Predicted Confidence Interval: [38.1, 39.2] p_anova.test(n=20, k=10, f=.25) |> Spower(beta_alpha=1, replications=30000) ##  ## Execution time (H:M:S): 00:00:44 ## Design conditions:  ##  ## # A tibble: 1 × 6 ##       n     k     f sig.level power beta_alpha ##   <dbl> <dbl> <dbl>     <dbl> <lgl>      <dbl> ## 1    20    10  0.25        NA NA             1 ##  ## Estimate of Type I error rate (alpha/sig.level): 0.160 ## 95% Confidence Interval: [0.156, 0.164] ##  ## Estimate of power (1-beta): 0.840 ## 95% Confidence Interval: [0.836, 0.844]"},{"path":"https://philchalmers.github.io/Spower/articles/gpower_examples.html","id":"t-test-linear-regression-two-groups","dir":"Articles","previous_headings":"","what":"tt-test: Linear regression (two groups)","title":"G*Power examples evaluated with Spower","text":"Test coefficients across distinct datasets similar form. case Y1=β0+β1X1+ϵY_1 = \\beta_0 + \\beta_1 X_1 + \\epsilonY2=β0*+β1*X2+ϵY_2 = \\beta_0^* + \\beta_1^* X_2 + \\epsilon null interest H0:β1−β1*=0H_0:\\, \\beta_1 - \\beta_1^* = 0 multiple linear regression model setup three variables Y=β0+β1X+β2S+β3(S⋅X)+ϵY = \\beta_0 + \\beta_1 X + \\beta_2 S + \\beta_3 (S\\cdot X) + \\epsilon Y=[Y1,Y2]Y=[Y_1, Y_2], X=[X1,X2]X = [X_1, X_2], SS binary indicator variable indicating whether observations second sample. S=0S = 0 first group’s parameterization recovered, S=1S=1 second group’s parameterization recovered potentially non-zero β2\\beta_2 reflects change intercept (β0*=β0+β2\\beta_0^* = \\beta_0 + \\beta_2) change slope second group reflected β3\\beta_3 (β1*=β1+β3\\beta_1^*=\\beta_1 + \\beta_3). Hence, null hypothesis two groups slope can evaluated using augmented model testing H0:β3=0H_0:\\, \\beta_3 = 0","code":""},{"path":"https://philchalmers.github.io/Spower/articles/gpower_examples.html","id":"example-17-3-and-18-3","dir":"Articles","previous_headings":"tt-test: Linear regression (two groups)","what":"Example 17.3 and 18.3","title":"G*Power examples evaluated with Spower","text":"start defining population generating model replace gen_glm() function default p_glm(). generating function organized data.frame returned columns y, X, S, interaction effect reflects magnitude difference β\\beta coefficients across independent samples. demonstrate, post-hoc power described example G*Power following. priori power analysis achieve power .80 G*Power gives estimate nn 163 (therefore 256 second group given n2_n1).","code":"gen_twogroup <- function(n, dbeta, sdx1, sdx2, sigma, n2_n1 = 1, ...){     X1 <- rnorm(n, sd=sdx1)     X2 <- rnorm(n*n2_n1, sd=sdx2)     X <- c(X1, X2)     N <- length(X)     S <- c(rep(0, n), rep(1, N-n))     y <- dbeta * X*S + rnorm(N, sd=sigma)     dat <- data.frame(y, X, S)     dat } p_glm(formula=y~X*S, test=\"X:S = 0\",       n=28, n2_n1=44/28, sdx1=9.02914, sdx2=11.86779, dbeta=0.01592,       sigma=0.5578413, gen_fun=gen_twogroup) |> Spower() ##  ## Execution time (H:M:S): 00:00:35 ## Design conditions:  ##  ## # A tibble: 1 × 8 ##   test      sigma     n   sdx1   sdx2   dbeta sig.level power ##   <chr>     <dbl> <dbl>  <dbl>  <dbl>   <dbl>     <dbl> <lgl> ## 1 X:S = 0 0.55784    28 9.0291 11.868 0.01592      0.05 NA    ##  ## Estimate of power: 0.199 ## 95% Confidence Interval: [0.191, 0.207] p_glm(formula=y~X*S, test=\"X:S = 0\",       n=NA, n2_n1=44/28, sdx1=9.02914, sdx2=11.86779, dbeta=0.01592,       sigma=0.5578413, gen_fun=gen_twogroup) |>      Spower(power=.8, interval=c(100, 1000)) ##  ## Execution time (H:M:S): 00:01:58 ## Design conditions:  ##  ## # A tibble: 1 × 8 ##   test      sigma     n   sdx1   sdx2   dbeta sig.level power ##   <chr>     <dbl> <dbl>  <dbl>  <dbl>   <dbl>     <dbl> <dbl> ## 1 X:S = 0 0.55784    NA 9.0291 11.868 0.01592      0.05   0.8 ##  ## Estimate of n: 164.9 ## 95% Predicted Confidence Interval: [163.3, 166.8]"},{"path":[]},{"path":"https://philchalmers.github.io/Spower/articles/gpower_examples.html","id":"example-26-3-difference-from-constant-one-sample-case","dir":"Articles","previous_headings":"Variance tests","what":"Example 26.3; Difference from constant (one sample case)","title":"G*Power examples evaluated with Spower","text":"Solve nn variance ratio 1/1.5=2/31/1.5 = 2/3 using one-tailed variance ratio test, assuming target power 1−β=.801-\\beta=.80. G*power gives sample size 81.","code":"p_var.test(n=NA, vars=1, sigma2=1.5, two.tailed=FALSE) |>      Spower(power=.80, interval=c(10, 200)) ##  ## Execution time (H:M:S): 00:00:33 ## Design conditions:  ##  ## # A tibble: 1 × 6 ##       n  vars sigma2 two.tailed sig.level power ##   <dbl> <dbl>  <dbl> <lgl>          <dbl> <dbl> ## 1    NA     1    1.5 FALSE           0.05   0.8 ##  ## Estimate of n: 80.6 ## 95% Predicted Confidence Interval: [79.3, 82.2]"},{"path":"https://philchalmers.github.io/Spower/articles/gpower_examples.html","id":"example-15-3-two-sample-variance-test","dir":"Articles","previous_headings":"Variance tests","what":"Example 15.3; Two-sample variance test","title":"G*Power examples evaluated with Spower","text":"two-sample equality variance test equal sample sizes, G*Power gives estimate 193 per group.","code":"# solve n for variance ratio of 1/1.5 = 2/3, two.tailed, 80% power p_var.test(n=NA, vars=c(1, 1.5), two.tailed=TRUE) |>      Spower(power=.80, interval=c(50, 300)) ##  ## Execution time (H:M:S): 00:00:45 ## Design conditions:  ##  ## # A tibble: 1 × 4 ##       n two.tailed sig.level power ##   <dbl> <lgl>          <dbl> <dbl> ## 1    NA TRUE            0.05   0.8 ##  ## Estimate of n: 193.4 ## 95% Predicted Confidence Interval: [191.5, 195.4]"},{"path":"https://philchalmers.github.io/Spower/articles/gpower_examples.html","id":"t-tests","dir":"Articles","previous_headings":"","what":"t-tests","title":"G*Power examples evaluated with Spower","text":"Estimate sample size (nn) per group independent samples tt-test, one-tailed, medium effect size (d=0.5d=0.5), α=0.05\\alpha=0.05, 95% power (1−β=0.951-\\beta = 0.95), equal sample sizes (n2n1=1\\frac{n_2}{n_1}=1). G*power estimate 88 per group, Spower estimate 86.9348 95% CI [85.2011, 88.4739].","code":"(out <- p_t.test(n = NA, d = .5, two.tailed=FALSE) |>                  Spower(power = .95, interval=c(10,500))) ##  ## Execution time (H:M:S): 00:00:11 ## Design conditions:  ##  ## # A tibble: 1 × 5 ##       n     d two.tailed sig.level power ##   <dbl> <dbl> <lgl>          <dbl> <dbl> ## 1    NA   0.5 FALSE           0.05  0.95 ##  ## Estimate of n: 86.9 ## 95% Predicted Confidence Interval: [85.2, 88.5]"},{"path":"https://philchalmers.github.io/Spower/articles/gpower_examples.html","id":"example-19-3-paired-samples-t-test","dir":"Articles","previous_headings":"t-tests","what":"Example 19.3; Paired samples t-test","title":"G*Power examples evaluated with Spower","text":"Paired-samples tt-test, assuming generated difference repeated measures Cohen’s dr=.421637d_r=.421637 (e.g., unadjusted d=.4d=.4, rxy=.55r_{xy} = .55, results repeated dr=|μx−μy|σx2+σy2−2ρxyσxσyd_r=\\frac{|\\mu_x-\\mu_y|}{\\sqrt{\\sigma^2_x + \\sigma^2_y - 2\\rho_{xy}\\sigma_x\\sigma_y}}). G*power gives power estimate .832, though Cohen reported value closer .840. d=0.2828427d=0.2828427 leads case G*Power 3.1 gives estimate .500. answer question “many subjects need arrive power 0.832114 two-group design?” specified within Spower() n set NA. G*power reports around N=110*2=220N=110*2=220 pairs required, though estimated visually using interpolation.","code":"p_t.test(n=50 * 2, d=0.421637, type = 'paired') |> Spower(replications=50000) ##  ## Execution time (H:M:S): 00:00:22 ## Design conditions:  ##  ## # A tibble: 1 × 4 ##         d type   sig.level power ##     <dbl> <chr>      <dbl> <lgl> ## 1 0.42164 paired      0.05 NA    ##  ## Estimate of power: 0.840 ## 95% Confidence Interval: [0.837, 0.843] p_t.test(n=50 * 2, d=.2828427, type = 'paired') |> Spower(replications=50000) ##  ## Execution time (H:M:S): 00:00:22 ## Design conditions:  ##  ## # A tibble: 1 × 4 ##         d type   sig.level power ##     <dbl> <chr>      <dbl> <lgl> ## 1 0.28284 paired      0.05 NA    ##  ## Estimate of power: 0.508 ## 95% Confidence Interval: [0.503, 0.512] p_t.test(n=NA, d=0.2828427, type = 'paired') |>      Spower(power=0.832114, interval=c(100,300)) ##  ## Execution time (H:M:S): 00:00:21 ## Design conditions:  ##  ## # A tibble: 1 × 5 ##       n       d type   sig.level   power ##   <dbl>   <dbl> <chr>      <dbl>   <dbl> ## 1    NA 0.28284 paired      0.05 0.83211 ##  ## Estimate of n: 215.9 ## 95% Predicted Confidence Interval: [213.7, 218.1]"},{"path":"https://philchalmers.github.io/Spower/articles/gpower_examples.html","id":"example-20-3-one-sample-t-test","dir":"Articles","previous_headings":"t-tests","what":"Example 20.3; One-sample t-test","title":"G*Power examples evaluated with Spower","text":"Evaluating hypotheses mean expression H0:μ≤μ0H_0:\\mu\\le\\mu_0Ha:μ>μ0H_a:\\mu>\\mu_0 using one-sample tt-test. following estimates nn given one-tailed d=.625d=.625 achieve 1−β=.951-\\beta=.95. G*power gives sample size n=30n=30. Similarly, though different inputs. G*power gives sample size n=1492n=1492.","code":"p_t.test(n=NA, d=.625, two.tailed=FALSE, type='one.sample') |>       Spower(power=.95, interval=c(10, 100)) ##  ## Execution time (H:M:S): 00:00:09 ## Design conditions:  ##  ## # A tibble: 1 × 6 ##       n     d type       two.tailed sig.level power ##   <dbl> <dbl> <chr>      <lgl>          <dbl> <dbl> ## 1    NA 0.625 one.sample FALSE           0.05  0.95 ##  ## Estimate of n: 28.7 ## 95% Predicted Confidence Interval: [28.0, 29.4] p_t.test(n=NA, d=.1, type='one.sample') |>       Spower(power=.9,sig.level=.01, interval=c(100,2000)) ##  ## Execution time (H:M:S): 00:00:14 ## Design conditions:  ##  ## # A tibble: 1 × 5 ##       n     d type       sig.level power ##   <dbl> <dbl> <chr>          <dbl> <dbl> ## 1    NA   0.1 one.sample      0.01   0.9 ##  ## Estimate of n: 1509.8 ## 95% Predicted Confidence Interval: [1489.5, 1529.2]"},{"path":[]},{"path":"https://philchalmers.github.io/Spower/articles/gpower_examples.html","id":"example-22-3-one-sample-test-with-normal-distribution","dir":"Articles","previous_headings":"t-tests > Wilcoxon tests","what":"Example 22.3; One-sample test with normal distribution","title":"G*Power examples evaluated with Spower","text":"Example 22.1 . G*power 3.1 provides power estimate .800, agreeing Spower. Similarly, assuming distribution one-sample followed Laplace distribution, N=11N=11 used instead. requires defining alternative parent distribution, uses rlaplace function extraDistr package. Interestingly, G*power 3.1 reports power 0.830.","code":"p_wilcox.test(n=649, d=.1, type='one.sample', two.tailed=FALSE) |> Spower() ##  ## Execution time (H:M:S): 00:00:21 ## Design conditions:  ##  ## # A tibble: 1 × 6 ##       n     d type       two.tailed sig.level power ##   <dbl> <dbl> <chr>      <lgl>          <dbl> <lgl> ## 1   649   0.1 one.sample FALSE           0.05 NA    ##  ## Estimate of power: 0.799 ## 95% Confidence Interval: [0.791, 0.806] library(extraDistr) parent1 <- function(n, d) extraDistr::rlaplace(n, mu=d, sigma=sqrt(1/2))  # properties of sampled distribution descript(parent1(n=100000, d=0.8)) ## # A tibble: 1 × 14 ##   VARS       n  miss  mean trimmed    sd   mad skewness kurtosis   min  Q_25 ##   <fct>  <dbl> <dbl> <dbl>   <dbl> <dbl> <dbl>    <dbl>    <dbl> <dbl> <dbl> ## 1 df    100000    NA 0.800   0.799 0.999 0.727  0.00702     3.06 -7.94 0.309 ## # ℹ 3 more variables: Q_50 <dbl>, Q_75 <dbl>, max <dbl> p_wilcox.test(n=11, d=.8, type='one.sample', two.tailed=FALSE, parent1 = parent1) |> Spower() ##  ## Execution time (H:M:S): 00:00:03 ## Design conditions:  ##  ## # A tibble: 1 × 6 ##       n     d type       two.tailed sig.level power ##   <dbl> <dbl> <chr>      <lgl>          <dbl> <lgl> ## 1    11   0.8 one.sample FALSE           0.05 NA    ##  ## Estimate of power: 0.815 ## 95% Confidence Interval: [0.807, 0.822]"},{"path":"https://philchalmers.github.io/Spower/articles/gpower_examples.html","id":"two-sample-test-with-laplace-distributions","dir":"Articles","previous_headings":"t-tests > Wilcoxon tests","what":"Two-sample test with Laplace distributions","title":"G*Power examples evaluated with Spower","text":"Two-sample Wilcoxon test comparing Laplace distributions different central tendencies. Unlike Laplace distribution, G*power 3.1 seems agree Spower, power .847 reported. seems raise questions consistency results.","code":"library(extraDistr)  parent1 <- function(n, d) extraDistr::rlaplace(n, mu=d, sigma=sqrt(1/2)) parent2 <- function(n, d) extraDistr::rlaplace(n, sigma=sqrt(1/2))  # properties of sampled distributions descript(parent1(n=100000, d=0.375)) ## # A tibble: 1 × 14 ##   VARS       n  miss  mean trimmed    sd   mad skewness kurtosis   min   Q_25 ##   <fct>  <dbl> <dbl> <dbl>   <dbl> <dbl> <dbl>    <dbl>    <dbl> <dbl>  <dbl> ## 1 df    100000    NA 0.381   0.382 0.997 0.725   0.0256     3.02 -6.07 -0.107 ## # ℹ 3 more variables: Q_50 <dbl>, Q_75 <dbl>, max <dbl> descript(parent1(n=100000, d=0)) ## # A tibble: 1 × 14 ##   VARS       n  miss    mean trimmed    sd   mad skewness kurtosis   min   Q_25 ##   <fct>  <dbl> <dbl>   <dbl>   <dbl> <dbl> <dbl>    <dbl>    <dbl> <dbl>  <dbl> ## 1 df    100000    NA 0.00267 0.00272 1.000 0.726  0.00490     2.86 -8.77 -0.485 ## # ℹ 3 more variables: Q_50 <dbl>, Q_75 <dbl>, max <dbl> nr <- 134/67 p_wilcox.test(n=67, n2_n1=nr, d=0.375, parent1=parent1, parent2=parent2) |>      Spower() ##  ## Execution time (H:M:S): 00:00:10 ## Design conditions:  ##  ## # A tibble: 1 × 4 ##       n     d sig.level power ##   <dbl> <dbl>     <dbl> <lgl> ## 1    67 0.375      0.05 NA    ##  ## Estimate of power: 0.851 ## 95% Confidence Interval: [0.844, 0.858]"},{"path":"https://philchalmers.github.io/Spower/articles/gpower_examples.html","id":"example-23-3-paired-samples-test-with-laplace-distributions","dir":"Articles","previous_headings":"t-tests > Wilcoxon tests","what":"Example 23.3: Paired-samples test with Laplace distributions","title":"G*Power examples evaluated with Spower","text":"Finally, paired-samples approach using Wilcoxon test N=10N=10. , simulation approach G*power 3.1 differ outputs, G*power 3.1 reported power 0.853.","code":"parent1 <- function(n, d) extraDistr::rlaplace(n, mu=d, sigma=sqrt(1/2)) parent2 <- function(n, d) extraDistr::rlaplace(n, sigma=sqrt(1/2))  descript(parent1(n=100000, d=1.13842)) ## # A tibble: 1 × 14 ##   VARS       n  miss  mean trimmed    sd   mad skewness kurtosis   min  Q_25 ##   <fct>  <dbl> <dbl> <dbl>   <dbl> <dbl> <dbl>    <dbl>    <dbl> <dbl> <dbl> ## 1 df    100000    NA  1.14    1.14 0.996 0.727   0.0158     2.93 -7.46 0.653 ## # ℹ 3 more variables: Q_50 <dbl>, Q_75 <dbl>, max <dbl> descript(parent1(n=100000, d=0)) ## # A tibble: 1 × 14 ##   VARS      n  miss     mean  trimmed    sd   mad skewness kurtosis   min   Q_25 ##   <fct> <dbl> <dbl>    <dbl>    <dbl> <dbl> <dbl>    <dbl>    <dbl> <dbl>  <dbl> ## 1 df      1e5    NA -0.00205 -0.00284  1.00 0.722   0.0147     3.16 -7.60 -0.490 ## # ℹ 3 more variables: Q_50 <dbl>, Q_75 <dbl>, max <dbl> p_wilcox.test(n=10*2, d=1.13842, type = 'paired',               parent1=parent1, parent2=parent2) |> Spower() ##  ## Execution time (H:M:S): 00:00:04 ## Design conditions:  ##  ## # A tibble: 1 × 4 ##        d type   sig.level power ##    <dbl> <chr>      <dbl> <lgl> ## 1 1.1384 paired      0.05 NA    ##  ## Estimate of power: 0.933 ## 95% Confidence Interval: [0.928, 0.938]"},{"path":"https://philchalmers.github.io/Spower/articles/original/gpower_examples.html","id":"correlation","dir":"Articles > Original","previous_headings":"","what":"Correlation","title":"G*Power examples evaluated with Spower","text":"Correlation analyses require evaluating power associated hypotheses H0:ρ−ρ0=0H_0:\\, \\rho-\\rho_0=0H1:ρ−ρ0≠0H_1:\\, \\rho-\\rho_0\\ne 0 ρ\\rho population correlation ρ0\\rho_0 null hypothesis constant.","code":""},{"path":"https://philchalmers.github.io/Spower/articles/original/gpower_examples.html","id":"example-3-3-difference-from-constant-one-sample-case","dir":"Articles > Original","previous_headings":"Correlation","what":"Example 3.3; Difference from constant (one sample case)","title":"G*Power examples evaluated with Spower","text":"following estimates sample size required reject H0:ρ0=.60H_0:\\, \\rho_0=.60 correlation analysis 1−β=.951-\\beta=.95 probability ρ=.65\\rho=.65. G*power estimates nn 1929 using Fisher zz-transformation approximation, used Spower definition well.","code":"p_r(n = NA, r = .65, rho = .60) |>      Spower(power = .95, interval=c(500,3000)) ##  ## Execution time (H:M:S): 00:00:16 ## Design conditions:  ##  ## # A tibble: 1 × 5 ##       n     r   rho sig.level power ##   <dbl> <dbl> <dbl>     <dbl> <dbl> ## 1    NA  0.65   0.6      0.05  0.95 ##  ## Estimate of n: 1931.4 ## 95% Predicted Confidence Interval: [1901.1, 1958.2]"},{"path":"https://philchalmers.github.io/Spower/articles/original/gpower_examples.html","id":"test-against-constant-rho_00","dir":"Articles > Original","previous_headings":"Correlation","what":"Test against constant ρ0=0\\rho_0=0","title":"G*Power examples evaluated with Spower","text":"canonical version hypotheses involving correlation coefficients appear rho0=0rho_0=0, require Fisher approximation. instance, power associated ρ=.3\\rho = .3 100 pairs observations, tested ρ0=0\\rho_0=0, results following. Next, sample sample size estimate required reject H0:ρ0=0H_0:\\, \\rho_0=0 correlation analysis 1−β=.951-\\beta=.95 probability ρ=.3\\rho=.3 expressed G*power 3.1 provides estimate pwr package case, comparison presented .","code":"p_r(n = 100, r = .3) |> Spower() ##  ## Execution time (H:M:S): 00:00:07 ## Design conditions:  ##  ## # A tibble: 1 × 4 ##       n     r sig.level power ##   <dbl> <dbl>     <dbl> <lgl> ## 1   100   0.3      0.05 NA    ##  ## Estimate of power: 0.861 ## 95% Confidence Interval: [0.854, 0.867] p_r(n = NA, r = .3) |>      Spower(power = .95, interval=c(50,1000)) ##  ## Execution time (H:M:S): 00:00:13 ## Design conditions:  ##  ## # A tibble: 1 × 4 ##       n     r sig.level power ##   <dbl> <dbl>     <dbl> <dbl> ## 1    NA   0.3      0.05  0.95 ##  ## Estimate of n: 138.3 ## 95% Predicted Confidence Interval: [136.1, 140.4] pwr::pwr.r.test(r=.3, power=.95, n=NULL) ##  ##      approximate correlation power calculation (arctangh transformation)  ##  ##               n = 137.8 ##               r = 0.3 ##       sig.level = 0.05 ##           power = 0.95 ##     alternative = two.sided"},{"path":"https://philchalmers.github.io/Spower/articles/original/gpower_examples.html","id":"example-27-3-correlation---inequality-of-two-independent-pearson-rs","dir":"Articles > Original","previous_headings":"Correlation","what":"Example 27.3; Correlation - inequality of two independent Pearson r’s","title":"G*Power examples evaluated with Spower","text":"correlation two independent samples compared, p_2r() simulation can adopted. sample N1=206N_1=206 observations appeared first sample (r=.75r=.75), second sample (r=.88r=.88) contained N2=51N_2=51 observations (hence, ratio N2/N1=51/206N_2/N_1=51/206). results post-hoc/observed power G*power 3.1 returns power .726 context.","code":"p_2r(n=206, r.ab=.75, r.ab2=.88, n2_n1=51/206) |> Spower() ##  ## Execution time (H:M:S): 00:00:19 ## Design conditions:  ##  ## # A tibble: 1 × 5 ##       n  r.ab r.ab2 sig.level power ##   <dbl> <dbl> <dbl>     <dbl> <lgl> ## 1   206  0.75  0.88      0.05 NA    ##  ## Estimate of power: 0.727 ## 95% Confidence Interval: [0.718, 0.735]"},{"path":"https://philchalmers.github.io/Spower/articles/original/gpower_examples.html","id":"example-28-3-1-correlation---inequality-of-two-dependent-pearson-rs-no-common-index","dir":"Articles > Original","previous_headings":"Correlation","what":"Example 28.3.1; Correlation - inequality of two dependent Pearson r’s (no common index)","title":"G*Power examples evaluated with Spower","text":"following two examples assume correlation matrix population structure. common index tests elements required, common index form 3×33\\times 3 subset needed. Evaluating null hypothesis H0:ρab=ρcdH_0: \\rho_{ab} = \\rho_{cd} case ρab=.5\\rho_{ab} = .5 ρcd=.8\\rho_{cd} = .8 can explored using p_2r() function. following performs priori analyses determine sample size (NN) required achieve 80% power using Steiger’s (1980) inferential zz approach. G*power 3.1 returns required sample size N=886N=886.","code":"# From Gpower 3.1 manual Cp <- matrix(c(1, .5, .4, .1,                 .5, 1, .2, -.4,                 .4, .2, 1, .8,                 .1, -.4, .8, 1), 4, 4)  # rearrange rows for convenience Cp <- Cp[c(1,4,2,3), c(1,4,2,3)] colnames(Cp) <- rownames(Cp) <- c('x1', 'y1', 'x2', 'y2') Cp ##     x1   y1   x2  y2 ## x1 1.0  0.1  0.5 0.4 ## y1 0.1  1.0 -0.4 0.8 ## x2 0.5 -0.4  1.0 0.2 ## y2 0.4  0.8  0.2 1.0 p_2r(n=NA, r.ab=.1, r.ac=.5, r.ad=.4, r.bc=-.4, r.bd=.8, r.cd=.2,       two.tailed=FALSE) |> Spower(power = .80, interval=c(500, 2000)) ##  ## Execution time (H:M:S): 00:01:11 ## Design conditions:  ##  ## # A tibble: 1 × 9 ##       n  r.ab  r.ac  r.ad  r.bd  r.cd two.tailed sig.level power ##   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <lgl>          <dbl> <dbl> ## 1    NA   0.1   0.5   0.4   0.8   0.2 FALSE           0.05   0.8 ##  ## Estimate of n: 886.2 ## 95% Predicted Confidence Interval: [875.3, 897.3]"},{"path":"https://philchalmers.github.io/Spower/articles/original/gpower_examples.html","id":"example-28-3-2-correlation---inequality-of-two-dependent-pearson-rs-common-index","dir":"Articles > Original","previous_headings":"Correlation","what":"Example 28.3.2; Correlation - inequality of two dependent Pearson r’s (common index)","title":"G*Power examples evaluated with Spower","text":"information example Example 28.3.1, however assumed common index correlation measures instead complete overlap. , previous Cp object may subset see type correlation structure required common index setup. null instigation case H0:ρab=ρacH_0:\\rho_{ab} = \\rho_{ac} ρab=.2\\rho_{ab} = .2 ρac=.4\\rho_{ac} = .4. Spower, equates following inputs, use Steiger’s (1980) inferential zz approach default. G*power 3.1 returns required sample size N=144N=144, interestingly slightly higher simulation version Spower. Providing N=144N=144 obtain power estimate gives following:","code":"Cp[c(4,3,1),c(4,3,1)] ##     y2  x2  x1 ## y2 1.0 0.2 0.4 ## x2 0.2 1.0 0.5 ## x1 0.4 0.5 1.0 p_2r(n=NA, r.ab=.4, r.ac=.2, r.bc=.5, two.tailed=FALSE) |>      Spower(power = .80, interval=c(50, 500)) ##  ## Execution time (H:M:S): 00:00:58 ## Design conditions:  ##  ## # A tibble: 1 × 7 ##       n  r.ab  r.ac  r.bc two.tailed sig.level power ##   <dbl> <dbl> <dbl> <dbl> <lgl>          <dbl> <dbl> ## 1    NA   0.4   0.2   0.5 FALSE           0.05   0.8 ##  ## Estimate of n: 134.7 ## 95% Predicted Confidence Interval: [133.1, 136.3] p_2r(n=144, r.ab=.4, r.ac=.2, r.bc=.5, two.tailed=FALSE) |> Spower() ##  ## Execution time (H:M:S): 00:00:15 ## Design conditions:  ##  ## # A tibble: 1 × 7 ##       n  r.ab  r.ac  r.bc two.tailed sig.level power ##   <dbl> <dbl> <dbl> <dbl> <lgl>          <dbl> <lgl> ## 1   144   0.4   0.2   0.5 FALSE           0.05 NA    ##  ## Estimate of power: 0.831 ## 95% Confidence Interval: [0.824, 0.839]"},{"path":"https://philchalmers.github.io/Spower/articles/original/gpower_examples.html","id":"example-28-3-3-sensitivity-analysis","dir":"Articles > Original","previous_headings":"Correlation","what":"Example 28.3.3; sensitivity analysis","title":"G*Power examples evaluated with Spower","text":"also possible perform sensitivity analyses rather priori power analysis. fixes N=144N=144, r.ac solved obtain 80% power. G*power 3.1 reports ρac=0.047702\\rho_{ac} = 0.047702, confirmed using simulation . Obtaining similar estimate using Spower() requires following sensitivity analysis structure: example, Spower G*power 3.1 seem agree.","code":"# confirm solution obtained by G*power (post hoc power estimate) p_2r(n=144, r.ab=.4, r.ac=0.047702, r.bc=-0.6, two.tailed=FALSE) |> Spower() ##  ## Execution time (H:M:S): 00:00:15 ## Design conditions:  ##  ## # A tibble: 1 × 6 ##       n  r.ab     r.ac two.tailed sig.level power ##   <dbl> <dbl>    <dbl> <lgl>          <dbl> <lgl> ## 1   144   0.4 0.047702 FALSE           0.05 NA    ##  ## Estimate of power: 0.815 ## 95% Confidence Interval: [0.808, 0.823] # note that interval is specified as c(upper, lower) as higher values # of r.ac result in lower power in this context p_2r(n=144, r.ab=.4, r.ac=NA, r.bc=-0.6, two.tailed=FALSE) |>      Spower(power = .80, interval=c(.4, .001)) ##  ## Execution time (H:M:S): 00:01:11 ## Design conditions:  ##  ## # A tibble: 1 × 6 ##       n  r.ab  r.ac two.tailed sig.level power ##   <dbl> <dbl> <dbl> <lgl>          <dbl> <dbl> ## 1   144   0.4    NA FALSE           0.05   0.8 ##  ## Estimate of r.ac: 0.048 ## 95% Predicted Confidence Interval: [0.046, 0.050]"},{"path":"https://philchalmers.github.io/Spower/articles/original/gpower_examples.html","id":"example-16-3-point-biserial-correlation","dir":"Articles > Original","previous_headings":"Correlation","what":"Example 16.3; Point-biserial correlation","title":"G*Power examples evaluated with Spower","text":"following estimates sample size required obtain power 1−β=.951-\\beta=.95 given r=.25r=.25 true correlation, evaluated null H0:ρ≤0H_0:\\rho\\le0 (hence, one-tailed) α=.05\\alpha = .05. G*power gives result N=164N=164. Relatedly, one can specify dd, Cohen’s standardized mean-difference effect size, instead rr since dd converted rr inside p_t.test() function.","code":"# solution per group out <- p_t.test(r = .25, n = NA, two.tailed=FALSE) |>      Spower(power = .95, interval=c(50, 200)) out ##  ## Execution time (H:M:S): 00:00:08 ## Design conditions:  ##  ## # A tibble: 1 × 5 ##       n     r two.tailed sig.level power ##   <dbl> <dbl> <lgl>          <dbl> <dbl> ## 1    NA  0.25 FALSE           0.05  0.95 ##  ## Estimate of n: 81.7 ## 95% Predicted Confidence Interval: [79.1, 85.4] # total sample size required ceiling(out$n) * 2 ## [1] 164"},{"path":"https://philchalmers.github.io/Spower/articles/original/gpower_examples.html","id":"example-31-3-tetrachoric-correlation","dir":"Articles > Original","previous_headings":"Correlation","what":"Example 31.3; tetrachoric correlation","title":"G*Power examples evaluated with Spower","text":"tetrachoric polychoric correlations, experiment definition p_r.cat() can used. requires specifying associated τ\\tau threshold coefficients population normal truncation processes, well bivariate correlation prior truncation. τ\\tau values correspond along assumed normal p.d.f. truncation took place, XX variable can seen following graphic. Finally, assuming untruncated r=0.2399846r=0.2399846, Score test used evaluate null hypothesis interest (score = TRUE), sample size required reject null hypothesis tetrachoric correlation less equal 0 population (one-tailed) expressed G*power gives n=463n=463, though uses SE value null (Score test). p_r.cat(), hand, defaults Wald approach SE maximum-likelihood estimate (MLE); hence, score = FALSE default. switch, use score=TRUE, though note requires twice many computations second set data generated analyzed r=r0r=r_0 obtain required SE0SE_0 estimate.","code":"F <- matrix(c(203, 186, 167, 374), 2, 2) N <- sum(F) (marginal.x <- colSums(F)/N) ## [1] 0.4183 0.5817 (marginal.y <- rowSums(F)/N) ## [1] 0.3978 0.6022 # converted to intercepts tauX <- qnorm(1-marginal.x)[2] tauY <- qnorm(1-marginal.y)[2] c(tauX, tauY) ## [1] -0.2063 -0.2589 p_r.cat(n=NA, r=0.2399846, tauX=tauX, tauY=tauY,          score=TRUE, two.tailed=FALSE) |>      Spower(power = .95, interval=c(100, 500),             parallel=TRUE, check.interval=FALSE) ##  ## Design conditions:  ##  ## # A tibble: 1 × 8 ##       n     r   tauX   tauY score two.tailed sig.level power ##   <dbl> <dbl> <dbl> <dbl> <lgl> <lgl>          <dbl> <dbl> ## 1    NA 0.240 -0.206 -0.259 FALSE FALSE           0.05  0.95 ##  ## Estimate of n: 462.9 ## 95% Prediction Interval: [458.5, 466.6]"},{"path":[]},{"path":"https://philchalmers.github.io/Spower/articles/original/gpower_examples.html","id":"example-4-3-one-sample-proportion-tests","dir":"Articles > Original","previous_headings":"Proportions","what":"Example 4.3; One sample proportion tests","title":"G*Power examples evaluated with Spower","text":"one sample, one-tailed proportion test given data generated population π=.80\\pi = .80 tested null hypothesis H0:π0≤.65H_0:\\pi_0\\le.65 n=20n=20 presented following. Note G*power requires term gg specified proportion difference null instead (hence, g=.80−.65=.15g = .80-.65=.15), though p_prop.teset() accepts null alternative probability values -. G*power gives estimate 1−β=.41121-\\beta=.4112. Note p_prop.test(), Fisher’s exact version test also supported passing argument exact = TRUE.","code":"pi <- .65 g <- .15 p <- pi + g  p_prop.test(n=20, prop=p, pi=pi, two.tailed=FALSE) |>     Spower() ##  ## Execution time (H:M:S): 00:00:02 ## Design conditions:  ##  ## # A tibble: 1 × 4 ##       n two.tailed sig.level power ##   <dbl> <lgl>          <dbl> <lgl> ## 1    20 FALSE           0.05 NA    ##  ## Estimate of power: 0.416 ## 95% Confidence Interval: [0.406, 0.425] # Fisher exact test p_prop.test(n=20, prop=p, pi=pi, exact=TRUE,              two.tailed=FALSE) |> Spower() ##  ## Execution time (H:M:S): 00:00:02 ## Design conditions:  ##  ## # A tibble: 1 × 5 ##       n two.tailed exact sig.level power ##   <dbl> <lgl>      <lgl>     <dbl> <lgl> ## 1    20 FALSE      TRUE       0.05 NA    ##  ## Estimate of power: 0.411 ## 95% Confidence Interval: [0.402, 0.421]"},{"path":"https://philchalmers.github.io/Spower/articles/original/gpower_examples.html","id":"example-22-1-wilcoxon-signed-rank-test","dir":"Articles > Original","previous_headings":"Proportions","what":"Example 22.1; Wilcoxon signed-rank test","title":"G*Power examples evaluated with Spower","text":"following performed one-sample, one-tailed Wilcoxon signed rank test given N=649N=649, d=.1d=.1, parent distribution assumed follow Normal/Gaussian shape (default). G*power gives power estimate .800. following partially recreates simulation results Figure 29 (partially extracted Shieh, Jan, Randles, 2007) Gaussian(μ\\mu,1) distribution varying sample sizes effect sizes. target obtain “approximate power 1−β=.801-\\beta = .80”, though sample sizes decided upon specified. Spower()’s stochastic root-solving approach likely get closer optimal NN estimates target analyses.","code":"p_wilcox.test(n=649, d=.1, type='one.sample', two.tailed=FALSE) |>      Spower() ##  ## Execution time (H:M:S): 00:00:12 ## Design conditions:  ##  ## # A tibble: 1 × 6 ##       n     d type       two.tailed sig.level power ##   <dbl> <dbl> <chr>      <lgl>          <dbl> <lgl> ## 1   649   0.1 one.sample FALSE           0.05 NA    ##  ## Estimate of power: 0.812 ## 95% Confidence Interval: [0.805, 0.820] # For Gaussian(d,1) out <- p_wilcox.test(type='one.sample', two.tailed=FALSE) |>      SpowerBatch(n=c(649, 164, 42, 20, 12, 9),                 d=c(.1, .2, .4, .6, .8, 1.0), replications = 50000, fully.crossed=FALSE) as.data.frame(out) ##     n   d       type two.tailed sig.level  power CI_2.5 CI_97.5 ## 1 649 0.1 one.sample      FALSE      0.05 0.8012 0.7977  0.8047 ## 2 164 0.2 one.sample      FALSE      0.05 0.8027 0.7992  0.8062 ## 3  42 0.4 one.sample      FALSE      0.05 0.8043 0.8009  0.8078 ## 4  20 0.6 one.sample      FALSE      0.05 0.8070 0.8035  0.8105 ## 5  12 0.8 one.sample      FALSE      0.05 0.8018 0.7983  0.8053 ## 6   9 1.0 one.sample      FALSE      0.05 0.8467 0.8435  0.8498"},{"path":"https://philchalmers.github.io/Spower/articles/original/gpower_examples.html","id":"laplacemu-1-version","dir":"Articles > Original","previous_headings":"Proportions > Example 22.1; Wilcoxon signed-rank test","what":"Laplace(μ\\mu, 1) version","title":"G*Power examples evaluated with Spower","text":"one-sample Wilcoxon signed rank test Laplace distribution parent. Note requires defining parent distribution manually, accepting arguments n d. G*power gives estimate .830, seems somewhat high (see ). following partially recreates simulation results Figure 29 Laplace(μ\\mu, 1) distribution varying sample sizes effect sizes. target obtain “approximate power 1−β=.801-\\beta = .80”, though sample sizes decided upon specified. Spower()’s stochastic root-solving approach likely get closer optimal NN estimates target analyses.","code":"library(extraDistr)  # generate data with scale 0-1 for d effect size to be same as mean # VAR = 2*b^2, so scale should be 1 = 2*b^2 -> sqrt(1/2) parent <- function(n, d, sigma=sqrt(1/2))      extraDistr::rlaplace(n, d, sigma=sigma)  p_wilcox.test(n=11, d=.8, parent1=parent, type='one.sample',               two.tailed=FALSE, correct = FALSE) |> Spower() ##  ## Execution time (H:M:S): 00:00:02 ## Design conditions:  ##  ## # A tibble: 1 × 7 ##       n     d type       correct two.tailed sig.level power ##   <dbl> <dbl> <chr>      <lgl>   <lgl>          <dbl> <lgl> ## 1    11   0.8 one.sample FALSE   FALSE           0.05 NA    ##  ## Estimate of power: 0.801 ## 95% Confidence Interval: [0.793, 0.809] # For Laplace(0,1) out <- p_wilcox.test(parent1=parent, type='one.sample',               two.tailed=FALSE) |>      SpowerBatch(n=c(419, 109, 31, 16, 11, 8),                 d=c(.1, .2, .4, .6, .8, 1.0), replications=50000, fully.crossed=FALSE) as.data.frame(out) ##     n   d       type two.tailed sig.level  power CI_2.5 CI_97.5 ## 1 419 0.1 one.sample      FALSE      0.05 0.8021 0.7986  0.8056 ## 2 109 0.2 one.sample      FALSE      0.05 0.7992 0.7957  0.8028 ## 3  31 0.4 one.sample      FALSE      0.05 0.8031 0.7996  0.8065 ## 4  16 0.6 one.sample      FALSE      0.05 0.8007 0.7972  0.8042 ## 5  11 0.8 one.sample      FALSE      0.05 0.8032 0.7998  0.8067 ## 6   8 1.0 one.sample      FALSE      0.05 0.7771 0.7735  0.7808"},{"path":"https://philchalmers.github.io/Spower/articles/original/gpower_examples.html","id":"example-5-3-two-dependent-proportions-test-mcnemars-test","dir":"Articles > Original","previous_headings":"Proportions","what":"Example 5.3; Two dependent proportions test (McNemar’s test)","title":"G*Power examples evaluated with Spower","text":"following performs proportions test two dependent groups using McNemar’s test. data O’Brien (2002, p. 161-163). Alternatively, specifying inputs terms proportions rather odds ratio (=π12/π21=.08/.32=.25OR=\\pi_{12}/\\pi_{21}=.08/.32=.25) proportions discordant pairs (πD=π12+π21=.08+.32=.40\\pi_D=\\pi_{12} + \\pi_{21}=.08 + .32=.40) can supplied G*Power gives .839 (α=.032\\alpha = .032). Slightly power can achieved using continuity correction, though general recommended practice.","code":"obrien2002 <- matrix(c(.54, .32, .08, .06), 2, 2,                      dimnames = list('Treatment' = c('Yes', 'No'),                                     'Standard' = c('Yes', 'No'))) obrien2002 ##          Standard ## Treatment  Yes   No ##       Yes 0.54 0.08 ##       No  0.32 0.06 p_mcnemar.test(n=50, prop=obrien2002, two.tailed=FALSE) |> Spower() ##  ## Execution time (H:M:S): 00:00:01 ## Design conditions:  ##  ## # A tibble: 1 × 4 ##       n two.tailed sig.level power ##   <dbl> <lgl>          <dbl> <lgl> ## 1    50 FALSE           0.05 NA    ##  ## Estimate of power: 0.836 ## 95% Confidence Interval: [0.828, 0.843] OR <- obrien2002[1,2] / obrien2002[2,1] disc <- obrien2002[1,2] + obrien2002[2,1] p_mcnemar.test(n=50, OR=OR, prop.disc=disc, two.tailed=FALSE) |> Spower() ##  ## Execution time (H:M:S): 00:00:01 ## Design conditions:  ##  ## # A tibble: 1 × 4 ##       n two.tailed sig.level power ##   <dbl> <lgl>          <dbl> <lgl> ## 1    50 FALSE           0.05 NA    ##  ## Estimate of power: 0.841 ## 95% Confidence Interval: [0.834, 0.848] p_mcnemar.test(n=50, prop=obrien2002, two.tailed=FALSE, correct=FALSE) |> Spower() ##  ## Execution time (H:M:S): 00:00:01 ## Design conditions:  ##  ## # A tibble: 1 × 5 ##       n two.tailed correct sig.level power ##   <dbl> <lgl>      <lgl>       <dbl> <lgl> ## 1    50 FALSE      FALSE        0.05 NA    ##  ## Estimate of power: 0.887 ## 95% Confidence Interval: [0.881, 0.893]"},{"path":[]},{"path":"https://philchalmers.github.io/Spower/articles/original/gpower_examples.html","id":"example-13-1","dir":"Articles > Original","previous_headings":"Multiple Linear Regression (Fixed IVs)","what":"Example 13.1","title":"G*Power examples evaluated with Spower","text":"Evaluating R2=.1R^2=.1 generated data linear regression model given null hypothesis H0:R02=0H_0:R^2_0=0. evaluated using N=95N=95 observations k=5k=5 predictor variables gives estimate. G*power gives 1−β=.6731-\\beta = .673.","code":"p_lm.R2(n=95, R2=.1, k=5) |> Spower() ##  ## Execution time (H:M:S): 00:00:30 ## Design conditions:  ##  ## # A tibble: 1 × 5 ##       n    R2     k sig.level power ##   <dbl> <dbl> <dbl>     <dbl> <lgl> ## 1    95   0.1     5      0.05 NA    ##  ## Estimate of power: 0.664 ## 95% Confidence Interval: [0.655, 0.674]"},{"path":"https://philchalmers.github.io/Spower/articles/original/gpower_examples.html","id":"example-14-3","dir":"Articles > Original","previous_headings":"Multiple Linear Regression (Fixed IVs)","what":"Example 14.3","title":"G*Power examples evaluated with Spower","text":"Similarly, comparing nested models changes R2R^2. following, note k total IVs (case, 9), k.R2_0 number IVs baseline model (case, 5). α=.01\\alpha=.01 change ΔR2=.05\\Delta R^2=.05 baseline R02=.25R^2_0=.25 gives G*power gives 1−β=.2411-\\beta = .241. Solving sample size achieve 80% power G*power gives n=242n = 242.","code":"p_lm.R2(n=90, R2=.3, k=9, R2_0=.25, k.R2_0=5) |> Spower(sig.level=.01) ##  ## Execution time (H:M:S): 00:00:40 ## Design conditions:  ##  ## # A tibble: 1 × 7 ##       n    R2     k  R2_0 k.R2_0 sig.level power ##   <dbl> <dbl> <dbl> <dbl>  <dbl>     <dbl> <lgl> ## 1    90   0.3     9  0.25      5      0.01 NA    ##  ## Estimate of power: 0.238 ## 95% Confidence Interval: [0.230, 0.247] p_lm.R2(n=NA, R2=.3, R2_0 = .25, k=9, k.R2_0=5) |>          Spower(sig.level=.01, power=.8, interval=c(100, 400)) ##  ## Execution time (H:M:S): 00:02:14 ## Design conditions:  ##  ## # A tibble: 1 × 7 ##       n    R2     k  R2_0 k.R2_0 sig.level power ##   <dbl> <dbl> <dbl> <dbl>  <dbl>     <dbl> <dbl> ## 1    NA   0.3     9  0.25      5      0.01   0.8 ##  ## Estimate of n: 242.6 ## 95% Predicted Confidence Interval: [240.5, 244.6]"},{"path":"https://philchalmers.github.io/Spower/articles/original/gpower_examples.html","id":"example-14-3b","dir":"Articles > Original","previous_headings":"Multiple Linear Regression (Fixed IVs)","what":"Example 14.3b","title":"G*Power examples evaluated with Spower","text":"Nested model comparison changes R2R^2 models 12 IVs versus 9 IVs. Requires specification Rresidual2R^2_{residual}. G*power gives 1−β=.7671-\\beta = .767.","code":"p_lm.R2(n=200, R2=.16, R2_0 = .1, k=12, k.R2_0=9, R2.resid=.8) |>      Spower(sig.level=.01) ##  ## Execution time (H:M:S): 00:00:53 ## Design conditions:  ##  ## # A tibble: 1 × 8 ##       n    R2     k  R2_0 k.R2_0 R2.resid sig.level power ##   <dbl> <dbl> <dbl> <dbl>  <dbl>    <dbl>     <dbl> <lgl> ## 1   200  0.16    12   0.1      9      0.8      0.01 NA    ##  ## Estimate of power: 0.756 ## 95% Confidence Interval: [0.748, 0.765]"},{"path":[]},{"path":"https://philchalmers.github.io/Spower/articles/original/gpower_examples.html","id":"example-7-3","dir":"Articles > Original","previous_headings":"Multiple Linear Regression (Random IVs)","what":"Example 7.3","title":"G*Power examples evaluated with Spower","text":"Example 13.1 , however assuming IVs randomly sampled instead fixed. G*power gives 0.662 using one-tailed test criterion.","code":"p_lm.R2(n=95, R2=.1, k=5, fixed=FALSE) |> Spower() ##  ## Execution time (H:M:S): 00:00:10 ## Design conditions:  ##  ## # A tibble: 1 × 6 ##       n    R2     k fixed sig.level power ##   <dbl> <dbl> <dbl> <lgl>     <dbl> <lgl> ## 1    95   0.1     5 FALSE      0.05 NA    ##  ## Estimate of power: 0.659 ## 95% Confidence Interval: [0.650, 0.669]"},{"path":[]},{"path":"https://philchalmers.github.io/Spower/articles/original/gpower_examples.html","id":"example-12-3","dir":"Articles > Original","previous_headings":"Simple linear regression","what":"Example 12.3","title":"G*Power examples evaluated with Spower","text":"Evaluate post-hoc power simple linear regression model null hypothesis H0:β1=0H_0:\\beta_1=0 given σx=7.5\\sigma_x = 7.5, σy\\sigma_y, β1=−0.0667\\beta_1=-0.0667, N=100N=100. G*power returns power estimate 1−β=0.23891-\\beta = 0.2389.","code":"p_slr(n=100, beta=-0.0667, sd_x=7.5, sd_y = 4) |> Spower() ##  ## Execution time (H:M:S): 00:00:21 ## Design conditions:  ##  ## # A tibble: 1 × 5 ##       n  sd_x  sd_y sig.level power ##   <dbl> <dbl> <dbl>     <dbl> <lgl> ## 1   100   7.5     4      0.05 NA    ##  ## Estimate of power: 0.243 ## 95% Confidence Interval: [0.234, 0.251]"},{"path":[]},{"path":"https://philchalmers.github.io/Spower/articles/original/gpower_examples.html","id":"example-10-3","dir":"Articles > Original","previous_headings":"Fixed effects ANOVA - One way (F-test)","what":"Example 10.3","title":"G*Power examples evaluated with Spower","text":"One-way ANOVA example solve nn per group (k=10k=10), using Cohen’s f=.25f=.25, achieve power 1−β=.951-\\beta=.95. G*power gives estimate n=39n=39. Fixing n=200n=200 total (hence, n=200/k=20n=200/k=20) performing compromise analysis assuming q=βα=1q=\\frac{\\beta}{\\alpha}=1, G*Power gives α=β=0.159\\alpha=\\beta=0.159.","code":"p_anova.test(n=NA, k=10, f=.25) |>  Spower(power=.95, interval=c(20, 300)) ##  ## Execution time (H:M:S): 00:00:17 ## Design conditions:  ##  ## # A tibble: 1 × 5 ##       n     k     f sig.level power ##   <dbl> <dbl> <dbl>     <dbl> <dbl> ## 1    NA    10  0.25      0.05  0.95 ##  ## Estimate of n: 38.7 ## 95% Predicted Confidence Interval: [38.1, 39.2] p_anova.test(n=20, k=10, f=.25) |> Spower(beta_alpha=1, replications=30000) ##  ## Execution time (H:M:S): 00:00:29 ## Design conditions:  ##  ## # A tibble: 1 × 6 ##       n     k     f sig.level power beta_alpha ##   <dbl> <dbl> <dbl>     <dbl> <lgl>      <dbl> ## 1    20    10  0.25        NA NA             1 ##  ## Estimate of Type I error rate (alpha/sig.level): 0.160 ## 95% Confidence Interval: [0.156, 0.164] ##  ## Estimate of power (1-beta): 0.840 ## 95% Confidence Interval: [0.836, 0.844]"},{"path":"https://philchalmers.github.io/Spower/articles/original/gpower_examples.html","id":"t-test-linear-regression-two-groups","dir":"Articles > Original","previous_headings":"","what":"tt-test: Linear regression (two groups)","title":"G*Power examples evaluated with Spower","text":"Test coefficients across distinct datasets similar form. case Y1=β0+β1X1+ϵY_1 = \\beta_0 + \\beta_1 X_1 + \\epsilonY2=β0*+β1*X2+ϵY_2 = \\beta_0^* + \\beta_1^* X_2 + \\epsilon null interest H0:β1−β1*=0H_0:\\, \\beta_1 - \\beta_1^* = 0 multiple linear regression model setup three variables Y=β0+β1X+β2S+β3(S⋅X)+ϵY = \\beta_0 + \\beta_1 X + \\beta_2 S + \\beta_3 (S\\cdot X) + \\epsilon Y=[Y1,Y2]Y=[Y_1, Y_2], X=[X1,X2]X = [X_1, X_2], SS binary indicator variable indicating whether observations second sample. S=0S = 0 first group’s parameterization recovered, S=1S=1 second group’s parameterization recovered potentially non-zero β2\\beta_2 reflects change intercept (β0*=β0+β2\\beta_0^* = \\beta_0 + \\beta_2) change slope second group reflected β3\\beta_3 (β1*=β1+β3\\beta_1^*=\\beta_1 + \\beta_3). Hence, null hypothesis two groups slope can evaluated using augmented model testing H0:β3=0H_0:\\, \\beta_3 = 0","code":""},{"path":"https://philchalmers.github.io/Spower/articles/original/gpower_examples.html","id":"example-17-3-and-18-3","dir":"Articles > Original","previous_headings":"tt-test: Linear regression (two groups)","what":"Example 17.3 and 18.3","title":"G*Power examples evaluated with Spower","text":"start defining population generating model replace gen_glm() function default p_glm(). generating function organized data.frame returned columns y, X, S, interaction effect reflects magnitude difference β\\beta coefficients across independent samples. demonstrate, post-hoc power described example G*Power following. priori power analysis achieve power .80 G*Power gives estimate nn 163 (therefore 256 second group given n2_n1).","code":"gen_twogroup <- function(n, dbeta, sdx1, sdx2, sigma, n2_n1 = 1, ...){     X1 <- rnorm(n, sd=sdx1)     X2 <- rnorm(n*n2_n1, sd=sdx2)     X <- c(X1, X2)     N <- length(X)     S <- c(rep(0, n), rep(1, N-n))     y <- dbeta * X*S + rnorm(N, sd=sigma)     dat <- data.frame(y, X, S)     dat } p_glm(formula=y~X*S, test=\"X:S = 0\",       n=28, n2_n1=44/28, sdx1=9.02914, sdx2=11.86779, dbeta=0.01592,       sigma=0.5578413, gen_fun=gen_twogroup) |> Spower() ##  ## Execution time (H:M:S): 00:00:24 ## Design conditions:  ##  ## # A tibble: 1 × 8 ##   test      sigma     n   sdx1   sdx2   dbeta sig.level power ##   <chr>     <dbl> <dbl>  <dbl>  <dbl>   <dbl>     <dbl> <lgl> ## 1 X:S = 0 0.55784    28 9.0291 11.868 0.01592      0.05 NA    ##  ## Estimate of power: 0.199 ## 95% Confidence Interval: [0.191, 0.207] p_glm(formula=y~X*S, test=\"X:S = 0\",       n=NA, n2_n1=44/28, sdx1=9.02914, sdx2=11.86779, dbeta=0.01592,       sigma=0.5578413, gen_fun=gen_twogroup) |>      Spower(power=.8, interval=c(100, 1000)) ##  ## Execution time (H:M:S): 00:01:25 ## Design conditions:  ##  ## # A tibble: 1 × 8 ##   test      sigma     n   sdx1   sdx2   dbeta sig.level power ##   <chr>     <dbl> <dbl>  <dbl>  <dbl>   <dbl>     <dbl> <dbl> ## 1 X:S = 0 0.55784    NA 9.0291 11.868 0.01592      0.05   0.8 ##  ## Estimate of n: 164.9 ## 95% Predicted Confidence Interval: [163.3, 166.8]"},{"path":[]},{"path":"https://philchalmers.github.io/Spower/articles/original/gpower_examples.html","id":"example-26-3-difference-from-constant-one-sample-case","dir":"Articles > Original","previous_headings":"Variance tests","what":"Example 26.3; Difference from constant (one sample case)","title":"G*Power examples evaluated with Spower","text":"Solve nn variance ratio 1/1.5=2/31/1.5 = 2/3 using one-tailed variance ratio test, assuming target power 1−β=.801-\\beta=.80. G*power gives sample size 81.","code":"p_var.test(n=NA, vars=1, sigma2=1.5, two.tailed=FALSE) |>      Spower(power=.80, interval=c(10, 200)) ##  ## Execution time (H:M:S): 00:00:24 ## Design conditions:  ##  ## # A tibble: 1 × 6 ##       n  vars sigma2 two.tailed sig.level power ##   <dbl> <dbl>  <dbl> <lgl>          <dbl> <dbl> ## 1    NA     1    1.5 FALSE           0.05   0.8 ##  ## Estimate of n: 80.6 ## 95% Predicted Confidence Interval: [79.3, 82.2]"},{"path":"https://philchalmers.github.io/Spower/articles/original/gpower_examples.html","id":"example-15-3-two-sample-variance-test","dir":"Articles > Original","previous_headings":"Variance tests","what":"Example 15.3; Two-sample variance test","title":"G*Power examples evaluated with Spower","text":"two-sample equality variance test equal sample sizes, G*Power gives estimate 193 per group.","code":"# solve n for variance ratio of 1/1.5 = 2/3, two.tailed, 80% power p_var.test(n=NA, vars=c(1, 1.5), two.tailed=TRUE) |>      Spower(power=.80, interval=c(50, 300)) ##  ## Execution time (H:M:S): 00:00:32 ## Design conditions:  ##  ## # A tibble: 1 × 4 ##       n two.tailed sig.level power ##   <dbl> <lgl>          <dbl> <dbl> ## 1    NA TRUE            0.05   0.8 ##  ## Estimate of n: 193.4 ## 95% Predicted Confidence Interval: [191.5, 195.4]"},{"path":"https://philchalmers.github.io/Spower/articles/original/gpower_examples.html","id":"t-tests","dir":"Articles > Original","previous_headings":"","what":"t-tests","title":"G*Power examples evaluated with Spower","text":"Estimate sample size (nn) per group independent samples tt-test, one-tailed, medium effect size (d=0.5d=0.5), α=0.05\\alpha=0.05, 95% power (1−β=0.951-\\beta = 0.95), equal sample sizes (n2n1=1\\frac{n_2}{n_1}=1). G*power estimate 88 per group, Spower estimate 86.9348 95% CI [85.2011, 88.4739].","code":"(out <- p_t.test(n = NA, d = .5, two.tailed=FALSE) |>                  Spower(power = .95, interval=c(10,500))) ##  ## Execution time (H:M:S): 00:00:09 ## Design conditions:  ##  ## # A tibble: 1 × 5 ##       n     d two.tailed sig.level power ##   <dbl> <dbl> <lgl>          <dbl> <dbl> ## 1    NA   0.5 FALSE           0.05  0.95 ##  ## Estimate of n: 86.9 ## 95% Predicted Confidence Interval: [85.2, 88.5]"},{"path":"https://philchalmers.github.io/Spower/articles/original/gpower_examples.html","id":"example-19-3-paired-samples-t-test","dir":"Articles > Original","previous_headings":"t-tests","what":"Example 19.3; Paired samples t-test","title":"G*Power examples evaluated with Spower","text":"Paired-samples tt-test, assuming generated difference repeated measures Cohen’s dr=.421637d_r=.421637 (e.g., unadjusted d=.4d=.4, rxy=.55r_{xy} = .55, results repeated dr=|μx−μy|σx2+σy2−2ρxyσxσyd_r=\\frac{|\\mu_x-\\mu_y|}{\\sqrt{\\sigma^2_x + \\sigma^2_y - 2\\rho_{xy}\\sigma_x\\sigma_y}}). G*power gives power estimate .832, though Cohen reported value closer .840. d=0.2828427d=0.2828427 leads case G*Power 3.1 gives estimate .500. answer question “many subjects need arrive power 0.832114 two-group design?” specified within Spower() n set NA. G*power reports around N=110*2=220N=110*2=220 pairs required, though estimated visually using interpolation.","code":"p_t.test(n=50 * 2, d=0.421637, type = 'paired') |> Spower(replications=50000) ##  ## Execution time (H:M:S): 00:00:13 ## Design conditions:  ##  ## # A tibble: 1 × 4 ##         d type   sig.level power ##     <dbl> <chr>      <dbl> <lgl> ## 1 0.42164 paired      0.05 NA    ##  ## Estimate of power: 0.840 ## 95% Confidence Interval: [0.837, 0.843] p_t.test(n=50 * 2, d=.2828427, type = 'paired') |> Spower(replications=50000) ##  ## Execution time (H:M:S): 00:00:13 ## Design conditions:  ##  ## # A tibble: 1 × 4 ##         d type   sig.level power ##     <dbl> <chr>      <dbl> <lgl> ## 1 0.28284 paired      0.05 NA    ##  ## Estimate of power: 0.508 ## 95% Confidence Interval: [0.503, 0.512] p_t.test(n=NA, d=0.2828427, type = 'paired') |>      Spower(power=0.832114, interval=c(100,300)) ##  ## Execution time (H:M:S): 00:00:16 ## Design conditions:  ##  ## # A tibble: 1 × 5 ##       n       d type   sig.level   power ##   <dbl>   <dbl> <chr>      <dbl>   <dbl> ## 1    NA 0.28284 paired      0.05 0.83211 ##  ## Estimate of n: 215.9 ## 95% Predicted Confidence Interval: [213.7, 218.1]"},{"path":"https://philchalmers.github.io/Spower/articles/original/gpower_examples.html","id":"example-20-3-one-sample-t-test","dir":"Articles > Original","previous_headings":"t-tests","what":"Example 20.3; One-sample t-test","title":"G*Power examples evaluated with Spower","text":"Evaluating hypotheses mean expression H0:μ≤μ0H_0:\\mu\\le\\mu_0Ha:μ>μ0H_a:\\mu>\\mu_0 using one-sample tt-test. following estimates nn given one-tailed d=.625d=.625 achieve 1−β=.951-\\beta=.95. G*power gives sample size n=30n=30. Similarly, though different inputs. G*power gives sample size n=1492n=1492.","code":"p_t.test(n=NA, d=.625, two.tailed=FALSE, type='one.sample') |>       Spower(power=.95, interval=c(10, 100)) ##  ## Execution time (H:M:S): 00:00:07 ## Design conditions:  ##  ## # A tibble: 1 × 6 ##       n     d type       two.tailed sig.level power ##   <dbl> <dbl> <chr>      <lgl>          <dbl> <dbl> ## 1    NA 0.625 one.sample FALSE           0.05  0.95 ##  ## Estimate of n: 28.7 ## 95% Predicted Confidence Interval: [28.0, 29.4] p_t.test(n=NA, d=.1, type='one.sample') |>       Spower(power=.9,sig.level=.01, interval=c(100,2000)) ##  ## Execution time (H:M:S): 00:00:11 ## Design conditions:  ##  ## # A tibble: 1 × 5 ##       n     d type       sig.level power ##   <dbl> <dbl> <chr>          <dbl> <dbl> ## 1    NA   0.1 one.sample      0.01   0.9 ##  ## Estimate of n: 1509.8 ## 95% Predicted Confidence Interval: [1489.5, 1529.2]"},{"path":[]},{"path":"https://philchalmers.github.io/Spower/articles/original/gpower_examples.html","id":"example-22-3-one-sample-test-with-normal-distribution","dir":"Articles > Original","previous_headings":"t-tests > Wilcoxon tests","what":"Example 22.3; One-sample test with normal distribution","title":"G*Power examples evaluated with Spower","text":"Example 22.1 . G*power 3.1 provides power estimate .800, agreeing Spower. Similarly, assuming distribution one-sample followed Laplace distribution, N=11N=11 used instead. requires defining alternative parent distribution, uses rlaplace function extraDistr package. Interestingly, G*power 3.1 reports power 0.830.","code":"p_wilcox.test(n=649, d=.1, type='one.sample', two.tailed=FALSE) |> Spower() ##  ## Execution time (H:M:S): 00:00:12 ## Design conditions:  ##  ## # A tibble: 1 × 6 ##       n     d type       two.tailed sig.level power ##   <dbl> <dbl> <chr>      <lgl>          <dbl> <lgl> ## 1   649   0.1 one.sample FALSE           0.05 NA    ##  ## Estimate of power: 0.799 ## 95% Confidence Interval: [0.791, 0.806] library(extraDistr) parent1 <- function(n, d) extraDistr::rlaplace(n, mu=d, sigma=sqrt(1/2))  # properties of sampled distribution descript(parent1(n=100000, d=0.8)) ## # A tibble: 1 × 14 ##   VARS       n  miss  mean trimmed    sd   mad skewness kurtosis   min  Q_25 ##   <fct>  <dbl> <dbl> <dbl>   <dbl> <dbl> <dbl>    <dbl>    <dbl> <dbl> <dbl> ## 1 df    100000    NA 0.800   0.799 0.999 0.727  0.00702     3.06 -7.94 0.309 ## # ℹ 3 more variables: Q_50 <dbl>, Q_75 <dbl>, max <dbl> p_wilcox.test(n=11, d=.8, type='one.sample', two.tailed=FALSE, parent1 = parent1) |> Spower() ##  ## Execution time (H:M:S): 00:00:02 ## Design conditions:  ##  ## # A tibble: 1 × 6 ##       n     d type       two.tailed sig.level power ##   <dbl> <dbl> <chr>      <lgl>          <dbl> <lgl> ## 1    11   0.8 one.sample FALSE           0.05 NA    ##  ## Estimate of power: 0.815 ## 95% Confidence Interval: [0.807, 0.822]"},{"path":"https://philchalmers.github.io/Spower/articles/original/gpower_examples.html","id":"two-sample-test-with-laplace-distributions","dir":"Articles > Original","previous_headings":"t-tests > Wilcoxon tests","what":"Two-sample test with Laplace distributions","title":"G*Power examples evaluated with Spower","text":"Two-sample Wilcoxon test comparing Laplace distributions different central tendencies. Unlike Laplace distribution, G*power 3.1 seems agree Spower, power .847 reported. seems raise questions consistency results.","code":"library(extraDistr)  parent1 <- function(n, d) extraDistr::rlaplace(n, mu=d, sigma=sqrt(1/2)) parent2 <- function(n, d) extraDistr::rlaplace(n, sigma=sqrt(1/2))  # properties of sampled distributions descript(parent1(n=100000, d=0.375)) ## # A tibble: 1 × 14 ##   VARS       n  miss  mean trimmed    sd   mad skewness kurtosis   min   Q_25 ##   <fct>  <dbl> <dbl> <dbl>   <dbl> <dbl> <dbl>    <dbl>    <dbl> <dbl>  <dbl> ## 1 df    100000    NA 0.381   0.382 0.997 0.725   0.0256     3.02 -6.07 -0.107 ## # ℹ 3 more variables: Q_50 <dbl>, Q_75 <dbl>, max <dbl> descript(parent1(n=100000, d=0)) ## # A tibble: 1 × 14 ##   VARS       n  miss    mean trimmed    sd   mad skewness kurtosis   min   Q_25 ##   <fct>  <dbl> <dbl>   <dbl>   <dbl> <dbl> <dbl>    <dbl>    <dbl> <dbl>  <dbl> ## 1 df    100000    NA 0.00267 0.00272 1.000 0.726  0.00490     2.86 -8.77 -0.485 ## # ℹ 3 more variables: Q_50 <dbl>, Q_75 <dbl>, max <dbl> nr <- 134/67 p_wilcox.test(n=67, n2_n1=nr, d=0.375, parent1=parent1, parent2=parent2) |>      Spower() ##  ## Execution time (H:M:S): 00:00:06 ## Design conditions:  ##  ## # A tibble: 1 × 4 ##       n     d sig.level power ##   <dbl> <dbl>     <dbl> <lgl> ## 1    67 0.375      0.05 NA    ##  ## Estimate of power: 0.851 ## 95% Confidence Interval: [0.844, 0.858]"},{"path":"https://philchalmers.github.io/Spower/articles/original/gpower_examples.html","id":"example-23-3-paired-samples-test-with-laplace-distributions","dir":"Articles > Original","previous_headings":"t-tests > Wilcoxon tests","what":"Example 23.3: Paired-samples test with Laplace distributions","title":"G*Power examples evaluated with Spower","text":"Finally, paired-samples approach using Wilcoxon test N=10N=10. , simulation approach G*power 3.1 differ outputs, G*power 3.1 reported power 0.853.","code":"parent1 <- function(n, d) extraDistr::rlaplace(n, mu=d, sigma=sqrt(1/2)) parent2 <- function(n, d) extraDistr::rlaplace(n, sigma=sqrt(1/2))  descript(parent1(n=100000, d=1.13842)) ## # A tibble: 1 × 14 ##   VARS       n  miss  mean trimmed    sd   mad skewness kurtosis   min  Q_25 ##   <fct>  <dbl> <dbl> <dbl>   <dbl> <dbl> <dbl>    <dbl>    <dbl> <dbl> <dbl> ## 1 df    100000    NA  1.14    1.14 0.996 0.727   0.0158     2.93 -7.46 0.653 ## # ℹ 3 more variables: Q_50 <dbl>, Q_75 <dbl>, max <dbl> descript(parent1(n=100000, d=0)) ## # A tibble: 1 × 14 ##   VARS      n  miss     mean  trimmed    sd   mad skewness kurtosis   min   Q_25 ##   <fct> <dbl> <dbl>    <dbl>    <dbl> <dbl> <dbl>    <dbl>    <dbl> <dbl>  <dbl> ## 1 df      1e5    NA -0.00205 -0.00284  1.00 0.722   0.0147     3.16 -7.60 -0.490 ## # ℹ 3 more variables: Q_50 <dbl>, Q_75 <dbl>, max <dbl> p_wilcox.test(n=10*2, d=1.13842, type = 'paired',               parent1=parent1, parent2=parent2) |> Spower() ##  ## Execution time (H:M:S): 00:00:02 ## Design conditions:  ##  ## # A tibble: 1 × 4 ##        d type   sig.level power ##    <dbl> <chr>      <dbl> <lgl> ## 1 1.1384 paired      0.05 NA    ##  ## Estimate of power: 0.933 ## 95% Confidence Interval: [0.928, 0.938]"},{"path":"https://philchalmers.github.io/Spower/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Phil Chalmers. Author, maintainer.","code":""},{"path":"https://philchalmers.github.io/Spower/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Chalmers P (2026). Spower: Power Analyses using Monte Carlo Simulations. doi:10.32614/CRAN.package.Spower, R package version 0.5.2, https://CRAN.R-project.org/package=Spower.","code":"@Manual{,   title = {Spower: Power Analyses using Monte Carlo Simulations},   author = {Phil Chalmers},   year = {2026},   note = {R package version 0.5.2},   url = {https://CRAN.R-project.org/package=Spower},   doi = {10.32614/CRAN.package.Spower}, }"},{"path":"https://philchalmers.github.io/Spower/index.html","id":"spower-power-analyses-using-monte-carlo-simulations-","dir":"","previous_headings":"","what":"Power Analyses using Monte Carlo Simulations","title":"Power Analyses using Monte Carlo Simulations","text":"Spower Provides general purpose simulation-based power analysis API routine customized simulation experimental designs. package focuses exclusively Monte Carlo simulation experiment variants (expected) prospective power analyses, criterion analyses, compromise analyses, sensitivity analyses, priori/post-hoc analyses. default simulation experiment functions defined within package provide stochastic variants power analysis subroutines GPower 3.1 (Faul, Erdfelder, Buchner, Lang, 2009), along various parametric non-parametric power analysis applications (e.g., mediation analyses) support Bayesian power analysis way Bayes factors posterior probability evaluations. Additional functions building empirical power curves, reanalyzing simulation information, increasing precision resulting power estimates also included, utilize similar API structures. details see associated publication Chalmers (2025).","code":""},{"path":"https://philchalmers.github.io/Spower/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Power Analyses using Monte Carlo Simulations","text":"can install Spower CRAN: install development version Spower package, need install remotes package Spower package.","code":"install.packages(\"Spower\") install.packages(\"remotes\") remotes::install_github(\"philchalmers/Spower\")"},{"path":"https://philchalmers.github.io/Spower/index.html","id":"quick-start","dir":"","previous_headings":"","what":"Quick Start","title":"Power Analyses using Monte Carlo Simulations","text":"Spower requires two components: available function used generate exactly one simulation experiment returns one p-values given null hypothesis interest (alternative criteria return logical indicators posterior probabilities), use either Spower() SpowerCurve() perform desired prospective/post-hoc, priori, sensitivity, compromise, criterion power analysis. example, built-p_t.test() function performs t-tests using various inputs, sample size N=200N=200 supplied (n = 100 per group) Cohen’s dd .5 (-called “medium” effect). returns single pp-value given null hypotheses mean difference, single case returns ‘surprising’ result given null position tested. evaluate prospective power test simply requires passing simulation function Spower(), perform experiment 10,000 independent replications, collecting summarizing relevant information power analysis. Alternatively, priori sensitive analyses, respective input simulation function must set NA, within Spower() target power rate must included along suitable search interval range. target power set 1−β=.951-\\beta = .95, associated nn suspected lay somewhere within boundary [50,300][50,300]. Equivalently, function interval() can used instead placing interval range within Spower(). provide stochastic root finding task.","code":"library(Spower) p_t.test(n=100, d=0.5) ## [1] 0.001231514 set.seed(42) p_t.test(n=100, d=0.5) |> Spower()  ## ## Execution time (H:M:S): 00:00:02 ## Design conditions:  ## ## # A tibble: 1 × 4 ##       n     d sig.level power ##   <dbl> <dbl>     <dbl> <lgl> ## 1   100   0.5      0.05 NA    ##  ## Estimate of power: 0.943 ## 95% Confidence Interval: [0.938, 0.947] set.seed(01123581321)  # estimate the require n value to achieve a power of 1 - beta = .95  p_t.test(n=NA, d=0.5) |> Spower(power=.95, interval=c(50, 300))  ## Iter: 56; Median = 101; E(f(x)) = 0.00; Total.reps = 11000; k.tol = 2; Pred = 103.4 ## ## Execution time (H:M:S): 00:00:05 ## Design conditions:  ##  ## # A tibble: 1 × 4 ##       n     d sig.level power ##   <dbl> <dbl>     <dbl> <dbl> ## 1    NA   0.5      0.05  0.95 ##  ## Estimate of n: 103.4 ## 95% Predicted Confidence Interval: [101.5, 105.4] # using interval() function instead p_t.test(n=interval(50,300), d=0.5) |> Spower(power=.95)"},{"path":"https://philchalmers.github.io/Spower/index.html","id":"estimated-power-curves","dir":"","previous_headings":"","what":"Estimated power curves","title":"Power Analyses using Monte Carlo Simulations","text":"generate suitable power-curves given simulation power analysis criteria, simulation experiment can passed SpowerCurve() (SpowerBatch() first, SpowerCurve()). function contains similar specification structure Spower(), however differs arguments vary explicitly passed named vectors SpowerCurve(). example varying sample size (n), next example varies n effect size d.","code":"set.seed(8675309) # Jenny Jenny p_t.test(d=0.2) |> SpowerCurve(n=seq(50, 550, by=100)) p_t.test() |> SpowerCurve(n=seq(50, 350, by=50), d=c(.2, .3, .4, .5))"},{"path":"https://philchalmers.github.io/Spower/index.html","id":"vignettes","dir":"","previous_headings":"","what":"Vignettes","title":"Power Analyses using Monte Carlo Simulations","text":"package currently contains vignette demonstrating several examples GPower 3.1 manual, providing simulation-based replications analyses, well vignettes showing advanced applications package (ROPEs, Bayesian power analyses, precision criterion, Type S/M errors, etc).","code":""},{"path":"https://philchalmers.github.io/Spower/index.html","id":"getting-help-or-reporting-an-issue","dir":"","previous_headings":"","what":"Getting Help or Reporting an Issue","title":"Power Analyses using Monte Carlo Simulations","text":"report bugs/issues/feature requests, please file issue.","code":""},{"path":"https://philchalmers.github.io/Spower/index.html","id":"how-to-contribute","dir":"","previous_headings":"","what":"How to Contribute","title":"Power Analyses using Monte Carlo Simulations","text":"simulation experiment ’d like contribute form either feel free document function using roxygen2 style syntax open pull request. Otherwise, contributions can made online Wiki.","code":"# returns a p-value, P(D|H0) p_yourSimulation()  # returns a posterior probability, P(H1|D) pp_yourSimulation()  # returns a logical (more complex experiments, perhaps involing ROPEs) l_yourSimulation()"},{"path":"https://philchalmers.github.io/Spower/reference/Spower.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulation-based Power Analyses — Spower","title":"Simulation-based Power Analyses — Spower","text":"General purpose function provides power-focused estimates priori, prospective/post-hoc, compromise, sensitivity, criterion power analysis. Function provides general wrapper SimDesign package's runSimulation SimSolve functions. , parallel processing automatically supported, along progress bars, confidence/predicted confidence intervals results estimates, safety checks, . function SpowerBatch, hand, can used run Spower across different simulation combinations, returning list results instead. Can also used pre-computing step using SpowerCurve, shares syntax specification (see SpowerCurve examples). SpowerCurve draws power curves either ) estimate power given set varying conditions b) solves set root conditions given fixed values power. Confidence/predicted confidence intervals included output reflect estimate uncertainties, though note fewer replications/iterations used compared Spower goal visualization competing variable inputs rather precision given input.","code":""},{"path":"https://philchalmers.github.io/Spower/reference/Spower.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulation-based Power Analyses — Spower","text":"","code":"Spower(   ...,   power = NA,   sig.level = 0.05,   interval,   beta_alpha,   sig.direction = \"below\",   replications = 10000,   integer,   parallel = FALSE,   cl = NULL,   packages = NULL,   ncores = parallelly::availableCores(omit = 1L),   predCI = 0.95,   predCI.tol = 0.01,   verbose = interactive(),   check.interval = FALSE,   maxiter = 150,   wait.time = NULL,   lastSpower = NULL,   select = NULL,   control = list() )  # S3 method for class 'Spower' print(x, ...)  # S3 method for class 'Spower' as.data.frame(x, ...)  SpowerBatch(   ...,   interval = NULL,   power = NA,   sig.level = 0.05,   beta_alpha = NULL,   sig.direction = \"below\",   replications = 10000,   integer,   fully.crossed = TRUE,   parallel = FALSE,   cl = NULL,   ncores = parallelly::availableCores(omit = 1L),   predCI = 0.95,   predCI.tol = 0.01,   verbose = interactive(),   check.interval = FALSE,   maxiter = 150,   wait.time = NULL,   select = NULL,   control = list() )  # S3 method for class 'SpowerBatch' print(x, ...)  # S3 method for class 'SpowerBatch' as.data.frame(x, ...)  SpowerCurve(   ...,   interval = NULL,   power = NA,   sig.level = 0.05,   sig.direction = \"below\",   replications = 2500,   integer,   plotCI = TRUE,   plotly = TRUE,   parallel = FALSE,   cl = NULL,   ncores = parallelly::availableCores(omit = 1L),   predCI = 0.95,   predCI.tol = 0.01,   verbose = interactive(),   check.interval = FALSE,   maxiter = 50,   wait.time = NULL,   select = NULL,   batch = NULL,   control = list() )  interval(lower, upper, integer, check.interval = FALSE)"},{"path":"https://philchalmers.github.io/Spower/reference/Spower.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulation-based Power Analyses — Spower","text":"... expression use simulation returns numeric vector containing either p-value (null hypothesis), probability alternative hypothesis Bayesian setting, first numeric value vector treated focus analyses prospective/post-hoc power. corresponds alpha value used flag samples 'significant' evaluating null hypothesis (via p-values; \\(P(D|H_0)\\)), returned p-value less sig.level indicates significance. However, sig.direction = '' values sig.level flagged significant, useful Bayesian posterior probability contexts focus alternative hypothesis, \\(P(H_1|D)\\). Alternatively, logical vector can returned (e.g., using confidence intervals (CIs) evaluating regions practical equivalence (ROPEs)), average TRUE/FALSE vector corresponds empirical power. Finally, named list data.frame can returned instead need general, heterogeneous objects, however specific element extract must specified using select argument indicate list elements used power computations. elements simulation can, however, extracted SimResults function. SpowerCurve SpowerBatch, first expression input must identical ... Spower, remaining named inputs must match arguments expression indicate variables modified resulting power curves. Providing NA values also supported solve missing component.  Note first three named arguments SpowerCurve plotted using x-y, colour, facet wrap aesthetics, respectively. However, necessary data can extracted visualizations via ggplot_build provide customized control power power level use. set NA (default) empirical power  estimated given fixed ... inputs (e.g., prospective/post-hoc power analysis). SpowerCurve SpowerBatch can vector sig.level alpha level use (default .05). set NA value estimated given fixed conditions input (e.g., criterion power analysis). used value returned experiment numeric (e.g., p-value, posterior probability; see sig.direction). return supplied experiment logical argument entirely ignored. , arguments conf.level included simulation experiment definition indicate explicit inferential criteria, argument can manipulated need arise. interval required search interval use SimSolve called perform stochastic root solving. Note compromise analyses, sig.level set NA, set explicitly interval default c(0,1). Alternatively, function interval can used within experiment function definition canonical NA placeholder used. Arguments interval extracted passed Spower usual beta_alpha (optional) ratio use compromise analyses corresponding Type II errors (beta) Type error (alpha). Ratios greater \\(q = \\beta/\\alpha = 1\\) indicate Type errors worse Type II, ratios less one opposite. ratio equal 1 gives equal trade-Type Type II errors sig.direction character vector either '' (default) '' indicate direction relative sig.level considered significant. useful, instance, forming cutoffs Bayesian posterior probabilities organized show support hypothesis interest (\\(P(H_1|D)\\)). example, setting sig.level = .95 sig.direction = '' flags sample 'significant' whenever posterior probability greater .95. replications number replications use runSimulation required. Default 10000, though set 2500 SpowerCurve integer logical value indicating whether search iterations use integers doubles. missing, automatically set FALSE interval contains non-integer numbers range less 5, well sig.level = NA parallel parallel computing slower simulation experiments (see runSimulation details). cl see runSimulation packages see runSimulation ncores see runSimulation predCI predicting confidence interval level (see SimSolve) predCI.tol predicting confidence interval consistency tolerance stochastic root solver convergence (see SimSolve). Default converges power rate CI consistently within .01/2 target power verbose logical; information printed console? default determined based whether session interactive check.interval logical; check interval range validity (see SimSolve). Disabled default maxiter maximum number stochastic root-solving iterations. Default 150, though set 50 SpowerCurve wait.time (optional) argument indicate time wait (specified minutes supplied numeric vector). See SimSolve details See timeFormater specifications lastSpower previously returned Spower object updated. Use want continue estimate left wish increase precision (e.g., adding replications, letting stochastic root solver continue searching). Note object stored use getLastSpower obtain last estimated power object select character vector indicating elements extract provided stimulation experiment function. default, elements provided function used, however provided function contains information relevant power computations (e.g., parameter estimates, standard errors, etc) ignored. extract complete results post-analysis use SimResults allow manual summarizing stored results (applicable prospective/post-hoc power) control list control parameters pass runSimulation SimSolve x object class 'Spower'. SpowerBatch used list fully.crossed logical; supplied conditions SpowerBatch fully crossed? Passed argument documented createDesign plotCI logical; include confidence/predicted confidence intervals plots? plotly logical; draw graphic interactive plotly interface? FALSE ggplot2 object returned instead batch SpowerBatch previously used perform computations information can provided batch argument avoid recomputing lower lower bound stochastic search interval. input contains decimal Spower(..., integer) set FALSE upper upper bound stochastic search interval. input contains decimal Spower(..., integer) set FALSE","code":""},{"path":"https://philchalmers.github.io/Spower/reference/Spower.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulation-based Power Analyses — Spower","text":"invisible tibble/data.frame-type object class 'Spower' containing power results simulation experiment ggplot2 object automatically rendered plotly interactivity","code":""},{"path":"https://philchalmers.github.io/Spower/reference/Spower.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulation-based Power Analyses — Spower","text":"Five types power analysis flavors can performed Spower, triggered based supplied input set missing (NA): Priori Solve missing sample size component (e.g., n) achieve specific target power rate Prospective Post-hoc Estimate power rate given set fixed conditions. estimates effect sizes empirical characteristics (e.g., observed sample size) supplied results observed/retrospective power (recommended), sample size included observed quantity, effect sizes treated unknown, results post-hoc power (Cohen, 1988) Sensitivity Solve missing effect size value function supplied constant components Criterion Solve error rate (argument sig.level) function supplied constant components Compromise Solve Type /Type II error trade-ratio function supplied constant components target ratio \\(q = \\beta/\\alpha\\) (argument beta_alpha) understand package structured, first expression ... argument, contains simulation experiment definition single sample, passed either SimSolve runSimulation depending element (including power sig.level arguments) set NA. instance, Spower(p_t.test(n=50, d=.5)) perform prospective/post-hoc power evaluation since power = NA default, Spower(p_t.test(n=NA, d=.5), power = .80) perform priori power analysis solve missing n argument. expected power computations, arguments simulation experiment arguments can specified function reflect prior uncertainty. instance, d_prior <- function() rnorm(1, mean=.5, sd=1/8) Spower(p_t.test(n=50, d=d_prior()) compute expected power prior sampling distribution d","code":""},{"path":[]},{"path":"https://philchalmers.github.io/Spower/reference/Spower.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Simulation-based Power Analyses — Spower","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/Spower/reference/Spower.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulation-based Power Analyses — Spower","text":"","code":"############################ # Independent samples t-test ############################  # Internally defined p_t.test function args(p_t.test)    # missing arguments required #> function (n, d, mu = 0, r = NULL, type = \"two.sample\", n2_n1 = 1,  #>     two.tailed = TRUE, var.equal = TRUE, means = NULL, sds = NULL,  #>     conf.level = 0.95, gen_fun = gen_t.test, return_analysis = FALSE,  #>     ...)  #> NULL # help(p_t.test)  # additional information  # p_* functions generate data and return single p-value p_t.test(n=50, d=.5) #> [1] 0.2536089 p_t.test(n=50, d=.5) #> [1] 0.08591039  # test that it works Spower(p_t.test(n = 50, d = .5), replications=10) #>  #> Execution time (H:M:S): 00:00:00 #> Design conditions:  #>  #> # A tibble: 1 × 4 #>       n     d sig.level power #>   <dbl> <dbl>     <dbl> <lgl> #> 1    50   0.5      0.05 NA    #>  #> Estimate of power: 0.800 #> 95% Confidence Interval: [0.552, 1.000]  # also behaves naturally with a pipe p_t.test(n = 50, d = .5) |> Spower(replications=10) #>  #> Execution time (H:M:S): 00:00:00 #> Design conditions:  #>  #> # A tibble: 1 × 4 #>       n     d sig.level power #>   <dbl> <dbl>     <dbl> <lgl> #> 1    50   0.5      0.05 NA    #>  #> Estimate of power: 0.800 #> 95% Confidence Interval: [0.552, 1.000]  # \\donttest{  # Estimate power given fixed inputs (prospective power analysis) out <- Spower(p_t.test(n = 50, d = .5)) summary(out)   # extra information #> $sessionInfo #> ─ Session info ─────────────────────────────────────────────────────────────── #>  setting  value #>  version  R version 4.5.2 (2025-10-31) #>  os       Ubuntu 24.04.3 LTS #>  system   x86_64, linux-gnu #>  ui       X11 #>  language en #>  collate  C #>  ctype    C.UTF-8 #>  tz       UTC #>  date     2026-02-10 #>  pandoc   3.1.11 @ /opt/hostedtoolcache/pandoc/3.1.11/x64/ (via rmarkdown) #>  quarto   NA #>  #> ─ Packages ─────────────────────────────────────────────────────────────────── #>  package      * version  date (UTC) lib source #>  abind          1.4-8    2024-09-12 [1] RSPM #>  askpass        1.2.1    2024-10-04 [1] RSPM #>  audio          0.1-12   2025-12-15 [1] RSPM #>  beepr          2.0      2024-07-06 [1] RSPM #>  brio           1.1.5    2024-04-24 [1] RSPM #>  bslib          0.10.0   2026-01-26 [1] RSPM #>  cachem         1.1.0    2024-05-16 [1] RSPM #>  car            3.1-5    2026-02-03 [1] RSPM #>  carData        3.0-6    2026-01-30 [1] RSPM #>  class          7.3-23   2025-01-01 [3] CRAN (R 4.5.2) #>  cli            3.6.5    2025-04-23 [1] RSPM #>  clipr          0.8.0    2022-02-22 [1] RSPM #>  cocor          1.1-4    2022-06-28 [1] RSPM #>  codetools      0.2-20   2024-03-31 [3] CRAN (R 4.5.2) #>  curl           7.0.0    2025-08-19 [1] RSPM #>  data.table     1.18.2.1 2026-01-27 [1] RSPM #>  desc           1.4.3    2023-12-10 [1] RSPM #>  digest         0.6.39   2025-11-19 [1] RSPM #>  downlit        0.4.5    2025-11-14 [1] RSPM #>  dplyr          1.2.0    2026-02-03 [1] RSPM #>  e1071          1.7-17   2025-12-18 [1] RSPM #>  EnvStats       3.1.0    2025-04-24 [1] RSPM #>  evaluate       1.0.5    2025-08-27 [1] RSPM #>  fansi          1.0.7    2025-11-19 [1] RSPM #>  farver         2.1.2    2024-05-13 [1] RSPM #>  fastmap        1.2.0    2024-05-15 [1] RSPM #>  fontawesome    0.5.3    2024-11-16 [1] RSPM #>  Formula        1.2-5    2023-02-24 [1] RSPM #>  fs             1.6.6    2025-04-12 [1] RSPM #>  future         1.69.0   2026-01-16 [1] RSPM #>  future.apply   1.20.1   2025-12-09 [1] RSPM #>  generics       0.1.4    2025-05-09 [1] RSPM #>  ggplot2        4.0.2    2026-02-03 [1] RSPM #>  globals        0.19.0   2026-02-02 [1] RSPM #>  glue           1.8.0    2024-09-30 [1] RSPM #>  gtable         0.3.6    2024-10-25 [1] RSPM #>  htmltools      0.5.9    2025-12-04 [1] RSPM #>  htmlwidgets    1.6.4    2023-12-06 [1] RSPM #>  httr           1.4.7    2023-08-15 [1] RSPM #>  httr2          1.2.2    2025-12-08 [1] RSPM #>  jquerylib      0.1.4    2021-04-26 [1] RSPM #>  jsonlite       2.0.0    2025-03-27 [1] RSPM #>  knitr          1.51     2025-12-20 [1] RSPM #>  lavaan         0.6-21   2025-12-21 [1] RSPM #>  lazyeval       0.2.2    2019-03-15 [1] RSPM #>  lifecycle      1.0.5    2026-01-08 [1] RSPM #>  listenv        0.10.0   2025-11-02 [1] RSPM #>  magrittr       2.0.4    2025-09-12 [1] RSPM #>  memoise        2.0.1    2021-11-26 [1] RSPM #>  mnormt         2.1.2    2026-01-27 [1] RSPM #>  openssl        2.3.4    2025-09-30 [1] RSPM #>  otel           0.2.0    2025-08-29 [1] RSPM #>  parallelly     1.46.1   2026-01-08 [1] RSPM #>  pbapply        1.7-4    2025-07-20 [1] RSPM #>  pbivnorm       0.6.0    2015-01-23 [1] RSPM #>  pillar         1.11.1   2025-09-17 [1] RSPM #>  pkgconfig      2.0.3    2019-09-22 [1] RSPM #>  pkgdown        2.2.0    2025-11-06 [1] any (@2.2.0) #>  plotly         4.12.0   2026-01-24 [1] RSPM #>  progressr      0.18.0   2025-11-06 [1] RSPM #>  proxy          0.4-29   2025-12-29 [1] RSPM #>  purrr          1.2.1    2026-01-09 [1] RSPM #>  quadprog       1.5-8    2019-11-20 [1] RSPM #>  R.methodsS3    1.8.2    2022-06-13 [1] RSPM #>  R.oo           1.27.1   2025-05-02 [1] RSPM #>  R.utils        2.13.0   2025-02-24 [1] RSPM #>  R6             2.6.1    2025-02-15 [1] RSPM #>  ragg           1.5.0    2025-09-02 [1] RSPM #>  rappdirs       0.3.4    2026-01-17 [1] RSPM #>  RColorBrewer   1.1-3    2022-04-03 [1] RSPM #>  rlang          1.1.7    2026-01-09 [1] RSPM #>  rmarkdown      2.30     2025-09-28 [1] RSPM #>  S7             0.2.1    2025-11-14 [1] RSPM #>  sass           0.4.10   2025-04-11 [1] RSPM #>  scales         1.4.0    2025-04-24 [1] RSPM #>  sessioninfo    1.2.3    2025-02-05 [1] RSPM #>  SimDesign    * 2.23     2026-02-10 [1] CRAN (R 4.5.2) #>  Spower       * 0.5.2    2026-02-10 [1] local #>  systemfonts    1.3.1    2025-10-01 [1] RSPM #>  testthat       3.3.2    2026-01-11 [1] RSPM #>  textshaping    1.0.4    2025-10-10 [1] RSPM #>  tibble         3.3.1    2026-01-11 [1] RSPM #>  tidyr          1.3.2    2025-12-19 [1] RSPM #>  tidyselect     1.2.1    2024-03-11 [1] RSPM #>  vctrs          0.7.1    2026-01-23 [1] RSPM #>  viridisLite    0.4.3    2026-02-04 [1] RSPM #>  whisker        0.4.1    2022-12-05 [1] RSPM #>  withr          3.0.2    2024-10-28 [1] RSPM #>  xfun           0.56     2026-01-18 [1] RSPM #>  xml2           1.5.2    2026-01-17 [1] RSPM #>  yaml           2.3.12   2025-12-10 [1] RSPM #>  #>  [1] /home/runner/work/_temp/Library #>  [2] /opt/R/4.5.2/lib/R/site-library #>  [3] /opt/R/4.5.2/lib/R/library #>  * ── Packages attached to the search path. #>  #> ────────────────────────────────────────────────────────────────────────────── #>  #> $packages #>   packages versions #> 1   Spower    0.5.2 #>  #> $seeds #> [1] 1629703387 #>  #> $ncores #> [1] 1 #>  #> $date_completed #> [1] Tue Feb 10 15:57:59 2026 #>  #> $total_elapsed_time #> [1] 2.94s #>  #> $SEED_history #> [1] 1629703387 #>  #> $power.CI #>          CI_2.5   CI_97.5 #> power 0.6805321 0.6986679 #>  as.data.frame(out)  # coerced to data.frame #>        n   d sig.level  power    CI_2.5   CI_97.5 #> power 50 0.5      0.05 0.6896 0.6805321 0.6986679  # increase precision (not run) # p_t.test(n = 50, d = .5) |> Spower(replications=30000)  # alternatively, increase precision from previous object. #   Here we add 20000 more replications on top of the previous 10000 p_t.test(n = 50, d = .5) |>   Spower(replications=20000, lastSpower=out) -> out2 out2$REPLICATIONS  # total of 30000 replications for estimate #> [1] 30000  # previous analysis not stored to object, but can be retrieved out <- getLastSpower() out   # as though it were stored from Spower() #>  #> Execution time (H:M:S): 00:00:05 #> Design conditions:  #>  #> # A tibble: 1 × 4 #>       n     d sig.level power #>   <dbl> <dbl>     <dbl> <lgl> #> 1    50   0.5      0.05 NA    #>  #> Estimate of power: 0.691 #> 95% Confidence Interval: [0.686, 0.697]  # Same as above, but executed with multiple cores (not run) p_t.test(n = 50, d = .5) |>    Spower(replications=30000, parallel=TRUE, ncores=2) #>  #> Execution time (H:M:S): 00:00:04 #> Design conditions:  #>  #> # A tibble: 1 × 4 #>       n     d sig.level power #>   <dbl> <dbl>     <dbl> <lgl> #> 1    50   0.5      0.05 NA    #>  #> Estimate of power: 0.700 #> 95% Confidence Interval: [0.695, 0.705]  # Solve N to get .80 power (a priori power analysis) p_t.test(n = NA, d = .5) |>   Spower(power=.8, interval=c(2,500)) -> out summary(out)  # extra information #> $root #> [1] 63.20207 #>  #> $predCI.root #>   CI_2.5  CI_97.5  #> 62.54397 63.86085  #>  #> $b #> [1] 0.8 #>  #> $predCI.b #> [1] 0.7951549 0.8047590 #>  #> $terminated_early #> [1] TRUE #>  #> $time #> [1] 37.19s #>  #> $iterations #> [1] 145 #>  #> $total.replications #> [1] 55400 #>  #> $tab #>            y  x  reps #> 7  0.7594595 60   370 #> 8  0.7848312 61 21030 #> 9  0.7914634 62 10660 #> 10 0.7984745 63 19010 #> 11 0.8091954 64   870 #> 12 0.8088496 65  1130 #> 13 0.8021739 67   460 #> 15 0.8222222 69   450 #>  plot(out)  plot(out, type = 'history')   # total sample size required ceiling(out$n) * 2 #> [1] 128  # equivalently, using interval() within the experiment definition instead p_t.test(n = interval(2,500), d = .5) |> Spower(power=.8) #>  #> Execution time (H:M:S): 00:00:26 #> Design conditions:  #>  #> # A tibble: 1 × 4 #>       n     d sig.level power #>   <dbl> <dbl>     <dbl> <dbl> #> 1    NA   0.5      0.05   0.8 #>  #> Estimate of n: 64.1 #> 95% Predicted Confidence Interval: [63.3, 64.9]  # same as above, but in parallel with 2 cores out.par <- p_t.test(n = interval(2,500), d = .5) |>   Spower(power=.8, parallel=TRUE, ncores=2) summary(out.par) #> $root #> [1] 63.19998 #>  #> $predCI.root #>   CI_2.5  CI_97.5  #> 62.55317 63.91759  #>  #> $b #> [1] 0.8 #>  #> $predCI.b #> [1] 0.7950159 0.8048931 #>  #> $terminated_early #> [1] TRUE #>  #> $time #> [1] 45.03s #>  #> $iterations #> [1] 126 #>  #> $total.replications #> [1] 45900 #>  #> $tab #>            y  x  reps #> 4  0.7647059 60   340 #> 5  0.7805012 61 12770 #> 6  0.7880565 62  9210 #> 7  0.8008004 63 19990 #> 8  0.8000000 64   780 #> 9  0.8083333 65   840 #> 10 0.8043478 66   460 #>   # similar information from pwr package (pwr <- pwr::pwr.t.test(d=.5, power=.80)) #>  #>      Two-sample t test power calculation  #>  #>               n = 63.76561 #>               d = 0.5 #>       sig.level = 0.05 #>           power = 0.8 #>     alternative = two.sided #>  #> NOTE: n is number in *each* group #>  ceiling(pwr$n) * 2 #> [1] 128  # If greater precision is required and the user has a specific amount of time # they are willing to wait (e.g., 5 minutes) then wait.time can be used. Below # estimates root after searching for 1 minute, and run in parallel #  with 2 cores (not run) p_t.test(n = NA, d = .5) |>   Spower(power=.8, interval=c(2,500), wait.time='1', parallel=TRUE, ncores=2) #>  #> Execution time (H:M:S): 00:01:00 #> Design conditions:  #>  #> # A tibble: 1 × 4 #>       n     d sig.level power #>   <dbl> <dbl>     <dbl> <dbl> #> 1    NA   0.5      0.05   0.8 #>  #> Estimate of n: 63.3 #> 95% Predicted Confidence Interval: [62.8, 63.8]  # Similiar to above for precision improvements, however letting #  the root solver continue searching from an early search history. #  Usually a good idea to increase the maxiter and lower the predCI.tol p_t.test(n = NA, d = .5) |>   Spower(power=.8, interval=c(2,500), lastSpower=out,         maxiter=200, predCI.tol=.008) #starts at last iteration in \"out\" #>  #> Execution time (H:M:S): 00:00:18 #> Design conditions:  #>  #> # A tibble: 1 × 4 #>       n     d sig.level power #>   <dbl> <dbl>     <dbl> <dbl> #> 1    NA   0.5      0.05   0.8 #>  #> Estimate of n: 63.4 #> 95% Predicted Confidence Interval: [62.8, 64.0]  # Solve d to get .80 power (sensitivity power analysis) p_t.test(n = 50, d = NA) |> Spower(power=.8, interval=c(.1, 2)) #>  #> Execution time (H:M:S): 00:00:17 #> Design conditions:  #>  #> # A tibble: 1 × 4 #>       n     d sig.level power #>   <dbl> <dbl>     <dbl> <dbl> #> 1    50    NA      0.05   0.8 #>  #> Estimate of d: 0.567 #> 95% Predicted Confidence Interval: [0.564, 0.571] pwr::pwr.t.test(n=50, power=.80) # compare #>  #>      Two-sample t test power calculation  #>  #>               n = 50 #>               d = 0.565858 #>       sig.level = 0.05 #>           power = 0.8 #>     alternative = two.sided #>  #> NOTE: n is number in *each* group #>   # Solve alpha that would give power of .80 (criterion power analysis) #    interval not required (set to interval = c(0, 1)) p_t.test(n = 50, d = .5) |> Spower(power=.80, sig.level=NA) #>  #> Execution time (H:M:S): 00:00:16 #> Design conditions:  #>  #> # A tibble: 1 × 4 #>       n     d sig.level power #>   <dbl> <dbl>     <dbl> <dbl> #> 1    50   0.5        NA   0.8 #>  #> Estimate of sig.level: 0.098 #> 95% Predicted Confidence Interval: [0.096, 0.101]  # Solve beta/alpha ratio to specific error trade-off constant #   (compromise power analysis) out <- p_t.test(n = 50, d = .5) |> Spower(beta_alpha = 2) with(out, (1-power)/sig.level)   # solved ratio #> [1] 2  # update beta_alpha criteria without re-simulating (out2 <- update(out, beta_alpha=4)) #>  #> Execution time (H:M:S): 00:00:02 #> Design conditions:  #>  #> # A tibble: 1 × 5 #>       n     d sig.level power beta_alpha #>   <dbl> <dbl>     <dbl> <lgl>      <dbl> #> 1    50   0.5        NA NA             4 #>  #> Estimate of Type I error rate (alpha/sig.level): 0.066 #> 95% Confidence Interval: [0.061, 0.071] #>  #> Estimate of power (1-beta): 0.736 #> 95% Confidence Interval: [0.728, 0.745] with(out2, (1-power)/sig.level)   # solved ratio #> [1] 4  ############## # Power Curves ##############  # SpowerCurve() has similar input, though requires varying argument p_t.test(d=.5) |> SpowerCurve(n=c(30, 60, 90))  # solve n given power and plot p_t.test(n=NA, d=.5) |> SpowerCurve(power=c(.2, .5, .8), interval=c(2,500))  # multiple varying components p_t.test() |> SpowerCurve(n=c(30,60,90), d=c(.2, .5, .8))  ################ # Expected Power ################  # Expected power computed by including effect size uncertainty. # For instance, belief is that the true d is somewhere around d ~ N(.5, 1/8) dprior <- function(x, mean=.5, sd=1/8) dnorm(x, mean=mean, sd=sd) curve(dprior, -1, 2, main=expression(d %~% N(0.5, 1/8)),       xlab='d', ylab='density')   # For Spower, define prior sampler for specific parameter(s) d_prior <- function() rnorm(1, mean=.5, sd=1/8) d_prior(); d_prior(); d_prior() #> [1] 0.4319688 #> [1] 0.4183137 #> [1] 0.4856814  # Replace d constant with d_prior to compute expected power p_t.test(n = 50, d = d_prior()) |> Spower() #> Error in d_prior(): could not find function \"d_prior\"  # A priori power analysis using expected power p_t.test(n = NA, d = d_prior()) |>   Spower(power=.8, interval=c(2,500)) #> Error in d_prior(): could not find function \"d_prior\" pwr::pwr.t.test(d=.5, power=.80) # expected power result higher than fixed d #>  #>      Two-sample t test power calculation  #>  #>               n = 63.76561 #>               d = 0.5 #>       sig.level = 0.05 #>           power = 0.8 #>     alternative = two.sided #>  #> NOTE: n is number in *each* group #>    ############### # Customization ###############  #   Make edits to the function for customization if(interactive()){     p_my_t.test <- edit(p_t.test)     args(p_my_t.test)     body(p_my_t.test) }  # Alternatively, define a custom function (potentially based on the template) p_my_t.test <- function(n, d, var.equal=FALSE, n2_n1=1, df=10){      # Welch power analysis with asymmetric distributions     # group2 as large as group1 by default      # degree of skewness controlled via chi-squared distribution's df     group1 <- rchisq(n, df=df)     group1 <-  (group1 - df) / sqrt(2*df)   # Adjusted mean to 0, sd = 1     group2 <- rnorm(n*n2_n1, mean=d)     dat <- data.frame(group = factor(rep(c('G1', 'G2'),                                      times = c(n, n*n2_n1))),               DV = c(group1, group2))     obj <- t.test(DV ~ group, dat, var.equal=var.equal)     p <- obj$p.value     p }  # Solve N to get .80 power (a priori power analysis), using defaults p_my_t.test(n = NA, d = .5, n2_n1=2) |>   Spower(power=.8, interval=c(2,500)) -> out  # total sample size required with(out, ceiling(n) + ceiling(n * 2)) #> [1] 152  # Solve N to get .80 power (a priori power analysis), assuming #   equal variances, group2 2x as large as group1, large skewness p_my_t.test(n = NA, d=.5, var.equal=TRUE, n2_n1=2, df=3) |>   Spower(power=.8, interval=c(30,100)) -> out2  # total sample size required with(out2, ceiling(n) + ceiling(n * 2)) #> [1] 147  # prospective power, can be used to extract the adjacent information p_my_t.test(n = 100, d = .5) |> Spower() -> post  ############################### # Using CIs instead of p-values ###############################  # CI test returning TRUE if psi0 is outside the 95% CI ci_ind.t.test <- function(n, d, psi0=0, conf.level=.95){   g1 <- rnorm(n)   g2 <- rnorm(n, mean=d)   CI <- t.test(g2, g1, var.equal=TRUE,conf.level=conf.level)$conf.int   is.outside_CI(psi0, CI) }  # returns logical ci_ind.t.test(n=100, d=.2) #> [1] TRUE ci_ind.t.test(n=100, d=.2) #> [1] FALSE  # simulated prospective power ci_ind.t.test(n=100, d=.2) |> Spower() #>  #> Execution time (H:M:S): 00:00:02 #> Design conditions:  #>  #> # A tibble: 1 × 4 #>       n     d sig.level power #>   <dbl> <dbl>     <dbl> <lgl> #> 1   100   0.2      0.05 NA    #>  #> Estimate of power: 0.291 #> 95% Confidence Interval: [0.282, 0.300]  # compare to pwr package pwr::pwr.t.test(n=100, d=.2) #>  #>      Two-sample t test power calculation  #>  #>               n = 100 #>               d = 0.2 #>       sig.level = 0.05 #>           power = 0.2906459 #>     alternative = two.sided #>  #> NOTE: n is number in *each* group #>   ############################ # Equivalence test power using CIs # # H0: population d is outside interval [LB, UB] (not tolerably equivalent) # H1: population d is within interval [LB, UB]  (tolerably equivalent)  # CI test returning TRUE if CI is within tolerable equivalence range (tol) ci_equiv.t.test <- function(n, d, tol, conf.level=.95){   g1 <- rnorm(n)   g2 <- rnorm(n, mean=d)   CI <- t.test(g2, g1, var.equal=TRUE,conf.level=conf.level)$conf.int   is.CI_within(CI, tol) }  # evaluate if CI is within tolerable interval (tol) ci_equiv.t.test(n=1000, d=.2, tol=c(.1, .3)) #> [1] FALSE  # simulated prospective power ci_equiv.t.test(n=1000, d=.2, tol=c(.1, .3)) |> Spower() #>  #> Execution time (H:M:S): 00:00:03 #> Design conditions:  #>  #> # A tibble: 1 × 4 #>       n     d sig.level power #>   <dbl> <dbl>     <dbl> <lgl> #> 1  1000   0.2      0.05 NA    #>  #> Estimate of power: 0.227 #> 95% Confidence Interval: [0.218, 0.235]  # higher power with larger N (more precision) or wider tol interval ci_equiv.t.test(n=2000, d=.2, tol=c(.1, .3)) |> Spower() #>  #> Execution time (H:M:S): 00:00:04 #> Design conditions:  #>  #> # A tibble: 1 × 4 #>       n     d sig.level power #>   <dbl> <dbl>     <dbl> <lgl> #> 1  2000   0.2      0.05 NA    #>  #> Estimate of power: 0.771 #> 95% Confidence Interval: [0.763, 0.779] ci_equiv.t.test(n=1000, d=.2, tol=c(.1, .5)) |> Spower() #>  #> Execution time (H:M:S): 00:00:03 #> Design conditions:  #>  #> # A tibble: 1 × 4 #>       n     d sig.level power #>   <dbl> <dbl>     <dbl> <lgl> #> 1  1000   0.2      0.05 NA    #>  #> Estimate of power: 0.611 #> 95% Confidence Interval: [0.601, 0.620]  #### # superiority test (one-tailed) # H0: population d is less than LB    (not superior) # H1: population d is greater than LB (superior)  # set upper bound to Inf as it's not relevant, and reduce conf.level #   to reflect one-tailed test ci_equiv.t.test(n=1000, d=.2, tol=c(.1, Inf), conf.level=.90) |>   Spower() #>  #> Execution time (H:M:S): 00:00:03 #> Design conditions:  #>  #> # A tibble: 1 × 5 #>       n     d conf.level sig.level power #>   <dbl> <dbl>      <dbl>     <dbl> <lgl> #> 1  1000   0.2        0.9      0.05 NA    #>  #> Estimate of power: 0.730 #> 95% Confidence Interval: [0.722, 0.739]  # higher LB means greater requirement for defining superiority (less power) ci_equiv.t.test(n=1000, d=.2, tol=c(.15, Inf), conf.level=.90) |>   Spower() #>  #> Execution time (H:M:S): 00:00:03 #> Design conditions:  #>  #> # A tibble: 1 × 5 #>       n     d conf.level sig.level power #>   <dbl> <dbl>      <dbl>     <dbl> <lgl> #> 1  1000   0.2        0.9      0.05 NA    #>  #> Estimate of power: 0.308 #> 95% Confidence Interval: [0.299, 0.317]  # }  ############################################## # SpowerBatch() examples ##############################################  if (FALSE) { # \\dontrun{  # estimate power given varying sample sizes p_t.test(d=0.2) |>   SpowerBatch(n=c(30, 90, 270, 550), replications=1000) -> nbatch nbatch  # can be stacked to view the output as data.frame as.data.frame(nbatch)  # plot with SpowerCurve() SpowerCurve(batch=nbatch)  # equivalent, but re-runs the computations p_t.test(d=0.2) |> SpowerCurve(n=c(30, 90, 270, 550), replications=1000)  # estimate power given varying sample sizes and effect size p_t.test() |> SpowerBatch(n=c(30, 90, 270, 550),                           d=c(.2, .5, .8), replications=1000) -> ndbatch ndbatch  # plot with SpowerCurve() SpowerCurve(batch=ndbatch)  # For non-crossed experimental combinations, pass fully.crossed = FALSE. Note # that this requires the lengths of the inputs to match p_t.test() |> SpowerBatch(n=c(30, 90, 270),            d=c(.2, .5, .8), replications=1000, fully.crossed=FALSE) -> batch3   ##############################  # Batches also useful for drawing graphics outside of current framework # in SpowerCurve(). Below an image is drawn pertaining to the distribution # of the effects (H0 vs Ha hypotheses), giving the classic sampling distribution # comparisons of the effect sizes, however presents the information using # kernel density plots as this may be useful when the sampling distributions # are non-normal  # Define wrapper function that returns p-value and estimated mean difference Ice_T <- function(...){     out <- p_t.test(..., return_analysis=TRUE)     ret <- c(p=out$p.value, mu_d=unname(with(out, estimate[1] - estimate[2])))    ret }  # rapper returns p-value and effect size of interest Ice_T(n=90, d=.5)  # run batch mode to get 4 mean difference combinations, selecting out only # the 'p' for the power-analysis portions batch <- Ice_T(n=90) |>    SpowerBatch(d=c(0, .2, .5, .8), select=\"p\") batch as.data.frame(batch)  # create big table of results across the batches results <- SimResults(batch, rbind=TRUE) results$d <- factor(results$d) results  # draw H0 vs Ha relationships for each effect size library(ggplot2) library(patchwork) gg1 <- ggplot(subset(results, d %in% c(0, .2)),         aes(mu_d, colour=d)) +   geom_density() + ggtitle('Small effect (d = 0.2)') +   theme(legend.position='none') + xlab(expression(mu[d])) + xlim(c(-0.75, 1.5)) gg2 <- ggplot(subset(results, d %in% c(0, .5)),         aes(mu_d, colour=d)) +   geom_density() + ggtitle('Medium effect  (d = 0.5)') +   theme(legend.position='none') + xlab(expression(mu[d])) +  xlim(c(-0.75, 1.5)) gg3 <- ggplot(subset(results, d %in% c(0, .8)),         aes(mu_d, colour=d)) +   geom_density() + ggtitle('Large effect  (d = 0.8)') +   theme(legend.position='none') + xlab(expression(mu[d])) + xlim(c(-0.75, 1.5))  gg1 / gg2 / gg3  } # }   # \\donttest{  ############################################## # SpowerCurve() examples ##############################################  # estimate power given varying sample sizes gg <- p_t.test(d=0.2) |> SpowerCurve(n=c(30, 90, 270, 550))  # Output is a ggplot2 (rendered with plotly by default); hence, can be modified library(ggplot2) gg + geom_text(aes(label=power), size=5, colour='red', nudge_y=.05) +   ylab(expression(1-beta)) + theme_grey()   # Increase precision by using 10000 replications. Parallel computations #   generally recommended in this case to save time p_t.test(d=0.2) |> SpowerCurve(n=c(30, 90, 270, 550), replications=10000)  # estimate sample sizes given varying power p_t.test(n=NA, d=0.2) |>   SpowerCurve(power=c(.2, .4, .6, .8), interval=c(10, 1000))  # get information from last printed graphic instead of saving gg <- last_plot() gg + coord_flip() # flip coordinates to put power on y-axis   # estimate power varying d p_t.test(n=50) |> SpowerCurve(d=seq(.1, 1, by=.2))  # estimate d varying power p_t.test(n=50, d=NA) |>   SpowerCurve(power=c(.2, .4, .6, .8), interval=c(.01, 1))   #####  # vary two inputs instead of one (second input uses colour aesthetic) p_t.test() |> SpowerCurve(n=c(30, 90, 270, 550),                          d=c(.2, .5, .8))  # extract data for alternative presentations build <- ggplot_build(last_plot()) build #> <ggplot2::ggplot_built> #>  @ data  :List of 3 #>  .. $ :'data.frame':\t12 obs. of  12 variables: #>  ..  ..$ ymin       : num [1:12] 0.103 0.253 0.622 0.909 0.453 ... #>  ..  ..$ ymax       : num [1:12] 0.128 0.287 0.66 0.93 0.492 ... #>  ..  ..$ x          : num [1:12] 30 90 270 550 30 90 270 550 30 90 ... #>  ..  ..$ y          : num [1:12] 0.103 0.253 0.622 0.909 0.453 ... #>  ..  ..$ colour     : chr [1:12] \"#F8766D\" \"#F8766D\" \"#F8766D\" \"#F8766D\" ... #>  ..  ..$ fill       : chr [1:12] \"#F8766D\" \"#F8766D\" \"#F8766D\" \"#F8766D\" ... #>  ..  ..$ PANEL      : Factor w/ 1 level \"1\": 1 1 1 1 1 1 1 1 1 1 ... #>  ..  ..$ group      : int [1:12] 1 1 1 1 2 2 2 2 3 3 ... #>  ..  ..$ flipped_aes: logi [1:12] FALSE FALSE FALSE FALSE FALSE FALSE ... #>  ..  ..$ linewidth  : num [1:12] 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 ... #>  ..  ..$ linetype   : chr [1:12] \"dashed\" \"dashed\" \"dashed\" \"dashed\" ... #>  ..  ..$ alpha      : num [1:12] 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 ... #>  .. $ :'data.frame':\t12 obs. of  10 variables: #>  ..  ..$ x          : num [1:12] 30 90 270 550 30 90 270 550 30 90 ... #>  ..  ..$ y          : num [1:12] 0.116 0.27 0.641 0.92 0.472 ... #>  ..  ..$ colour     : chr [1:12] \"#F8766D\" \"#F8766D\" \"#F8766D\" \"#F8766D\" ... #>  ..  ..$ fill       : chr [1:12] \"#F8766D\" \"#F8766D\" \"#F8766D\" \"#F8766D\" ... #>  ..  ..$ PANEL      : Factor w/ 1 level \"1\": 1 1 1 1 1 1 1 1 1 1 ... #>  ..  ..$ group      : int [1:12] 1 1 1 1 2 2 2 2 3 3 ... #>  ..  ..$ flipped_aes: logi [1:12] FALSE FALSE FALSE FALSE FALSE FALSE ... #>  ..  ..$ linewidth  : num [1:12] 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 ... #>  ..  ..$ linetype   : int [1:12] 1 1 1 1 1 1 1 1 1 1 ... #>  ..  ..$ alpha      : logi [1:12] NA NA NA NA NA NA ... #>  .. $ :'data.frame':\t12 obs. of  10 variables: #>  ..  ..$ x     : num [1:12] 30 90 270 550 30 90 270 550 30 90 ... #>  ..  ..$ y     : num [1:12] 0.116 0.27 0.641 0.92 0.472 ... #>  ..  ..$ colour: chr [1:12] \"#F8766D\" \"#F8766D\" \"#F8766D\" \"#F8766D\" ... #>  ..  ..$ fill  : chr [1:12] \"#F8766D\" \"#F8766D\" \"#F8766D\" \"#F8766D\" ... #>  ..  ..$ PANEL : Factor w/ 1 level \"1\": 1 1 1 1 1 1 1 1 1 1 ... #>  ..  ..$ group : int [1:12] 1 1 1 1 2 2 2 2 3 3 ... #>  ..  .. ..- attr(*, \"n\")= int 3 #>  ..  ..$ shape : num [1:12] 19 19 19 19 19 19 19 19 19 19 ... #>  ..  ..$ size  : num [1:12] 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 ... #>  ..  ..$ alpha : logi [1:12] NA NA NA NA NA NA ... #>  ..  ..$ stroke: num [1:12] 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 ... #>  @ layout:Classes 'Layout', 'ggproto', 'gg' <ggproto object: Class Layout, gg> #>     coord: <ggproto object: Class CoordCartesian, Coord, gg> #>         aspect: function #>         backtransform_range: function #>         clip: on #>         default: TRUE #>         distance: function #>         draw_panel: function #>         expand: TRUE #>         is_free: function #>         is_linear: function #>         labels: function #>         limits: list #>         modify_scales: function #>         range: function #>         ratio: NULL #>         render_axis_h: function #>         render_axis_v: function #>         render_bg: function #>         render_fg: function #>         reverse: none #>         setup_data: function #>         setup_layout: function #>         setup_panel_guides: function #>         setup_panel_params: function #>         setup_params: function #>         train_panel_guides: function #>         transform: function #>         super:  <ggproto object: Class CoordCartesian, Coord, gg> #>     coord_params: list #>     facet: <ggproto object: Class FacetNull, Facet, gg> #>         attach_axes: function #>         attach_strips: function #>         compute_layout: function #>         draw_back: function #>         draw_front: function #>         draw_labels: function #>         draw_panel_content: function #>         draw_panels: function #>         finish_data: function #>         format_strip_labels: function #>         init_gtable: function #>         init_scales: function #>         map_data: function #>         params: list #>         set_panel_size: function #>         setup_data: function #>         setup_panel_params: function #>         setup_params: function #>         shrink: TRUE #>         train_scales: function #>         vars: function #>         super:  <ggproto object: Class FacetNull, Facet, gg> #>     facet_params: list #>     finish_data: function #>     get_scales: function #>     layout: data.frame #>     map_position: function #>     panel_params: list #>     panel_scales_x: list #>     panel_scales_y: list #>     render: function #>     render_labels: function #>     reset_scales: function #>     resolve_label: function #>     setup: function #>     setup_panel_guides: function #>     setup_panel_params: function #>     train_position: function #>     super:  <ggproto object: Class Layout, gg>  #>  @ plot  : <ggplot2::ggplot> #>  .. @ data       :'data.frame':\t12 obs. of  8 variables: #>  .. .. $ n        : num  30 90 270 550 30 90 270 550 30 90 ... #>  .. .. $ d        : Factor w/ 3 levels \"0.2\",\"0.5\",\"0.8\": 1 1 1 1 2 2 2 2 3 3 ... #>  .. .. $ sig.level: num  0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 ... #>  .. .. $ power    : num  0.116 0.27 0.641 0.92 0.472 ... #>  .. .. $ CI_2.5   : num  0.103 0.253 0.622 0.909 0.453 ... #>  .. .. $ CI_97.5  : num  0.128 0.287 0.66 0.93 0.492 ... #>  .. .. $ CI.low   : num  0.103 0.253 0.622 0.909 0.453 ... #>  .. .. $ CI.high  : num  0.128 0.287 0.66 0.93 0.492 ... #>  .. @ layers     :List of 3 #>  .. .. $ geom_ribbon:Classes 'LayerInstance', 'Layer', 'ggproto', 'gg' <ggproto object: Class LayerInstance, Layer, gg> #>     aes_params: list #>     compute_aesthetics: function #>     compute_geom_1: function #>     compute_geom_2: function #>     compute_position: function #>     compute_statistic: function #>     computed_geom_params: list #>     computed_mapping: ggplot2::mapping, uneval, gg, S7_object #>     computed_stat_params: list #>     constructor: call #>     data: waiver #>     draw_geom: function #>     finish_statistics: function #>     geom: <ggproto object: Class GeomRibbon, Geom, gg> #>         aesthetics: function #>         default_aes: ggplot2::mapping, uneval, gg, S7_object #>         draw_group: function #>         draw_key: function #>         draw_layer: function #>         draw_panel: function #>         extra_params: na.rm orientation #>         handle_na: function #>         non_missing_aes:  #>         optional_aes:  #>         parameters: function #>         rename_size: TRUE #>         required_aes: x|y ymin|xmin ymax|xmax #>         setup_data: function #>         setup_params: function #>         use_defaults: function #>         super:  <ggproto object: Class Geom, gg> #>     geom_params: list #>     inherit.aes: TRUE #>     layer_data: function #>     layout: NULL #>     map_statistic: function #>     mapping: ggplot2::mapping, uneval, gg, S7_object #>     name: NULL #>     position: <ggproto object: Class PositionIdentity, Position, gg> #>         aesthetics: function #>         compute_layer: function #>         compute_panel: function #>         default_aes: ggplot2::mapping, uneval, gg, S7_object #>         required_aes:  #>         setup_data: function #>         setup_params: function #>         use_defaults: function #>         super:  <ggproto object: Class Position, gg> #>     print: function #>     setup_layer: function #>     show.legend: NA #>     stat: <ggproto object: Class StatIdentity, Stat, gg> #>         aesthetics: function #>         compute_group: function #>         compute_layer: function #>         compute_panel: function #>         default_aes: ggplot2::mapping, uneval, gg, S7_object #>         dropped_aes: x_plotlyDomain y_plotlyDomain x_plotlyDomain y_plotlyDom ... #>         extra_params: na.rm #>         finish_layer: function #>         non_missing_aes:  #>         optional_aes:  #>         parameters: function #>         required_aes:  #>         retransform: TRUE #>         setup_data: function #>         setup_params: function #>         super:  <ggproto object: Class Stat, gg> #>     stat_params: list #>     super:  <ggproto object: Class Layer, gg>  #>  .. .. $ geom_line  :Classes 'LayerInstance', 'Layer', 'ggproto', 'gg' <ggproto object: Class LayerInstance, Layer, gg> #>     aes_params: list #>     compute_aesthetics: function #>     compute_geom_1: function #>     compute_geom_2: function #>     compute_position: function #>     compute_statistic: function #>     computed_geom_params: list #>     computed_mapping: ggplot2::mapping, uneval, gg, S7_object #>     computed_stat_params: list #>     constructor: call #>     data: waiver #>     draw_geom: function #>     finish_statistics: function #>     geom: <ggproto object: Class GeomLine, GeomPath, Geom, gg> #>         aesthetics: function #>         default_aes: ggplot2::mapping, uneval, gg, S7_object #>         draw_group: function #>         draw_key: function #>         draw_layer: function #>         draw_panel: function #>         extra_params: na.rm orientation #>         handle_na: function #>         non_missing_aes: linewidth colour linetype #>         optional_aes:  #>         parameters: function #>         rename_size: TRUE #>         required_aes: x y #>         setup_data: function #>         setup_params: function #>         use_defaults: function #>         super:  <ggproto object: Class GeomPath, Geom, gg> #>     geom_params: list #>     inherit.aes: TRUE #>     layer_data: function #>     layout: NULL #>     map_statistic: function #>     mapping: NULL #>     name: NULL #>     position: <ggproto object: Class PositionIdentity, Position, gg> #>         aesthetics: function #>         compute_layer: function #>         compute_panel: function #>         default_aes: ggplot2::mapping, uneval, gg, S7_object #>         required_aes:  #>         setup_data: function #>         setup_params: function #>         use_defaults: function #>         super:  <ggproto object: Class Position, gg> #>     print: function #>     setup_layer: function #>     show.legend: NA #>     stat: <ggproto object: Class StatIdentity, Stat, gg> #>         aesthetics: function #>         compute_group: function #>         compute_layer: function #>         compute_panel: function #>         default_aes: ggplot2::mapping, uneval, gg, S7_object #>         dropped_aes: x_plotlyDomain y_plotlyDomain x_plotlyDomain y_plotlyDom ... #>         extra_params: na.rm #>         finish_layer: function #>         non_missing_aes:  #>         optional_aes:  #>         parameters: function #>         required_aes:  #>         retransform: TRUE #>         setup_data: function #>         setup_params: function #>         super:  <ggproto object: Class Stat, gg> #>     stat_params: list #>     super:  <ggproto object: Class Layer, gg>  #>  .. .. $ geom_point :Classes 'LayerInstance', 'Layer', 'ggproto', 'gg' <ggproto object: Class LayerInstance, Layer, gg> #>     aes_params: list #>     compute_aesthetics: function #>     compute_geom_1: function #>     compute_geom_2: function #>     compute_position: function #>     compute_statistic: function #>     computed_geom_params: list #>     computed_mapping: ggplot2::mapping, uneval, gg, S7_object #>     computed_stat_params: list #>     constructor: call #>     data: waiver #>     draw_geom: function #>     finish_statistics: function #>     geom: <ggproto object: Class GeomPoint, Geom, gg> #>         aesthetics: function #>         default_aes: ggplot2::mapping, uneval, gg, S7_object #>         draw_group: function #>         draw_key: function #>         draw_layer: function #>         draw_panel: function #>         extra_params: na.rm #>         handle_na: function #>         non_missing_aes: size shape colour #>         optional_aes:  #>         parameters: function #>         rename_size: FALSE #>         required_aes: x y #>         setup_data: function #>         setup_params: function #>         use_defaults: function #>         super:  <ggproto object: Class Geom, gg> #>     geom_params: list #>     inherit.aes: TRUE #>     layer_data: function #>     layout: NULL #>     map_statistic: function #>     mapping: NULL #>     name: NULL #>     position: <ggproto object: Class PositionIdentity, Position, gg> #>         aesthetics: function #>         compute_layer: function #>         compute_panel: function #>         default_aes: ggplot2::mapping, uneval, gg, S7_object #>         required_aes:  #>         setup_data: function #>         setup_params: function #>         use_defaults: function #>         super:  <ggproto object: Class Position, gg> #>     print: function #>     setup_layer: function #>     show.legend: NA #>     stat: <ggproto object: Class StatIdentity, Stat, gg> #>         aesthetics: function #>         compute_group: function #>         compute_layer: function #>         compute_panel: function #>         default_aes: ggplot2::mapping, uneval, gg, S7_object #>         dropped_aes: x_plotlyDomain y_plotlyDomain x_plotlyDomain y_plotlyDom ... #>         extra_params: na.rm #>         finish_layer: function #>         non_missing_aes:  #>         optional_aes:  #>         parameters: function #>         required_aes:  #>         retransform: TRUE #>         setup_data: function #>         setup_params: function #>         super:  <ggproto object: Class Stat, gg> #>     stat_params: list #>     super:  <ggproto object: Class Layer, gg>  #>  .. @ scales     :Classes 'ScalesList', 'ggproto', 'gg' <ggproto object: Class ScalesList, gg> #>     add: function #>     add_defaults: function #>     add_missing: function #>     backtransform_df: function #>     clone: function #>     find: function #>     get_scales: function #>     has_scale: function #>     input: function #>     map_df: function #>     n: function #>     non_position_scales: function #>     scales: list #>     set_palettes: function #>     train_df: function #>     transform_df: function #>     super:  <ggproto object: Class ScalesList, gg>  #>  .. @ guides     :Classes 'Guides', 'ggproto', 'gg' <ggproto object: Class Guides, gg> #>     add: function #>     aesthetics: colour #>     assemble: function #>     build: function #>     draw: function #>     get_custom: function #>     get_guide: function #>     get_params: function #>     get_position: function #>     guides: list #>     merge: function #>     missing: <ggproto object: Class GuideNone, Guide, gg> #>         add_title: function #>         arrange_layout: function #>         assemble_drawing: function #>         available_aes: any #>         build_decor: function #>         build_labels: function #>         build_ticks: function #>         build_title: function #>         draw: function #>         draw_early_exit: function #>         elements: list #>         extract_decor: function #>         extract_key: function #>         extract_params: function #>         get_layer_key: function #>         hashables: list #>         measure_grobs: function #>         merge: function #>         override_elements: function #>         params: list #>         process_layers: function #>         setup_elements: function #>         setup_params: function #>         train: function #>         transform: function #>         super:  <ggproto object: Class GuideNone, Guide, gg> #>     package_box: function #>     params: list #>     print: function #>     process_layers: function #>     setup: function #>     subset_guides: function #>     train: function #>     update_params: function #>     super:  <ggproto object: Class Guides, gg>  #>  .. @ mapping    : <ggplot2::mapping> List of 4 #>  .. .. $ x     : language ~.data[[\"n\"]] #>  .. ..  ..- attr(*, \".Environment\")=<environment: 0x557ee432d5c8>  #>  .. .. $ y     : language ~power #>  .. ..  ..- attr(*, \".Environment\")=<environment: 0x557ee432d5c8>  #>  .. .. $ colour: language ~.data[[\"d\"]] #>  .. ..  ..- attr(*, \".Environment\")=<environment: 0x557ee432d5c8>  #>  .. .. $ fill  : language ~.data[[\"d\"]] #>  .. ..  ..- attr(*, \".Environment\")=<environment: 0x557ee432d5c8>  #>  .. @ theme      : <theme> List of 144 #>  .. .. $ line                            : <ggplot2::element_line> #>  .. ..  ..@ colour       : chr \"black\" #>  .. ..  ..@ linewidth    : num 0.5 #>  .. ..  ..@ linetype     : num 1 #>  .. ..  ..@ lineend      : chr \"butt\" #>  .. ..  ..@ linejoin     : chr \"round\" #>  .. ..  ..@ arrow        : logi FALSE #>  .. ..  ..@ arrow.fill   : chr \"black\" #>  .. ..  ..@ inherit.blank: logi TRUE #>  .. .. $ rect                            : <ggplot2::element_rect> #>  .. ..  ..@ fill         : chr \"white\" #>  .. ..  ..@ colour       : chr \"black\" #>  .. ..  ..@ linewidth    : num 0.5 #>  .. ..  ..@ linetype     : num 1 #>  .. ..  ..@ linejoin     : chr \"round\" #>  .. ..  ..@ inherit.blank: logi TRUE #>  .. .. $ text                            : <ggplot2::element_text> #>  .. ..  ..@ family       : chr \"\" #>  .. ..  ..@ face         : chr \"plain\" #>  .. ..  ..@ italic       : chr NA #>  .. ..  ..@ fontweight   : num NA #>  .. ..  ..@ fontwidth    : num NA #>  .. ..  ..@ colour       : chr \"black\" #>  .. ..  ..@ size         : num 11 #>  .. ..  ..@ hjust        : num 0.5 #>  .. ..  ..@ vjust        : num 0.5 #>  .. ..  ..@ angle        : num 0 #>  .. ..  ..@ lineheight   : num 0.9 #>  .. ..  ..@ margin       : <ggplot2::margin> num [1:4] 0 0 0 0 #>  .. ..  ..@ debug        : logi FALSE #>  .. ..  ..@ inherit.blank: logi TRUE #>  .. .. $ title                           : <ggplot2::element_text> #>  .. ..  ..@ family       : NULL #>  .. ..  ..@ face         : NULL #>  .. ..  ..@ italic       : chr NA #>  .. ..  ..@ fontweight   : num NA #>  .. ..  ..@ fontwidth    : num NA #>  .. ..  ..@ colour       : NULL #>  .. ..  ..@ size         : NULL #>  .. ..  ..@ hjust        : NULL #>  .. ..  ..@ vjust        : NULL #>  .. ..  ..@ angle        : NULL #>  .. ..  ..@ lineheight   : NULL #>  .. ..  ..@ margin       : NULL #>  .. ..  ..@ debug        : NULL #>  .. ..  ..@ inherit.blank: logi TRUE #>  .. .. $ point                           : <ggplot2::element_point> #>  .. ..  ..@ colour       : chr \"black\" #>  .. ..  ..@ shape        : num 19 #>  .. ..  ..@ size         : num 1.5 #>  .. ..  ..@ fill         : chr \"white\" #>  .. ..  ..@ stroke       : num 0.5 #>  .. ..  ..@ inherit.blank: logi TRUE #>  .. .. $ polygon                         : <ggplot2::element_polygon> #>  .. ..  ..@ fill         : chr \"white\" #>  .. ..  ..@ colour       : chr \"black\" #>  .. ..  ..@ linewidth    : num 0.5 #>  .. ..  ..@ linetype     : num 1 #>  .. ..  ..@ linejoin     : chr \"round\" #>  .. ..  ..@ inherit.blank: logi TRUE #>  .. .. $ geom                            : <ggplot2::element_geom> #>  .. ..  ..@ ink        : chr \"black\" #>  .. ..  ..@ paper      : chr \"white\" #>  .. ..  ..@ accent     : chr \"#3366FF\" #>  .. ..  ..@ linewidth  : num 0.5 #>  .. ..  ..@ borderwidth: num 0.5 #>  .. ..  ..@ linetype   : int 1 #>  .. ..  ..@ bordertype : int 1 #>  .. ..  ..@ family     : chr \"\" #>  .. ..  ..@ fontsize   : num 3.87 #>  .. ..  ..@ pointsize  : num 1.5 #>  .. ..  ..@ pointshape : num 19 #>  .. ..  ..@ colour     : NULL #>  .. ..  ..@ fill       : NULL #>  .. .. $ spacing                         : 'simpleUnit' num 5.5points #>  .. ..  ..- attr(*, \"unit\")= int 8 #>  .. .. $ margins                         : <ggplot2::margin> num [1:4] 5.5 5.5 5.5 5.5 #>  .. .. $ aspect.ratio                    : NULL #>  .. .. $ axis.title                      : NULL #>  .. .. $ axis.title.x                    : <ggplot2::element_text> #>  .. ..  ..@ family       : NULL #>  .. ..  ..@ face         : NULL #>  .. ..  ..@ italic       : chr NA #>  .. ..  ..@ fontweight   : num NA #>  .. ..  ..@ fontwidth    : num NA #>  .. ..  ..@ colour       : NULL #>  .. ..  ..@ size         : NULL #>  .. ..  ..@ hjust        : NULL #>  .. ..  ..@ vjust        : num 1 #>  .. ..  ..@ angle        : NULL #>  .. ..  ..@ lineheight   : NULL #>  .. ..  ..@ margin       : <ggplot2::margin> num [1:4] 2.75 0 0 0 #>  .. ..  ..@ debug        : NULL #>  .. ..  ..@ inherit.blank: logi TRUE #>  .. .. $ axis.title.x.top                : <ggplot2::element_text> #>  .. ..  ..@ family       : NULL #>  .. ..  ..@ face         : NULL #>  .. ..  ..@ italic       : chr NA #>  .. ..  ..@ fontweight   : num NA #>  .. ..  ..@ fontwidth    : num NA #>  .. ..  ..@ colour       : NULL #>  .. ..  ..@ size         : NULL #>  .. ..  ..@ hjust        : NULL #>  .. ..  ..@ vjust        : num 0 #>  .. ..  ..@ angle        : NULL #>  .. ..  ..@ lineheight   : NULL #>  .. ..  ..@ margin       : <ggplot2::margin> num [1:4] 0 0 2.75 0 #>  .. ..  ..@ debug        : NULL #>  .. ..  ..@ inherit.blank: logi TRUE #>  .. .. $ axis.title.x.bottom             : NULL #>  .. .. $ axis.title.y                    : <ggplot2::element_text> #>  .. ..  ..@ family       : NULL #>  .. ..  ..@ face         : NULL #>  .. ..  ..@ italic       : chr NA #>  .. ..  ..@ fontweight   : num NA #>  .. ..  ..@ fontwidth    : num NA #>  .. ..  ..@ colour       : NULL #>  .. ..  ..@ size         : NULL #>  .. ..  ..@ hjust        : NULL #>  .. ..  ..@ vjust        : num 1 #>  .. ..  ..@ angle        : num 90 #>  .. ..  ..@ lineheight   : NULL #>  .. ..  ..@ margin       : <ggplot2::margin> num [1:4] 0 2.75 0 0 #>  .. ..  ..@ debug        : NULL #>  .. ..  ..@ inherit.blank: logi TRUE #>  .. .. $ axis.title.y.left               : NULL #>  .. .. $ axis.title.y.right              : <ggplot2::element_text> #>  .. ..  ..@ family       : NULL #>  .. ..  ..@ face         : NULL #>  .. ..  ..@ italic       : chr NA #>  .. ..  ..@ fontweight   : num NA #>  .. ..  ..@ fontwidth    : num NA #>  .. ..  ..@ colour       : NULL #>  .. ..  ..@ size         : NULL #>  .. ..  ..@ hjust        : NULL #>  .. ..  ..@ vjust        : num 1 #>  .. ..  ..@ angle        : num -90 #>  .. ..  ..@ lineheight   : NULL #>  .. ..  ..@ margin       : <ggplot2::margin> num [1:4] 0 0 0 2.75 #>  .. ..  ..@ debug        : NULL #>  .. ..  ..@ inherit.blank: logi TRUE #>  .. .. $ axis.text                       : <ggplot2::element_text> #>  .. ..  ..@ family       : NULL #>  .. ..  ..@ face         : NULL #>  .. ..  ..@ italic       : chr NA #>  .. ..  ..@ fontweight   : num NA #>  .. ..  ..@ fontwidth    : num NA #>  .. ..  ..@ colour       : chr \"#4D4D4DFF\" #>  .. ..  ..@ size         : 'rel' num 0.8 #>  .. ..  ..@ hjust        : NULL #>  .. ..  ..@ vjust        : NULL #>  .. ..  ..@ angle        : NULL #>  .. ..  ..@ lineheight   : NULL #>  .. ..  ..@ margin       : NULL #>  .. ..  ..@ debug        : NULL #>  .. ..  ..@ inherit.blank: logi TRUE #>  .. .. $ axis.text.x                     : <ggplot2::element_text> #>  .. ..  ..@ family       : NULL #>  .. ..  ..@ face         : NULL #>  .. ..  ..@ italic       : chr NA #>  .. ..  ..@ fontweight   : num NA #>  .. ..  ..@ fontwidth    : num NA #>  .. ..  ..@ colour       : NULL #>  .. ..  ..@ size         : NULL #>  .. ..  ..@ hjust        : NULL #>  .. ..  ..@ vjust        : num 1 #>  .. ..  ..@ angle        : NULL #>  .. ..  ..@ lineheight   : NULL #>  .. ..  ..@ margin       : <ggplot2::margin> num [1:4] 2.2 0 0 0 #>  .. ..  ..@ debug        : NULL #>  .. ..  ..@ inherit.blank: logi TRUE #>  .. .. $ axis.text.x.top                 : <ggplot2::element_text> #>  .. ..  ..@ family       : NULL #>  .. ..  ..@ face         : NULL #>  .. ..  ..@ italic       : chr NA #>  .. ..  ..@ fontweight   : num NA #>  .. ..  ..@ fontwidth    : num NA #>  .. ..  ..@ colour       : NULL #>  .. ..  ..@ size         : NULL #>  .. ..  ..@ hjust        : NULL #>  .. ..  ..@ vjust        : num 0 #>  .. ..  ..@ angle        : NULL #>  .. ..  ..@ lineheight   : NULL #>  .. ..  ..@ margin       : <ggplot2::margin> num [1:4] 0 0 2.2 0 #>  .. ..  ..@ debug        : NULL #>  .. ..  ..@ inherit.blank: logi TRUE #>  .. .. $ axis.text.x.bottom              : NULL #>  .. .. $ axis.text.y                     : <ggplot2::element_text> #>  .. ..  ..@ family       : NULL #>  .. ..  ..@ face         : NULL #>  .. ..  ..@ italic       : chr NA #>  .. ..  ..@ fontweight   : num NA #>  .. ..  ..@ fontwidth    : num NA #>  .. ..  ..@ colour       : NULL #>  .. ..  ..@ size         : NULL #>  .. ..  ..@ hjust        : num 1 #>  .. ..  ..@ vjust        : NULL #>  .. ..  ..@ angle        : NULL #>  .. ..  ..@ lineheight   : NULL #>  .. ..  ..@ margin       : <ggplot2::margin> num [1:4] 0 2.2 0 0 #>  .. ..  ..@ debug        : NULL #>  .. ..  ..@ inherit.blank: logi TRUE #>  .. .. $ axis.text.y.left                : NULL #>  .. .. $ axis.text.y.right               : <ggplot2::element_text> #>  .. ..  ..@ family       : NULL #>  .. ..  ..@ face         : NULL #>  .. ..  ..@ italic       : chr NA #>  .. ..  ..@ fontweight   : num NA #>  .. ..  ..@ fontwidth    : num NA #>  .. ..  ..@ colour       : NULL #>  .. ..  ..@ size         : NULL #>  .. ..  ..@ hjust        : num 0 #>  .. ..  ..@ vjust        : NULL #>  .. ..  ..@ angle        : NULL #>  .. ..  ..@ lineheight   : NULL #>  .. ..  ..@ margin       : <ggplot2::margin> num [1:4] 0 0 0 2.2 #>  .. ..  ..@ debug        : NULL #>  .. ..  ..@ inherit.blank: logi TRUE #>  .. .. $ axis.text.theta                 : NULL #>  .. .. $ axis.text.r                     : <ggplot2::element_text> #>  .. ..  ..@ family       : NULL #>  .. ..  ..@ face         : NULL #>  .. ..  ..@ italic       : chr NA #>  .. ..  ..@ fontweight   : num NA #>  .. ..  ..@ fontwidth    : num NA #>  .. ..  ..@ colour       : NULL #>  .. ..  ..@ size         : NULL #>  .. ..  ..@ hjust        : num 0.5 #>  .. ..  ..@ vjust        : NULL #>  .. ..  ..@ angle        : NULL #>  .. ..  ..@ lineheight   : NULL #>  .. ..  ..@ margin       : <ggplot2::margin> num [1:4] 0 2.2 0 2.2 #>  .. ..  ..@ debug        : NULL #>  .. ..  ..@ inherit.blank: logi TRUE #>  .. .. $ axis.ticks                      : <ggplot2::element_line> #>  .. ..  ..@ colour       : chr \"#333333FF\" #>  .. ..  ..@ linewidth    : NULL #>  .. ..  ..@ linetype     : NULL #>  .. ..  ..@ lineend      : NULL #>  .. ..  ..@ linejoin     : NULL #>  .. ..  ..@ arrow        : logi FALSE #>  .. ..  ..@ arrow.fill   : chr \"#333333FF\" #>  .. ..  ..@ inherit.blank: logi TRUE #>  .. .. $ axis.ticks.x                    : NULL #>  .. .. $ axis.ticks.x.top                : NULL #>  .. .. $ axis.ticks.x.bottom             : NULL #>  .. .. $ axis.ticks.y                    : NULL #>  .. .. $ axis.ticks.y.left               : NULL #>  .. .. $ axis.ticks.y.right              : NULL #>  .. .. $ axis.ticks.theta                : NULL #>  .. .. $ axis.ticks.r                    : NULL #>  .. .. $ axis.minor.ticks.x.top          : NULL #>  .. .. $ axis.minor.ticks.x.bottom       : NULL #>  .. .. $ axis.minor.ticks.y.left         : NULL #>  .. .. $ axis.minor.ticks.y.right        : NULL #>  .. .. $ axis.minor.ticks.theta          : NULL #>  .. .. $ axis.minor.ticks.r              : NULL #>  .. .. $ axis.ticks.length               : 'rel' num 0.5 #>  .. .. $ axis.ticks.length.x             : NULL #>  .. .. $ axis.ticks.length.x.top         : NULL #>  .. .. $ axis.ticks.length.x.bottom      : NULL #>  .. .. $ axis.ticks.length.y             : NULL #>  .. .. $ axis.ticks.length.y.left        : NULL #>  .. .. $ axis.ticks.length.y.right       : NULL #>  .. .. $ axis.ticks.length.theta         : NULL #>  .. .. $ axis.ticks.length.r             : NULL #>  .. .. $ axis.minor.ticks.length         : 'rel' num 0.75 #>  .. .. $ axis.minor.ticks.length.x       : NULL #>  .. .. $ axis.minor.ticks.length.x.top   : NULL #>  .. .. $ axis.minor.ticks.length.x.bottom: NULL #>  .. .. $ axis.minor.ticks.length.y       : NULL #>  .. .. $ axis.minor.ticks.length.y.left  : NULL #>  .. .. $ axis.minor.ticks.length.y.right : NULL #>  .. .. $ axis.minor.ticks.length.theta   : NULL #>  .. .. $ axis.minor.ticks.length.r       : NULL #>  .. .. $ axis.line                       : <ggplot2::element_blank> #>  .. .. $ axis.line.x                     : NULL #>  .. .. $ axis.line.x.top                 : NULL #>  .. .. $ axis.line.x.bottom              : NULL #>  .. .. $ axis.line.y                     : NULL #>  .. .. $ axis.line.y.left                : NULL #>  .. .. $ axis.line.y.right               : NULL #>  .. .. $ axis.line.theta                 : NULL #>  .. .. $ axis.line.r                     : NULL #>  .. .. $ legend.background               : <ggplot2::element_rect> #>  .. ..  ..@ fill         : NULL #>  .. ..  ..@ colour       : logi NA #>  .. ..  ..@ linewidth    : NULL #>  .. ..  ..@ linetype     : NULL #>  .. ..  ..@ linejoin     : NULL #>  .. ..  ..@ inherit.blank: logi TRUE #>  .. .. $ legend.margin                   : NULL #>  .. .. $ legend.spacing                  : 'rel' num 2 #>  .. .. $ legend.spacing.x                : NULL #>  .. .. $ legend.spacing.y                : NULL #>  .. .. $ legend.key                      : NULL #>  .. .. $ legend.key.size                 : 'simpleUnit' num 1.2lines #>  .. ..  ..- attr(*, \"unit\")= int 3 #>  .. .. $ legend.key.height               : NULL #>  .. .. $ legend.key.width                : NULL #>  .. .. $ legend.key.spacing              : NULL #>  .. .. $ legend.key.spacing.x            : NULL #>  .. .. $ legend.key.spacing.y            : NULL #>  .. .. $ legend.key.justification        : NULL #>  .. .. $ legend.frame                    : NULL #>  .. .. $ legend.ticks                    : NULL #>  .. .. $ legend.ticks.length             : 'rel' num 0.2 #>  .. .. $ legend.axis.line                : NULL #>  .. .. $ legend.text                     : <ggplot2::element_text> #>  .. ..  ..@ family       : NULL #>  .. ..  ..@ face         : NULL #>  .. ..  ..@ italic       : chr NA #>  .. ..  ..@ fontweight   : num NA #>  .. ..  ..@ fontwidth    : num NA #>  .. ..  ..@ colour       : NULL #>  .. ..  ..@ size         : 'rel' num 0.8 #>  .. ..  ..@ hjust        : NULL #>  .. ..  ..@ vjust        : NULL #>  .. ..  ..@ angle        : NULL #>  .. ..  ..@ lineheight   : NULL #>  .. ..  ..@ margin       : NULL #>  .. ..  ..@ debug        : NULL #>  .. ..  ..@ inherit.blank: logi TRUE #>  .. .. $ legend.text.position            : NULL #>  .. .. $ legend.title                    : <ggplot2::element_text> #>  .. ..  ..@ family       : NULL #>  .. ..  ..@ face         : NULL #>  .. ..  ..@ italic       : chr NA #>  .. ..  ..@ fontweight   : num NA #>  .. ..  ..@ fontwidth    : num NA #>  .. ..  ..@ colour       : NULL #>  .. ..  ..@ size         : NULL #>  .. ..  ..@ hjust        : num 0 #>  .. ..  ..@ vjust        : NULL #>  .. ..  ..@ angle        : NULL #>  .. ..  ..@ lineheight   : NULL #>  .. ..  ..@ margin       : NULL #>  .. ..  ..@ debug        : NULL #>  .. ..  ..@ inherit.blank: logi TRUE #>  .. .. $ legend.title.position           : NULL #>  .. .. $ legend.position                 : chr \"right\" #>  .. .. $ legend.position.inside          : NULL #>  .. .. $ legend.direction                : NULL #>  .. .. $ legend.byrow                    : NULL #>  .. .. $ legend.justification            : chr \"center\" #>  .. .. $ legend.justification.top        : NULL #>  .. .. $ legend.justification.bottom     : NULL #>  .. .. $ legend.justification.left       : NULL #>  .. .. $ legend.justification.right      : NULL #>  .. .. $ legend.justification.inside     : NULL #>  .. ..  [list output truncated] #>  .. .. @ complete: logi TRUE #>  .. .. @ validate: logi TRUE #>  .. @ coordinates:Classes 'CoordCartesian', 'Coord', 'ggproto', 'gg' <ggproto object: Class CoordCartesian, Coord, gg> #>     aspect: function #>     backtransform_range: function #>     clip: on #>     default: TRUE #>     distance: function #>     draw_panel: function #>     expand: TRUE #>     is_free: function #>     is_linear: function #>     labels: function #>     limits: list #>     modify_scales: function #>     range: function #>     ratio: NULL #>     render_axis_h: function #>     render_axis_v: function #>     render_bg: function #>     render_fg: function #>     reverse: none #>     setup_data: function #>     setup_layout: function #>     setup_panel_guides: function #>     setup_panel_params: function #>     setup_params: function #>     train_panel_guides: function #>     transform: function #>     super:  <ggproto object: Class CoordCartesian, Coord, gg>  #>  .. @ facet      :Classes 'FacetNull', 'Facet', 'ggproto', 'gg' <ggproto object: Class FacetNull, Facet, gg> #>     attach_axes: function #>     attach_strips: function #>     compute_layout: function #>     draw_back: function #>     draw_front: function #>     draw_labels: function #>     draw_panel_content: function #>     draw_panels: function #>     finish_data: function #>     format_strip_labels: function #>     init_gtable: function #>     init_scales: function #>     map_data: function #>     params: list #>     set_panel_size: function #>     setup_data: function #>     setup_panel_params: function #>     setup_params: function #>     shrink: TRUE #>     train_scales: function #>     vars: function #>     super:  <ggproto object: Class FacetNull, Facet, gg>  #>  .. @ layout     :Classes 'Layout', 'ggproto', 'gg' <ggproto object: Class Layout, gg> #>     coord: NULL #>     coord_params: list #>     facet: NULL #>     facet_params: list #>     finish_data: function #>     get_scales: function #>     layout: NULL #>     map_position: function #>     panel_params: NULL #>     panel_scales_x: NULL #>     panel_scales_y: NULL #>     render: function #>     render_labels: function #>     reset_scales: function #>     resolve_label: function #>     setup: function #>     setup_panel_guides: function #>     setup_panel_params: function #>     train_position: function #>     super:  <ggproto object: Class Layout, gg>  #>  .. @ labels     : <ggplot2::labels> List of 8 #>  .. .. $ title : chr \"Power Curve\" #>  .. .. $ ymin  : chr \"CI.low\" #>  .. .. $ ymax  : chr \"CI.high\" #>  .. .. $ x     : chr \"n\" #>  .. .. $ y     : chr \"power\" #>  .. .. $ colour: chr \"d\" #>  .. .. $ fill  : chr \"d\" #>  .. .. $ alt   : chr \"\" #>  .. @ meta       : list() #>  .. @ plot_env   :<environment: 0x557ee432d5c8>   df <- build$plot$data head(df) #>     n   d sig.level  power    CI_2.5   CI_97.5    CI.low   CI.high #> 1  30 0.2      0.05 0.1156 0.1030662 0.1281338 0.1030662 0.1281338 #> 2  90 0.2      0.05 0.2700 0.2525971 0.2874029 0.2525971 0.2874029 #> 3 270 0.2      0.05 0.6408 0.6219935 0.6596065 0.6219935 0.6596065 #> 4 550 0.2      0.05 0.9196 0.9089413 0.9302587 0.9089413 0.9302587 #> 5  30 0.5      0.05 0.4724 0.4528302 0.4919698 0.4528302 0.4919698 #> 6  90 0.5      0.05 0.9192 0.9085171 0.9298829 0.9085171 0.9298829 ggplot(df, aes(n, power, linetype=d)) + geom_line()   # vary three arguments (third uses facet_wrap ... any more than that and #   you're on your own!) p_t.test() |> SpowerCurve(n=c(30, 90, 270, 550),                          d=c(.2, .5, .8),                          var.equal=c(FALSE, TRUE))  ########################################  # If objects were precomputed using SpowerBatch() then #  these can be plotted instead p_t.test(d=0.2) |>   SpowerBatch(n=c(30, 90, 270, 550), replications=1000) -> nbatch nbatch #> $CONDITION_1 #>  #> Execution time (H:M:S): 00:00:00 #> Design conditions:  #>  #> # A tibble: 1 × 4 #>       n     d sig.level power #>   <dbl> <dbl>     <dbl> <lgl> #> 1    30   0.2      0.05 NA    #>  #> Estimate of power: 0.132 #> 95% Confidence Interval: [0.111, 0.153] #>  #> $CONDITION_2 #>  #> Execution time (H:M:S): 00:00:00 #> Design conditions:  #>  #> # A tibble: 1 × 4 #>       n     d sig.level power #>   <dbl> <dbl>     <dbl> <lgl> #> 1    90   0.2      0.05 NA    #>  #> Estimate of power: 0.250 #> 95% Confidence Interval: [0.223, 0.277] #>  #> $CONDITION_3 #>  #> Execution time (H:M:S): 00:00:00 #> Design conditions:  #>  #> # A tibble: 1 × 4 #>       n     d sig.level power #>   <dbl> <dbl>     <dbl> <lgl> #> 1   270   0.2      0.05 NA    #>  #> Estimate of power: 0.615 #> 95% Confidence Interval: [0.585, 0.645] #>  #> $CONDITION_4 #>  #> Execution time (H:M:S): 00:00:00 #> Design conditions:  #>  #> # A tibble: 1 × 4 #>       n     d sig.level power #>   <dbl> <dbl>     <dbl> <lgl> #> 1   550   0.2      0.05 NA    #>  #> Estimate of power: 0.919 #> 95% Confidence Interval: [0.902, 0.936] #>  as.data.frame(nbatch) #>     n   d sig.level power    CI_2.5   CI_97.5 #> 1  30 0.2      0.05 0.132 0.1110205 0.1529795 #> 2  90 0.2      0.05 0.250 0.2231621 0.2768379 #> 3 270 0.2      0.05 0.615 0.5848411 0.6451589 #> 4 550 0.2      0.05 0.919 0.9020898 0.9359102  # plot the results, but avoid further computations SpowerCurve(batch=nbatch)  # }"},{"path":"https://philchalmers.github.io/Spower/reference/getLastSpower.html","id":null,"dir":"Reference","previous_headings":"","what":"Get previously evaluated Spower execution — getLastSpower","title":"Get previously evaluated Spower execution — getLastSpower","text":"result Spower SpowerBatch stored object function retrieve last evaluation.","code":""},{"path":"https://philchalmers.github.io/Spower/reference/getLastSpower.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get previously evaluated Spower execution — getLastSpower","text":"","code":"getLastSpower()"},{"path":"https://philchalmers.github.io/Spower/reference/getLastSpower.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get previously evaluated Spower execution — getLastSpower","text":"last object returned Spower SpowerBatch","code":""},{"path":"https://philchalmers.github.io/Spower/reference/getLastSpower.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Get previously evaluated Spower execution — getLastSpower","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/Spower/reference/is.CI_within.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate whether a confidence interval is within a tolerable interval — is.CI_within","title":"Evaluate whether a confidence interval is within a tolerable interval — is.CI_within","text":"Return TRUE estimated confidence interval falls within tolerable interval range. Typically used equivalence, superiority, non-inferiority testing.","code":""},{"path":"https://philchalmers.github.io/Spower/reference/is.CI_within.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate whether a confidence interval is within a tolerable interval — is.CI_within","text":"","code":"is.CI_within(CI, interval)"},{"path":"https://philchalmers.github.io/Spower/reference/is.CI_within.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate whether a confidence interval is within a tolerable interval — is.CI_within","text":"CI estimated confidence interval (length 2) interval tolerable interval range (length 2)","code":""},{"path":"https://philchalmers.github.io/Spower/reference/is.CI_within.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate whether a confidence interval is within a tolerable interval — is.CI_within","text":"logical","code":""},{"path":[]},{"path":"https://philchalmers.github.io/Spower/reference/is.CI_within.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Evaluate whether a confidence interval is within a tolerable interval — is.CI_within","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/Spower/reference/is.CI_within.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evaluate whether a confidence interval is within a tolerable interval — is.CI_within","text":"","code":"CI <- c(.2, .4) LU <- c(.1, .3) is.CI_within(CI, LU)        # not within tolerable interval #> [1] FALSE is.CI_within(CI, c(0, .5))  # is within wider interval #> [1] TRUE  # complement indicates if CI is outside interval !is.CI_within(CI, LU) #> [1] TRUE  ##### # for superiority test is.CI_within(CI, c(.1, Inf))  # CI is within tolerable interval #> [1] TRUE  # for inferiority test is.CI_within(CI, c(-Inf, .3))  # CI is not within tolerable interval #> [1] FALSE"},{"path":"https://philchalmers.github.io/Spower/reference/is.outside_CI.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate whether parameter is outside a given confidence interval — is.outside_CI","title":"Evaluate whether parameter is outside a given confidence interval — is.outside_CI","text":"Returns TRUE parameter reflecting null hypothesis falls outside given confidence interval. alternative approach writing experiment returns p-value.","code":""},{"path":"https://philchalmers.github.io/Spower/reference/is.outside_CI.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate whether parameter is outside a given confidence interval — is.outside_CI","text":"","code":"is.outside_CI(P0, CI)"},{"path":"https://philchalmers.github.io/Spower/reference/is.outside_CI.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate whether parameter is outside a given confidence interval — is.outside_CI","text":"P0 parameter evaluate CI confidence interval","code":""},{"path":"https://philchalmers.github.io/Spower/reference/is.outside_CI.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate whether parameter is outside a given confidence interval — is.outside_CI","text":"logical","code":""},{"path":[]},{"path":"https://philchalmers.github.io/Spower/reference/is.outside_CI.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Evaluate whether parameter is outside a given confidence interval — is.outside_CI","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/Spower/reference/is.outside_CI.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evaluate whether parameter is outside a given confidence interval — is.outside_CI","text":"","code":"p0 <- .3 CI <- c(.2, .4) is.outside_CI(p0, CI) #> [1] FALSE  # complement indicates if p0 is within CI !is.outside_CI(p0, CI) #> [1] TRUE"},{"path":"https://philchalmers.github.io/Spower/reference/p_2r.html","id":null,"dir":"Reference","previous_headings":"","what":"p-value from comparing two or more correlations simulation — p_2r","title":"p-value from comparing two or more correlations simulation — p_2r","text":"Function utilizes cocor perform correlation comparison independent, overlapping, non-overlapping correlation designs. Type type correlation design inferred based correlations specified.","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_2r.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"p-value from comparing two or more correlations simulation — p_2r","text":"","code":"p_2r(   n,   r.ab,   r.ab2 = NULL,   r.ac,   r.bc,   r.ad,   r.bd,   r.cd,   n2_n1 = 1,   two.tailed = TRUE,   test = NULL,   gen_fun = gen_2r,   return_analysis = FALSE,   ... )  gen_2r(n, R, ...)"},{"path":"https://philchalmers.github.io/Spower/reference/p_2r.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"p-value from comparing two or more correlations simulation — p_2r","text":"n sample size r.ab correlation variable B (independent groups, sample 1) r.ab2 (independent group test ) correlation variable B sample 2 r.ac (overlap/non-overlap) correlation C. correlation used overlapping hypothesis test, comparing input r.ab r.bc (overlap/non-overlap ) correlation B C. r.ad (non-overlap ) correlation D r.bd (non-overlap ) correlation B D r.cd (non-overlap ) correlation C D. correlation used non-overlapping hypothesis test, comparing input r.ab n2_n1 sample size ratio. used independent group test two.tailed logical; use two-tailed test? test hypothesis testing method use. Defaults 'fisher1925' independent groups test 'steiger1980' overlap/non-overlap tests gen_fun function used generate required discrete data. Object returned must matrix n rows. Default uses gen_2r. User defined version function must include argument ... return_analysis logical; return analysis object extraction customization? ... additional arguments passed gen_fun. used unless customized gen_fun defined R correlation matrix constructed inputs p_2r","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_2r.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"p-value from comparing two or more correlations simulation — p_2r","text":"single p-value","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_2r.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"p-value from comparing two or more correlations simulation — p_2r","text":"independent group tests, r.ab r.ab2 need specified, null hypothesis pertains \\(H_0: r_{ab}=r_{ab2}\\). overlapping correlation tests, r.ab, r.ac, r.bc need specified, null hypothesis pertains \\(H_0: r_{ab}=r_{ac}\\). non-overlapping correlation tests, correlations expect r.ab2 must specified, null hypothesis pertains \\(H_0: r_{ab}=r_{cd}\\).","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_2r.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"p-value from comparing two or more correlations simulation — p_2r","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_2r.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"p-value from comparing two or more correlations simulation — p_2r","text":"","code":"# independent (same x-y pairing across groups) p_2r(100, r.ab=.5, r.ab2=.6) #> [1] 0.5411214  # return cocor object for further analysis p_2r(100, r.ab=.5, r.ab2=.6, return_analysis = TRUE) #>  #>   Results of a comparison of two correlations based on independent groups #>  #> Comparison between r1.jk (y, x) = 0.5909 and r2.hm (y, x) = 0.5523 #> Difference: r1.jk - r2.hm = 0.0386 #> Data: sample1: j = y, k = x; sample2: h = y, m = x #> Group sizes: n1 = 100, n2 = 100 #> Null hypothesis: r1.jk is equal to r2.hm #> Alternative hypothesis: r1.jk is not equal to r2.hm (two-sided) #> Alpha: 0.05 #>  #> fisher1925: Fisher's z (1925) #>   z = 0.3998, p-value = 0.6893 #>   Null hypothesis retained #>   # \\donttest{     # estimate empirical power    p_2r(n=100, r.ab=.5, r.ab2=.6) |> Spower() #>  #> Execution time (H:M:S): 00:00:19 #> Design conditions:  #>  #> # A tibble: 1 × 5 #>       n  r.ab r.ab2 sig.level power #>   <dbl> <dbl> <dbl>     <dbl> <lgl> #> 1   100   0.5   0.6      0.05 NA    #>  #> Estimate of power: 0.178 #> 95% Confidence Interval: [0.171, 0.186]     # estimate n required to reach 80% power    p_2r(n=NA, r.ab=.5, r.ab2=.6) |>         Spower(power=.80, interval=c(100, 5000)) #>  #> Execution time (H:M:S): 00:01:13 #> Design conditions:  #>  #> # A tibble: 1 × 5 #>       n  r.ab r.ab2 sig.level power #>   <dbl> <dbl> <dbl>     <dbl> <dbl> #> 1    NA   0.5   0.6      0.05   0.8 #>  #> Estimate of n: 759.1 #> 95% Predicted Confidence Interval: [750.4, 767.8]  # }  # overlap (same y, different xs) # H0: r.ab = r.bc p_2r(100, r.ab=.5, r.ac=.3, r.bc=.2) #> [1] 0.02333902  # nonoverlap (different ys, different xs) # H0: r.ab = r.cd p_2r(100, r.ab=.5, r.ac=.3, r.bc=.2, r.ad=.2, r.bd=.4, r.cd=.2) #> [1] 0.03451324"},{"path":"https://philchalmers.github.io/Spower/reference/p_anova.test.html","id":null,"dir":"Reference","previous_headings":"","what":"p-value from one-way ANOVA simulation — p_anova.test","title":"p-value from one-way ANOVA simulation — p_anova.test","text":"Generates continuous multi-sample data analyzed one-way ANOVA, return p-value. Uses function oneway.test perform analyses. data associated test assume conditional observations normally distributed equal variance default, however may modified.","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_anova.test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"p-value from one-way ANOVA simulation — p_anova.test","text":"","code":"p_anova.test(   n,   k,   f,   n.ratios = rep(1, k),   two.tailed = TRUE,   var.equal = TRUE,   means = NULL,   sds = NULL,   gen_fun = gen_anova.test,   return_analysis = FALSE,   ... )  gen_anova.test(n, k, f, n.ratios = rep(1, k), means = NULL, sds = NULL, ...)"},{"path":"https://philchalmers.github.io/Spower/reference/p_anova.test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"p-value from one-way ANOVA simulation — p_anova.test","text":"n sample size per group k number groups f Cohen's f effect size n.ratios allocation ratios reflecting sample size ratios. Default 1 sets groups size (n * n.ratio) two.tailed logical; two-tailed one-tailed test used? var.equal logical; use pooled SE estimate instead Welch correction unequal variances? means (optional) vector means. specified input f ignored sds (optional) vector SDs. specified input f ignored gen_fun function used generate required data. Object returned must matrix k rows k columns numeric data. Default uses gen_anova.test. User defined version function must include argument ... return_analysis logical; return analysis object extraction customization? ... additional arguments passed gen_fun. used unless customized gen_fun defined","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_anova.test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"p-value from one-way ANOVA simulation — p_anova.test","text":"single p-value","code":""},{"path":[]},{"path":"https://philchalmers.github.io/Spower/reference/p_anova.test.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"p-value from one-way ANOVA simulation — p_anova.test","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_anova.test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"p-value from one-way ANOVA simulation — p_anova.test","text":"","code":"# n=50 in 3 groups, \"medium\" effect size p_anova.test(50, k=3, f=.25) #> [1] 0.1037413  # return analysis model p_anova.test(50, k=3, f=.25, return_analysis=TRUE) #>  #> \tOne-way analysis of means #>  #> data:  DV and group #> F = 1.0875, num df = 2, denom df = 147, p-value = 0.3398 #>   # explicit means/sds p_anova.test(50, 3, means=c(0,0,1), sds=c(1,2,1)) #> [1] 0.003467751  # \\donttest{   # compare simulated results to pwr package   pwr::pwr.anova.test(f=0.28, k=4, n=20) #>  #>      Balanced one-way analysis of variance power calculation  #>  #>               k = 4 #>               n = 20 #>               f = 0.28 #>       sig.level = 0.05 #>           power = 0.5149793 #>  #> NOTE: n is number in each group #>    p_anova.test(n=20, k=4, f=.28) |> Spower() #>  #> Execution time (H:M:S): 00:00:09 #> Design conditions:  #>  #> # A tibble: 1 × 5 #>       n     k     f sig.level power #>   <dbl> <dbl> <dbl>     <dbl> <lgl> #> 1    20     4  0.28      0.05 NA    #>  #> Estimate of power: 0.517 #> 95% Confidence Interval: [0.507, 0.526] # }"},{"path":"https://philchalmers.github.io/Spower/reference/p_chisq.test.html","id":null,"dir":"Reference","previous_headings":"","what":"p-value from chi-squared test simulation — p_chisq.test","title":"p-value from chi-squared test simulation — p_chisq.test","text":"Generates multinomial data suitable analysis chisq.test.","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_chisq.test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"p-value from chi-squared test simulation — p_chisq.test","text":"","code":"p_chisq.test(   n,   w,   df,   correct = TRUE,   P0 = NULL,   P = NULL,   gen_fun = gen_chisq.test,   return_analysis = FALSE,   ... )  gen_chisq.test(n, P, ...)"},{"path":"https://philchalmers.github.io/Spower/reference/p_chisq.test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"p-value from chi-squared test simulation — p_chisq.test","text":"n sample size per group w Cohen's w effect size df degrees freedom correct logical; apply continuity correction? P0 specific null pattern, specified numeric vector matrix P specific power configuration, specified numeric vector matrix gen_fun function used generate required discrete data. Object returned must matrix k rows k columns counts. Default uses gen_chisq.test. User defined version function must include argument ... return_analysis logical; return analysis object extraction customization? ... additional arguments passed gen_fun. used unless customized gen_fun defined","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_chisq.test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"p-value from chi-squared test simulation — p_chisq.test","text":"single p-value","code":""},{"path":[]},{"path":"https://philchalmers.github.io/Spower/reference/p_chisq.test.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"p-value from chi-squared test simulation — p_chisq.test","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_chisq.test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"p-value from chi-squared test simulation — p_chisq.test","text":"","code":"# effect size w + df p_chisq.test(100, w=.2, df=3) #> [1] 0.6961859  # return analysis model p_chisq.test(100, w=.2, df=3, return_analysis=TRUE) #>  #> \tChi-squared test for given probabilities #>  #> data:  tab #> X-squared = 3.12, df = 3, p-value = 0.3735 #>   # vector of explicit probabilities (goodness of fit test) p_chisq.test(100, P0 = c(.25, .25, .25, .25),                    P = c(.6, .2, .1, .1)) #> [1] 2.826475e-08  # matrix of explicit probabilities (two-dimensional test of independence) p_chisq.test(100, P0 = matrix(c(.25, .25, .25, .25), 2, 2),                    P = matrix(c(.6, .2, .1, .1),2,2)) #> [1] 0.02256915  # \\donttest{     # compare simulated results to pwr package      P0 <- c(1/3, 1/3, 1/3)     P <- c(.5, .25, .25)     w <- pwr::ES.w1(P0, P)     df <- 3-1     pwr::pwr.chisq.test(w=w, df=df, N=100, sig.level=0.05) #>  #>      Chi squared power calculation  #>  #>               w = 0.3535534 #>               N = 100 #>              df = 2 #>       sig.level = 0.05 #>           power = 0.8962428 #>  #> NOTE: N is the number of observations #>       # slightly less power when evaluated empirically     p_chisq.test(n=100, w=w, df=df) |> Spower(replications=100000) #>  #> Execution time (H:M:S): 00:00:21 #> Design conditions:  #>  #> # A tibble: 1 × 3 #>       n sig.level power #>   <dbl>     <dbl> <lgl> #> 1   100      0.05 NA    #>  #> Estimate of power: 0.886 #> 95% Confidence Interval: [0.884, 0.888]     p_chisq.test(n=100, P0=P0, P=P) |> Spower(replications=100000) #>  #> Execution time (H:M:S): 00:00:16 #> Design conditions:  #>  #> # A tibble: 1 × 3 #>       n sig.level power #>   <dbl>     <dbl> <lgl> #> 1   100      0.05 NA    #>  #> Estimate of power: 0.888 #> 95% Confidence Interval: [0.886, 0.890]      # slightly differ (latter more conservative due to finite sampling behaviour)     pwr::pwr.chisq.test(w=w, df=df, power=.8, sig.level=0.05) #>  #>      Chi squared power calculation  #>  #>               w = 0.3535534 #>               N = 77.07751 #>              df = 2 #>       sig.level = 0.05 #>           power = 0.8 #>  #> NOTE: N is the number of observations #>      p_chisq.test(n=NA, w=w, df=df) |>            Spower(power=.80, interval=c(50, 200)) #>  #> Execution time (H:M:S): 00:00:22 #> Design conditions:  #>  #> # A tibble: 1 × 3 #>       n sig.level power #>   <dbl>     <dbl> <dbl> #> 1    NA      0.05   0.8 #>  #> Estimate of n: 79.6 #> 95% Predicted Confidence Interval: [78.9, 80.2]     p_chisq.test(n=NA, w=w, df=df, correct=FALSE) |>            Spower(power=.80, interval=c(50, 200)) #>  #> Execution time (H:M:S): 00:00:17 #> Design conditions:  #>  #> # A tibble: 1 × 4 #>       n correct sig.level power #>   <dbl> <lgl>       <dbl> <dbl> #> 1    NA FALSE        0.05   0.8 #>  #> Estimate of n: 80.1 #> 95% Predicted Confidence Interval: [79.5, 80.8]      # Spower slightly more conservative even with larger N     pwr::pwr.chisq.test(w=.1, df=df, power=.95, sig.level=0.05) #>  #>      Chi squared power calculation  #>  #>               w = 0.1 #>               N = 1544.324 #>              df = 2 #>       sig.level = 0.05 #>           power = 0.95 #>  #> NOTE: N is the number of observations #>      p_chisq.test(n=NA, w=.1, df=df) |>            Spower(power=.95, interval=c(1000, 2000)) #>  #> Execution time (H:M:S): 00:00:06 #> Design conditions:  #>  #> # A tibble: 1 × 4 #>       n     w sig.level power #>   <dbl> <dbl>     <dbl> <dbl> #> 1    NA   0.1      0.05  0.95 #>  #> Estimate of n: 1582.7 #> 95% Predicted Confidence Interval: [1546.6, 1636.7]     p_chisq.test(n=NA, w=.1, df=df, correct=FALSE) |>            Spower(power=.95, interval=c(1000, 2000)) #>  #> Execution time (H:M:S): 00:00:08 #> Design conditions:  #>  #> # A tibble: 1 × 5 #>       n     w correct sig.level power #>   <dbl> <dbl> <lgl>       <dbl> <dbl> #> 1    NA   0.1 FALSE        0.05  0.95 #>  #> Estimate of n: 1546.8 #> 95% Predicted Confidence Interval: [1536.5, 1556.9]  # }"},{"path":"https://philchalmers.github.io/Spower/reference/p_glm.html","id":null,"dir":"Reference","previous_headings":"","what":"p-value from (generalized) linear regression model simulations with fixed predictors — p_glm","title":"p-value from (generalized) linear regression model simulations with fixed predictors — p_glm","text":"p-values associated (generalized) linear regression model. Requires pre-specified design matrix (X).","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_glm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"p-value from (generalized) linear regression model simulations with fixed predictors — p_glm","text":"","code":"p_glm(   formula,   X,   betas,   test,   sigma = NULL,   family = gaussian(),   gen_fun = gen_glm,   return_analysis = FALSE,   ... )  gen_glm(formula, X, betas, sigma = NULL, family = gaussian(), ...)"},{"path":"https://philchalmers.github.io/Spower/reference/p_glm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"p-value from (generalized) linear regression model simulations with fixed predictors — p_glm","text":"formula formula passed either lm glm X data.frame containing covariates betas vector slope coefficients match model.matrix version X test character vector specifying test pass lht. Can also list character vectors evaluate multiple tests sigma residual standard deviation linear model. used family = 'gaussian' family family distributions use (see family) gen_fun function used generate required discrete data. Object returned must data.frame. Default uses gen_glm. User defined version function must include argument ... return_analysis logical; return analysis object extraction customization? ... additional arguments passed gen_fun. used unless customized gen_fun defined","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_glm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"p-value from (generalized) linear regression model simulations with fixed predictors — p_glm","text":"single p-value","code":""},{"path":[]},{"path":"https://philchalmers.github.io/Spower/reference/p_glm.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"p-value from (generalized) linear regression model simulations with fixed predictors — p_glm","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_glm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"p-value from (generalized) linear regression model simulations with fixed predictors — p_glm","text":"","code":"X <- data.frame(G = factor(rep(c('control', 'treatment'), each=50)),                 C = sample(50:100, 100, replace=TRUE)) head(X) #>         G  C #> 1 control 96 #> 2 control 72 #> 3 control 83 #> 4 control 66 #> 5 control 54 #> 6 control 85  # ANCOVA setup p_glm(y ~ G + C, test=\"Gtreatment = 0\",   X=X, betas=c(10, .3, 1), sigma=1) #> [1] 0.02103663  # return analysis model p_glm(y ~ G + C, test=\"Gtreatment = 0\",   X=X, betas=c(10, .3, 1), sigma=1, return_analysis=TRUE) #>  #> Call: #> lm(formula = formula, data = X) #>  #> Coefficients: #> (Intercept)   Gtreatment            C   #>      9.7051       0.5201       1.0033   #>    # ANCOVA setup with logistic regression p_glm(y ~ G + C, test=\"Gtreatment = 0\",   X=X, betas=c(-2, .5, .01), family=binomial()) #> [1] 0.4833122  # ANCOVA setup with poisson regression p_glm(y ~ G + C, test=\"Gtreatment = 0\",   X=X, betas=c(-2, .5, .01), family=poisson()) #> [1] 0.01291868  # \\donttest{  # test whether two slopes differ given different samples. #   To do this setup data as an MLR where a binary variable S #   is used to reflect the second sample, and the interaction #   effect evaluates the magnitude of the slope difference gen_twogroup <- function(n, dbeta, sdx1, sdx2, sigma, n2_n1 = 1, ...){   X1 <- rnorm(n, sd=sdx1)   X2 <- rnorm(n*n2_n1, sd=sdx2)   X <- c(X1, X2)   N <- length(X)   S <- c(rep(0, n), rep(1, N-n))   y <- dbeta * X*S + rnorm(N, sd=sigma)   dat <- data.frame(y, X, S)   dat }  # prospective power using test that interaction effect is equal to 0 p_glm(formula=y~X*S, test=\"X:S = 0\",     n=100, sdx1=1, sdx2=2, dbeta=0.2,     sigma=0.5, gen_fun=gen_twogroup) |> Spower(replications=1000) #>  #> Execution time (H:M:S): 00:00:02 #> Design conditions:  #>  #> # A tibble: 1 × 8 #>   test    sigma     n  sdx1  sdx2 dbeta sig.level power #>   <chr>   <dbl> <dbl> <dbl> <dbl> <dbl>     <dbl> <lgl> #> 1 X:S = 0   0.5   100     1     2   0.2      0.05 NA    #>  #> Estimate of power: 0.923 #> 95% Confidence Interval: [0.906, 0.940]  # }"},{"path":"https://philchalmers.github.io/Spower/reference/p_kruskal.test.html","id":null,"dir":"Reference","previous_headings":"","what":"p-value from Kruskal-Wallis Rank Sum Test simulation — p_kruskal.test","title":"p-value from Kruskal-Wallis Rank Sum Test simulation — p_kruskal.test","text":"Simulates data given two parent distributions returns p-value using kruskal.test. Default generates data Gaussian distributions, however can modified.","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_kruskal.test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"p-value from Kruskal-Wallis Rank Sum Test simulation — p_kruskal.test","text":"","code":"p_kruskal.test(   n,   k,   means,   n.ratios = rep(1, k),   gen_fun = gen_kruskal.test,   return_analysis = FALSE,   ... )  gen_kruskal.test(n, k, n.ratios, means, ...)"},{"path":"https://philchalmers.github.io/Spower/reference/p_kruskal.test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"p-value from Kruskal-Wallis Rank Sum Test simulation — p_kruskal.test","text":"n sample size per group k number groups means vector means control location parameters n.ratios allocation ratios reflecting sample size ratios. Default 1 sets groups size (n * n.ratio) gen_fun function used generate required data. Object returned must list length k, element contains sample data group. Default uses gen_kruskal.test. User defined version function must include argument ... return_analysis logical; return analysis object extraction customization? ... additional arguments pass gen_fun","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_kruskal.test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"p-value from Kruskal-Wallis Rank Sum Test simulation — p_kruskal.test","text":"single p-value","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_kruskal.test.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"p-value from Kruskal-Wallis Rank Sum Test simulation — p_kruskal.test","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_kruskal.test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"p-value from Kruskal-Wallis Rank Sum Test simulation — p_kruskal.test","text":"","code":"# three group test where data generate from Gaussian distributions p_kruskal.test(n=30, k=3, means=c(0, .5, .6)) #> [1] 0.0005061295  # return analysis model p_kruskal.test(n=30, k=3, means=c(0, .5, .6), return_analysis=TRUE) #>  #> \tKruskal-Wallis rank sum test #>  #> data:  dat #> Kruskal-Wallis chi-squared = 10.328, df = 2, p-value = 0.005719 #>   # generate data from chi-squared distributions with different variances gen_chisq <- function(n, k, n.ratios, means, dfs, ...){   dat <- vector('list', k)   ns <- n * n.ratios   for(g in 1:k)    dat[[g]] <- rchisq(ns[g], df=dfs[g]) - dfs[g] + means[g]   dat }  p_kruskal.test(n=30, k=3, means=c(0, 1, 2),    gen_fun=gen_chisq, dfs=c(10, 15, 20)) #> [1] 0.702669  # \\donttest{   # empirical power estimate   p_kruskal.test(n=30, k=3, means=c(0, .5, .6)) |> Spower() #>  #> Execution time (H:M:S): 00:00:06 #> Design conditions:  #>  #> # A tibble: 1 × 4 #>       n     k sig.level power #>   <dbl> <dbl>     <dbl> <lgl> #> 1    30     3      0.05 NA    #>  #> Estimate of power: 0.553 #> 95% Confidence Interval: [0.543, 0.563]   p_kruskal.test(n=30, k=3, means=c(0, 1, 2), gen_fun=gen_chisq,          dfs = c(10, 15, 20)) |> Spower() #>  #> Execution time (H:M:S): 00:00:07 #> Design conditions:  #>  #> # A tibble: 1 × 4 #>       n     k sig.level power #>   <dbl> <dbl>     <dbl> <lgl> #> 1    30     3      0.05 NA    #>  #> Estimate of power: 0.185 #> 95% Confidence Interval: [0.177, 0.193]  # }"},{"path":"https://philchalmers.github.io/Spower/reference/p_ks.test.html","id":null,"dir":"Reference","previous_headings":"","what":"p-value from Kolmogorov-Smirnov one- or two-sample simulation — p_ks.test","title":"p-value from Kolmogorov-Smirnov one- or two-sample simulation — p_ks.test","text":"Generates one two sets continuous data group-level data returns p-value null groups drawn distribution (two sample) theoretically known distribution (one sample).","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_ks.test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"p-value from Kolmogorov-Smirnov one- or two-sample simulation — p_ks.test","text":"","code":"p_ks.test(   n,   p1,   p2,   n2_n1 = 1,   two.tailed = TRUE,   parent = NULL,   return_analysis = FALSE,   ... )"},{"path":"https://philchalmers.github.io/Spower/reference/p_ks.test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"p-value from Kolmogorov-Smirnov one- or two-sample simulation — p_ks.test","text":"n sample size per group, assumed equal across groups p1 function indicating data generated group 1 p2 (optional) function indicating data generated group 2. omitted one-sample test evaluated provided parent also specified n2_n1 sample size ratio. Default uses equal sample sizes two.tailed logical; two-tailed one-tailed test used? parent cumulative distribution function use (e.g., pnorm). Specifying input construct one-sample test setup return_analysis logical; return analysis object extraction customization? ... additional arguments passed parent distribution function ks.test, well relevant parameter ks.test (e.g., exact = TRUE)","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_ks.test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"p-value from Kolmogorov-Smirnov one- or two-sample simulation — p_ks.test","text":"single p-value","code":""},{"path":[]},{"path":"https://philchalmers.github.io/Spower/reference/p_ks.test.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"p-value from Kolmogorov-Smirnov one- or two-sample simulation — p_ks.test","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_ks.test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"p-value from Kolmogorov-Smirnov one- or two-sample simulation — p_ks.test","text":"","code":"# two-sample test from two Gaussian distributions with different locations p1 <- function(n) rnorm(n) p2 <- function(n) rnorm(n, mean=-.5) p_ks.test(n=100, p1, p2) #> [1] 0.2105516  # return analysis model p_ks.test(n=100, p1, p2, return_analysis=TRUE) #>  #> \tAsymptotic two-sample Kolmogorov-Smirnov test #>  #> data:  dat1 and dat2 #> D = 0.22, p-value = 0.01581 #> alternative hypothesis: two-sided #>   # one-sample data from chi-squared distribution tested #   against a standard normal distribution pc <- function(n, df=15) (rchisq(n, df=df) - df) / sqrt(2*df) p_ks.test(n=100, p1=pc, parent=pnorm, mean=0, sd=1) #> [1] 0.0341901  # \\donttest{   # empirical power estimates   p_ks.test(n=100, p1, p2) |> Spower() #>  #> Execution time (H:M:S): 00:00:03 #> Design conditions:  #>  #> # A tibble: 1 × 3 #>       n sig.level power #>   <dbl>     <dbl> <lgl> #> 1   100      0.05 NA    #>  #> Estimate of power: 0.827 #> 95% Confidence Interval: [0.819, 0.834]   p_ks.test(n=100, p1=pc, parent=pnorm, mean=0, sd=1) |> Spower() #>  #> Execution time (H:M:S): 00:00:02 #> Design conditions:  #>  #> # A tibble: 1 × 5 #>       n  mean    sd sig.level power #>   <dbl> <dbl> <dbl>     <dbl> <lgl> #> 1   100     0     1      0.05 NA    #>  #> Estimate of power: 0.143 #> 95% Confidence Interval: [0.136, 0.150]  # }"},{"path":"https://philchalmers.github.io/Spower/reference/p_lm.R2.html","id":null,"dir":"Reference","previous_headings":"","what":"p-value from global linear regression model simulation — p_lm.R2","title":"p-value from global linear regression model simulation — p_lm.R2","text":"p-values associated linear regression model using fixed/random independent variables. Focus omnibus behavior R^2 statistic.","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_lm.R2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"p-value from global linear regression model simulation — p_lm.R2","text":"","code":"p_lm.R2(   n,   R2,   k,   R2_0 = 0,   k.R2_0 = 0,   R2.resid = 1 - R2,   fixed = TRUE,   return_analysis = FALSE,   ... )"},{"path":"https://philchalmers.github.io/Spower/reference/p_lm.R2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"p-value from global linear regression model simulation — p_lm.R2","text":"n sample size R2 R-squared effect size k number IVs R2_0 null hypothesis R-squared k.R2_0 number IVs associated null hypothesis model R2.resid residual R-squared value, typically used comparing nested models fit sequentially (e.g., comparing model vs B model involves structure -> B -> C) fixed logical; FALSE data random generated according joint multivariate normal distribution return_analysis logical; return analysis object extraction customization? ... additional arguments passed gen_fun. used unless customized gen_fun defined","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_lm.R2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"p-value from global linear regression model simulation — p_lm.R2","text":"single p-value","code":""},{"path":[]},{"path":"https://philchalmers.github.io/Spower/reference/p_lm.R2.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"p-value from global linear regression model simulation — p_lm.R2","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_lm.R2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"p-value from global linear regression model simulation — p_lm.R2","text":"","code":"# 5 fixed IVs, R^2 = .1, sample size of 95 p_lm.R2(n=95, R2=.1, k=5) #> [1] 0.001117883  # random model p_lm.R2(n=95, R2=.1, k=5, fixed=FALSE) #> [1] 0.01962667  # return analysis model p_lm.R2(n=95, R2=.1, k=5, return_analysis=TRUE) #>  #> Call: #> lm(formula = y ~ ., data = df) #>  #> Coefficients: #> (Intercept)           X1           X2           X3           X4           X5   #>     0.09457      0.13480      0.08671     -0.19228     -0.09899      0.19240   #>"},{"path":"https://philchalmers.github.io/Spower/reference/p_mauchly.test.html","id":null,"dir":"Reference","previous_headings":"","what":"p-value from Mauchly's Test of Sphericity simulation — p_mauchly.test","title":"p-value from Mauchly's Test of Sphericity simulation — p_mauchly.test","text":"Perform simulation experiment Mauchly's Test Sphericity using function mauchlys.test, returning p-value. Assumes data multivariate normal distribution, however can modified.","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_mauchly.test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"p-value from Mauchly's Test of Sphericity simulation — p_mauchly.test","text":"","code":"p_mauchly.test(   n,   sigma,   gen_fun = gen_mauchly.test,   return_analysis = FALSE,   ... )  gen_mauchly.test(n, sigma, ...)  mauchlys.test(X)"},{"path":"https://philchalmers.github.io/Spower/reference/p_mauchly.test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"p-value from Mauchly's Test of Sphericity simulation — p_mauchly.test","text":"n sample size sigma symmetric covariance/correlation matrix passed gen_fun gen_fun function used generate required data. Object returned must matrix K columns n rows. Default uses gen_mauchly.test generate multivariate normal samples. User defined version function must include argument ... return_analysis logical; return analysis object extraction customization? ... additional arguments passed gen_fun. used unless customized gen_fun defined X matrix k columns n rows","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_mauchly.test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"p-value from Mauchly's Test of Sphericity simulation — p_mauchly.test","text":"single p-value","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_mauchly.test.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"p-value from Mauchly's Test of Sphericity simulation — p_mauchly.test","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_mauchly.test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"p-value from Mauchly's Test of Sphericity simulation — p_mauchly.test","text":"","code":"sigma <- diag(c(1,2,1)) sigma #>      [,1] [,2] [,3] #> [1,]    1    0    0 #> [2,]    0    2    0 #> [3,]    0    0    1  # H0 test that sphericity holds p_mauchly.test(100, sigma=sigma) #> [1] 0.2675412  # return analysis object p_mauchly.test(100, sigma=sigma, return_analysis=TRUE) #>          W df     p.value #> 1 0.851268  2 0.000374325  # Null is true sigma.H0 <- diag(3) p_mauchly.test(100, sigma=sigma.H0) #> [1] 0.6799348   # \\donttest{     # empirical power estimate     p_mauchly.test(100, sigma=sigma) |> Spower() #>  #> Execution time (H:M:S): 00:00:09 #> Design conditions:  #>  #> # A tibble: 1 × 3 #>       n sig.level power #>   <dbl>     <dbl> <lgl> #> 1   100      0.05 NA    #>  #> Estimate of power: 0.609 #> 95% Confidence Interval: [0.599, 0.618]      # empirical Type I error estimate     p_mauchly.test(100, sigma=sigma.H0) |> Spower() #>  #> Execution time (H:M:S): 00:00:09 #> Design conditions:  #>  #> # A tibble: 1 × 3 #>       n sig.level power #>   <dbl>     <dbl> <lgl> #> 1   100      0.05 NA    #>  #> Estimate of power: 0.049 #> 95% Confidence Interval: [0.045, 0.054] # }"},{"path":"https://philchalmers.github.io/Spower/reference/p_mcnemar.test.html","id":null,"dir":"Reference","previous_headings":"","what":"p-value from McNemar test simulation — p_mcnemar.test","title":"p-value from McNemar test simulation — p_mcnemar.test","text":"Generates two-dimensional sample data McNemar test return p-value. Uses mcnemar.test.","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_mcnemar.test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"p-value from McNemar test simulation — p_mcnemar.test","text":"","code":"p_mcnemar.test(   n,   prop,   OR = NULL,   prop.disc = NULL,   two.tailed = TRUE,   correct = TRUE,   gen_fun = gen_mcnemar.test,   return_analysis = FALSE,   ... )  gen_mcnemar.test(n, prop, ...)"},{"path":"https://philchalmers.github.io/Spower/reference/p_mcnemar.test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"p-value from McNemar test simulation — p_mcnemar.test","text":"n total sample size prop two-dimensional matrix proportions/probabilities instead supplying prop table, odds ratio can specified instead \\(\\pi_{12}/\\pi_{21}\\). Also requires proportion discordant pairings specified prop.disc proportion discordant pairings, \\(\\pi_{12} + \\pi_{21}\\) two.tailed logical; two-tailed one-tailed test used? correct logical; use continuity correction? applicable 2x2 tables gen_fun function used generate required discrete data. Object returned must matrix k rows k columns counts. Default uses gen_mcnemar.test. User defined version function must include argument ... return_analysis logical; return analysis object extraction customization? ... additional arguments passed gen_fun. used unless customized gen_fun defined","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_mcnemar.test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"p-value from McNemar test simulation — p_mcnemar.test","text":"single p-value","code":""},{"path":[]},{"path":"https://philchalmers.github.io/Spower/reference/p_mcnemar.test.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"p-value from McNemar test simulation — p_mcnemar.test","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_mcnemar.test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"p-value from McNemar test simulation — p_mcnemar.test","text":"","code":"# from ?mcnemar.test Performance <- matrix(c(794, 86, 150, 570),        nrow = 2,        dimnames = list(\"1st Survey\" = c(\"Approve\", \"Disapprove\"),                    \"2nd Survey\" = c(\"Approve\", \"Disapprove\"))) (prop <- prop.table(Performance)) #>             2nd Survey #> 1st Survey   Approve Disapprove #>   Approve    0.49625    0.09375 #>   Disapprove 0.05375    0.35625  # one sample + test and resulting p-value p_mcnemar.test(n=sum(Performance), prop=prop) #> [1] 9.682145e-11  # return analysis model p_mcnemar.test(n=sum(Performance), prop=prop, return_analysis=TRUE) #>  #> \tMcNemar's Chi-squared test with continuity correction #>  #> data:  dat #> McNemar's chi-squared = 16.676, df = 1, p-value = 4.433e-05 #>   # \\donttest{  # post-hoc power (not recommended) Spower(p_mcnemar.test(n=sum(Performance), prop=prop)) #> Error in eval(x, parent.frame()): object 'Performance' not found  # odds ratio + discordant proportions supplied instead OR <- prop[1,2] / prop[2,1] disc <- prop[1,2] + prop[2,1] p_mcnemar.test(n=50, OR=.25, prop.disc=disc, two.tailed=FALSE) |>   Spower(replications=30000) #>  #> Execution time (H:M:S): 00:00:05 #> Design conditions:  #>  #> # A tibble: 1 × 5 #>       n    OR two.tailed sig.level power #>   <dbl> <dbl> <lgl>          <dbl> <lgl> #> 1    50  0.25 FALSE           0.05 NA    #>  #> Estimate of power: 0.337 #> 95% Confidence Interval: [0.332, 0.342]  # }"},{"path":"https://philchalmers.github.io/Spower/reference/p_mediation.html","id":null,"dir":"Reference","previous_headings":"","what":"p-value from three-variable mediation analysis simulation — p_mediation","title":"p-value from three-variable mediation analysis simulation — p_mediation","text":"Simple 3-variable mediation analysis simulation test hypothesis X -> Y mediated relationship X -> M -> Y. Currently, M Y assumed continuous variables Gaussian errors, X may continuous dichotomous.","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_mediation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"p-value from three-variable mediation analysis simulation — p_mediation","text":"","code":"p_mediation(   n,   a,   b,   cprime,   dichotomous.X = FALSE,   two.tailed = TRUE,   method = \"wald\",   sd.X = 1,   sd.Y = 1,   sd.M = 1,   gen_fun = gen_mediation,   return_analysis = FALSE,   ... )  gen_mediation(   n,   a,   b,   cprime,   dichotomous.X = FALSE,   sd.X = 1,   sd.Y = 1,   sd.M = 1,   ... )"},{"path":"https://philchalmers.github.io/Spower/reference/p_mediation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"p-value from three-variable mediation analysis simulation — p_mediation","text":"n total sample size unless dichotomous.X = TRUE, value represents size per group regression coefficient path X -> M b regression coefficient path M -> Y cprime partial regression coefficient path X -> Y dichotomous.X logical; X variable generated though dichotomous? TRUE n represents sample size per group two.tailed logical; two-tailed one-tailed test used? method type inferential method use. Default uses Wald (.k.., Sobel) test sd.X standard deviation X sd.Y standard deviation Y sd.M standard deviation M gen_fun function used generate required two-sample data. Object returned must data.frame columns \"DV\" \"group\". Default uses gen_mediation generate conditionally Gaussian distributed samples. User defined version function must include argument ... return_analysis logical; return analysis object extraction customization? ... additional arguments passed gen_fun. used unless customized gen_fun defined","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_mediation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"p-value from three-variable mediation analysis simulation — p_mediation","text":"single p-value","code":""},{"path":[]},{"path":"https://philchalmers.github.io/Spower/reference/p_mediation.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"p-value from three-variable mediation analysis simulation — p_mediation","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_mediation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"p-value from three-variable mediation analysis simulation — p_mediation","text":"","code":"# joint test H0: a*b = 0 p_mediation(50, a=sqrt(.35), b=sqrt(.35), cprime=.39) #> [1] 0.02351936 p_mediation(50, a=sqrt(.35), b=sqrt(.35), cprime=.39, dichotomous.X=TRUE) #> [1] 4.292603e-09  # return analysis model p_mediation(50, a=sqrt(.35), b=sqrt(.35), cprime=.39, return_analysis=TRUE) #> lavaan 0.6-21 ended normally after 1 iteration #>  #>   Estimator                                         ML #>   Optimization method                           NLMINB #>   Number of model parameters                         5 #>  #>   Number of observations                            50 #>  #> Model Test User Model: #>                                                        #>   Test statistic                                 0.000 #>   Degrees of freedom                                 0  # \\donttest{    # power to detect mediation   p_mediation(n=50, a=sqrt(.35), b=sqrt(.35), cprime=.39) |>     Spower(parallel=TRUE, replications=1000) #>  #> Execution time (H:M:S): 00:00:21 #> Design conditions:  #>  #> # A tibble: 1 × 4 #>       n cprime sig.level power #>   <dbl>  <dbl>     <dbl> <lgl> #> 1    50   0.39      0.05 NA    #>  #> Estimate of power: 0.998 #> 95% Confidence Interval: [0.995, 1.000]    # sample size estimate for .95 power   p_mediation(n=NA, a=sqrt(.35), b=sqrt(.35), cprime=.39) |>     Spower(power=.95, interval=c(50, 200), parallel=TRUE) #>  #> Execution time (H:M:S): 00:23:41 #> Design conditions:  #>  #> # A tibble: 1 × 4 #>       n cprime sig.level power #>   <dbl>  <dbl>     <dbl> <dbl> #> 1    NA   0.39      0.05  0.95 #>  #> Estimate of n: 50.0 #> 95% Predicted Confidence Interval: [NA, NA]  # }"},{"path":"https://philchalmers.github.io/Spower/reference/p_prop.test.html","id":null,"dir":"Reference","previous_headings":"","what":"p-value from proportion test simulation — p_prop.test","title":"p-value from proportion test simulation — p_prop.test","text":"Generates single multi-sample data proportion tests return p-value. Uses binom.test one-sample applications prop.test otherwise.","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_prop.test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"p-value from proportion test simulation — p_prop.test","text":"","code":"p_prop.test(   n,   h,   prop = NULL,   pi = 0.5,   n.ratios = rep(1, length(prop)),   two.tailed = TRUE,   correct = TRUE,   exact = FALSE,   gen_fun = gen_prop.test,   return_analysis = FALSE,   ... )  gen_prop.test(   n,   h,   prop = NULL,   pi = 0.5,   n.ratios = rep(1, length(prop)),   ... )"},{"path":"https://philchalmers.github.io/Spower/reference/p_prop.test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"p-value from proportion test simulation — p_prop.test","text":"n sample size per group h Cohen's h effect size; supported one-sample analysis. Note important specify null value pi supplying effect size power changes depending specific values (see example ). prop sample probability/proportions success. vector two-values elements supplied multi-samples test used. Matrices also supported pi probability success test (default .5). Ignored two-sample tests n.ratios allocation ratios reflecting sample size ratios. Default 1 sets groups size (n * n.ratio) two.tailed logical; two-tailed one-tailed test used? correct logical; use Yates' continuity correction? exact logical; use fisher's exact test via fisher.test? Use flag requires prop specified matrix gen_fun function used generate required discrete data. Object returned must matrix two rows 1 columns. Default uses gen_prop.test. User defined version function must include argument ... return_analysis logical; return analysis object extraction customization? ... additional arguments passed gen_fun. used unless customized gen_fun defined","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_prop.test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"p-value from proportion test simulation — p_prop.test","text":"single p-value","code":""},{"path":[]},{"path":"https://philchalmers.github.io/Spower/reference/p_prop.test.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"p-value from proportion test simulation — p_prop.test","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_prop.test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"p-value from proportion test simulation — p_prop.test","text":"","code":"# one sample, 50 observations, tested against pi = .5 by default p_prop.test(50, prop=.65) #> [1] 0.1189205  # return analysis model p_prop.test(50, prop=.65, return_analysis = TRUE) #>  #> \tExact binomial test #>  #> data:  dat[1, 1] and n #> number of successes = 29, number of trials = 50, p-value = 0.3222 #> alternative hypothesis: true probability of success is not equal to 0.5 #> 95 percent confidence interval: #>  0.4320604 0.7181178 #> sample estimates: #> probability of success  #>                   0.58  #>   # specified using h and pi h <- pwr::ES.h(.65, .4) p_prop.test(50, h=h, pi=.4) #> [1] 0.002131058 p_prop.test(50, h=-h, pi=.65) #> [1] 6.656485e-07  # two-sample test p_prop.test(50, prop=c(.5, .65)) #> [1] 0.07163328  # two-sample test, unequal ns p_prop.test(50, prop=c(.5, .65), n.ratios = c(1,2)) #> [1] 0.01208178  # three-sample test, group2 twice as large as others p_prop.test(50, prop=c(.5, .65, .7), n.ratios=c(1,2,1)) #> [1] 0.008836383  # Fisher exact test p_prop.test(50, prop=matrix(c(.5, .65, .7, .5), 2, 2)) #> [1] 0.01971896  # \\donttest{     # compare simulated results to pwr package      # one-sample tests     (h <- pwr::ES.h(0.5, 0.4)) #> [1] 0.2013579     pwr::pwr.p.test(h=h, n=60) #>  #>      proportion power calculation for binomial distribution (arcsine transformation)  #>  #>               h = 0.2013579 #>               n = 60 #>       sig.level = 0.05 #>           power = 0.3447014 #>     alternative = two.sided #>       # uses binom.test (need to specify null location as this matters!)     Spower(p_prop.test(n=60, h=h, pi=.4)) #>  #> Execution time (H:M:S): 00:00:03 #> Design conditions:  #>  #> # A tibble: 1 × 4 #>       n    pi sig.level power #>   <dbl> <dbl>     <dbl> <lgl> #> 1    60   0.4      0.05 NA    #>  #> Estimate of power: 0.346 #> 95% Confidence Interval: [0.337, 0.356]     Spower(p_prop.test(n=60, prop=.5, pi=.4)) #>  #> Execution time (H:M:S): 00:00:03 #> Design conditions:  #>  #> # A tibble: 1 × 5 #>       n  prop    pi sig.level power #>   <dbl> <dbl> <dbl>     <dbl> <lgl> #> 1    60   0.5   0.4      0.05 NA    #>  #> Estimate of power: 0.345 #> 95% Confidence Interval: [0.336, 0.354]      # compare with switched null     Spower(p_prop.test(n=60, h=h, pi=.5)) #>  #> Execution time (H:M:S): 00:00:03 #> Design conditions:  #>  #> # A tibble: 1 × 4 #>       n    pi sig.level power #>   <dbl> <dbl>     <dbl> <lgl> #> 1    60   0.5      0.05 NA    #>  #> Estimate of power: 0.257 #> 95% Confidence Interval: [0.248, 0.265]     Spower(p_prop.test(n=60, prop=.4, pi=.5)) #>  #> Execution time (H:M:S): 00:00:03 #> Design conditions:  #>  #> # A tibble: 1 × 5 #>       n  prop    pi sig.level power #>   <dbl> <dbl> <dbl>     <dbl> <lgl> #> 1    60   0.4   0.5      0.05 NA    #>  #> Estimate of power: 0.260 #> 95% Confidence Interval: [0.251, 0.268]      # two-sample test, one-tailed     (h <- pwr::ES.h(0.67, 0.5)) #> [1] 0.3469169     pwr::pwr.2p.test(h=h, n=80, alternative=\"greater\") #>  #>      Difference of proportion power calculation for binomial distribution (arcsine transformation)  #>  #>               h = 0.3469169 #>               n = 80 #>       sig.level = 0.05 #>           power = 0.7085801 #>     alternative = greater #>  #> NOTE: same sample sizes #>      p_prop.test(n=80, prop=c(.67, .5), two.tailed=FALSE,       correct=FALSE) |> Spower() #>  #> Execution time (H:M:S): 00:00:03 #> Design conditions:  #>  #> # A tibble: 1 × 5 #>       n two.tailed correct sig.level power #>   <dbl> <lgl>      <lgl>       <dbl> <lgl> #> 1    80 FALSE      FALSE        0.05 NA    #>  #> Estimate of power: 0.694 #> 95% Confidence Interval: [0.685, 0.703]      # same as above, but with continuity correction (default)     p_prop.test(n=80, prop=c(.67, .5), two.tailed=FALSE) |>       Spower() #>  #> Execution time (H:M:S): 00:00:03 #> Design conditions:  #>  #> # A tibble: 1 × 4 #>       n two.tailed sig.level power #>   <dbl> <lgl>          <dbl> <lgl> #> 1    80 FALSE           0.05 NA    #>  #> Estimate of power: 0.643 #> 95% Confidence Interval: [0.633, 0.652]      # three-sample joint test, equal n's     p_prop.test(n=50, prop=c(.6,.4,.7)) |> Spower() #>  #> Execution time (H:M:S): 00:00:03 #> Design conditions:  #>  #> # A tibble: 1 × 3 #>       n sig.level power #>   <dbl>     <dbl> <lgl> #> 1    50      0.05 NA    #>  #> Estimate of power: 0.798 #> 95% Confidence Interval: [0.791, 0.806]  # }"},{"path":"https://philchalmers.github.io/Spower/reference/p_r.cat.html","id":null,"dir":"Reference","previous_headings":"","what":"p-value from tetrachoric/polychoric or polyserial — p_r.cat","title":"p-value from tetrachoric/polychoric or polyserial — p_r.cat","text":"Generates correlated X-Y data returns p-value assess null correlation population. X-Y data generated assuming multivariate normal distribution subsequently discretized one variables.","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_r.cat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"p-value from tetrachoric/polychoric or polyserial — p_r.cat","text":"","code":"p_r.cat(   n,   r,   tauX,   rho = 0,   tauY = NULL,   ML = TRUE,   two.tailed = TRUE,   score = FALSE,   gen_fun = gen_r,   return_analysis = FALSE,   ... )"},{"path":"https://philchalmers.github.io/Spower/reference/p_r.cat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"p-value from tetrachoric/polychoric or polyserial — p_r.cat","text":"n sample size r correlation prior discretization (recovered via polyserial/polychoric estimates) tauX intercept parameters used discretizing X variable rho population coefficient test tauY intercept parameters used discretizing Y variable. missing polyserial correlation estimated, otherwise tetrachoric/polychoric correlation estimated ML logical; use maximum-likelihood estimation? two.tailed logical; two-tailed one-tailed test used? score logical; SE based null hypothesis (score test) ML estimate (Wald test)? former canonical form priori power analyses though requires twice many computations Wald test approach gen_fun function used generate required continuous bivariate data (prior truncation). Object returned must matrix two columns. Default uses gen_r generate conditionally dependent data bivariate normal distribution. User defined version function must include argument ... return_analysis logical; return analysis object extraction customization? ... additional arguments passed gen_fun. used unless customized gen_fun defined","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_r.cat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"p-value from tetrachoric/polychoric or polyserial — p_r.cat","text":"single p-value","code":""},{"path":[]},{"path":"https://philchalmers.github.io/Spower/reference/p_r.cat.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"p-value from tetrachoric/polychoric or polyserial — p_r.cat","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_r.cat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"p-value from tetrachoric/polychoric or polyserial — p_r.cat","text":"","code":"# 100 observations, .5 correlation, tetrachoric estimate p_r.cat(100, r=.5, tauX=0, tauY=1) #> [1] 0.02083308  # return analysis model p_r.cat(100, r=.5, tauX=0, tauY=1, return_analysis=TRUE) #>  #> Polychoric Correlation, ML est. = 0.4779 (0.1793) #>  #>   Row Threshold #>   Threshold Std.Err. #>       1.175   0.1624 #>  #>  #>   Column Threshold #>   Threshold Std.Err. #>    -0.07527   0.1255  # Wald test p_r.cat(100, r=.5, tauX=0, tauY=1, score=FALSE) #> [1] 0.01119212  # polyserial estimate (Y continuous) p_r.cat(50, r=.5, tauX=0) #> [1] 0.006380214"},{"path":"https://philchalmers.github.io/Spower/reference/p_r.html","id":null,"dir":"Reference","previous_headings":"","what":"p-value from correlation simulation — p_r","title":"p-value from correlation simulation — p_r","text":"Generates correlated X-Y data returns p-value assess null correlation population. X-Y data generated assuming bivariate normal distribution.","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_r.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"p-value from correlation simulation — p_r","text":"","code":"p_r(   n,   r,   rho = 0,   method = \"pearson\",   two.tailed = TRUE,   gen_fun = gen_r,   return_analysis = FALSE,   ... )  gen_r(n, r, ...)"},{"path":"https://philchalmers.github.io/Spower/reference/p_r.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"p-value from correlation simulation — p_r","text":"n sample size r correlation rho population coefficient test . Uses Fisher's z-transformation approximation non-zero method method use compute correlation (see cor.test). used rho = 0 two.tailed logical; two-tailed one-tailed test used? gen_fun function used generate required dependent bivariate data. Object returned must matrix two columns n rows. Default uses gen_r generate conditionally dependent data bivariate normal distribution. User defined version function must include argument ... return_analysis logical; return analysis object extraction customization? Note rho != 0 p.value related element replaced internally computed approximation versions ... additional arguments passed gen_fun. used unless customized gen_fun defined","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_r.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"p-value from correlation simulation — p_r","text":"single p-value","code":""},{"path":[]},{"path":"https://philchalmers.github.io/Spower/reference/p_r.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"p-value from correlation simulation — p_r","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_r.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"p-value from correlation simulation — p_r","text":"","code":"# 50 observations, .5 correlation p_r(50, r=.5) #> [1] 1.118634e-05 p_r(50, r=.5, method = 'spearman') #> [1] 8.326385e-05  # test against constant other than rho = .6 p_r(50, .5, rho=.60) #> [1] 0.2973482  # return analysis model p_r(50, .5, return_analysis=TRUE) #>  #> \tPearson's product-moment correlation #>  #> data:  x and y #> t = 3.2934, df = 48, p-value = 0.001863 #> alternative hypothesis: true correlation is not equal to 0 #> 95 percent confidence interval: #>  0.1714634 0.6321291 #> sample estimates: #>       cor  #> 0.4293211  #>  p_r(50, .5, rho=.60, return_analysis=TRUE) #>  #> \tPearson's product-moment correlation #>  #> data:  x and y #> t = -0.38724, df = Inf, p-value = 0.6986 #> alternative hypothesis: true correlation is not equal to 0.6 #> 95 percent confidence interval: #>  0.3370604 0.7271028 #> sample estimates: #>       cor  #> 0.5626228  #>   # \\donttest{     # compare simulated results to pwr package      pwr::pwr.r.test(r=0.3, n=50) #>  #>      approximate correlation power calculation (arctangh transformation)  #>  #>               n = 50 #>               r = 0.3 #>       sig.level = 0.05 #>           power = 0.5715558 #>     alternative = two.sided #>      p_r(n=50, r=0.3) |> Spower() #>  #> Execution time (H:M:S): 00:00:08 #> Design conditions:  #>  #> # A tibble: 1 × 4 #>       n     r sig.level power #>   <dbl> <dbl>     <dbl> <lgl> #> 1    50   0.3      0.05 NA    #>  #> Estimate of power: 0.575 #> 95% Confidence Interval: [0.566, 0.585]      pwr::pwr.r.test(r=0.3, power=0.80) #>  #>      approximate correlation power calculation (arctangh transformation)  #>  #>               n = 84.07364 #>               r = 0.3 #>       sig.level = 0.05 #>           power = 0.8 #>     alternative = two.sided #>      p_r(n=NA, r=0.3) |> Spower(power=.80, interval=c(10, 200)) #>  #> Execution time (H:M:S): 00:00:32 #> Design conditions:  #>  #> # A tibble: 1 × 4 #>       n     r sig.level power #>   <dbl> <dbl>     <dbl> <dbl> #> 1    NA   0.3      0.05   0.8 #>  #> Estimate of n: 84.0 #> 95% Predicted Confidence Interval: [83.1, 84.8]      pwr::pwr.r.test(r=0.1, power=0.80) #>  #>      approximate correlation power calculation (arctangh transformation)  #>  #>               n = 781.7516 #>               r = 0.1 #>       sig.level = 0.05 #>           power = 0.8 #>     alternative = two.sided #>      p_r(n=NA, r=0.1) |> Spower(power=.80, interval=c(200, 1000)) #>  #> Execution time (H:M:S): 00:01:16 #> Design conditions:  #>  #> # A tibble: 1 × 4 #>       n     r sig.level power #>   <dbl> <dbl>     <dbl> <dbl> #> 1    NA   0.1      0.05   0.8 #>  #> Estimate of n: 788.1 #> 95% Predicted Confidence Interval: [772.8, 802.1]  # }"},{"path":"https://philchalmers.github.io/Spower/reference/p_scale.html","id":null,"dir":"Reference","previous_headings":"","what":"p-value from Scale Test simulation — p_scale","title":"p-value from Scale Test simulation — p_scale","text":"Simulates data given one two parent distributions returns p-value testing scale type distributions . Default implementation uses Gaussian distributions, however distribution function may modified reflect populations interest. Uses ansari.test mood.test analysis.","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_scale.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"p-value from Scale Test simulation — p_scale","text":"","code":"p_scale(   n,   scale,   n2_n1 = 1,   two.tailed = TRUE,   exact = NULL,   test = \"Ansari\",   parent = function(n, ...) rnorm(n),   ...,   return_analysis = FALSE )"},{"path":"https://philchalmers.github.io/Spower/reference/p_scale.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"p-value from Scale Test simulation — p_scale","text":"n sample size per group scale scale multiply second group (1 reflects equal scaling) n2_n1 sample size ratio two.tailed logical; use two-tailed test? exact logical indicating whether exact p-value computed test type method use. Can either 'Ansari' 'Mood' parent data generation function (default assumes Gaussian shape). Must population mean centered ... additional arguments pass simulation functions (used) return_analysis logical; return analysis object extraction customization?","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_scale.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"p-value from Scale Test simulation — p_scale","text":"single p-value","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_scale.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"p-value from Scale Test simulation — p_scale","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_scale.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"p-value from Scale Test simulation — p_scale","text":"","code":"# n=30 per group, #  Distributions Gaussian with sd=1 for first group and sd=2 for second p_scale(30, scale=2) #> [1] 0.01514069 p_scale(30, scale=2, test='Mood') #> [1] 0.01283308  # compare chi-squared distributions parent <- function(n, df, ...) rchisq(n, df=df) - df p_scale(30, scale=2, parent=parent, df=3) #> [1] 2.315821e-06  # \\donttest{   # empirical power of the experiments   p_scale(30, scale=2) |> Spower() #>  #> Execution time (H:M:S): 00:00:22 #> Design conditions:  #>  #> # A tibble: 1 × 4 #>       n scale sig.level power #>   <dbl> <dbl>     <dbl> <lgl> #> 1    30     2      0.05 NA    #>  #> Estimate of power: 0.775 #> 95% Confidence Interval: [0.767, 0.783]   p_scale(30, scale=2, test='Mood') |> Spower() #>  #> Execution time (H:M:S): 00:00:02 #> Design conditions:  #>  #> # A tibble: 1 × 5 #>       n scale test  sig.level power #>   <dbl> <dbl> <chr>     <dbl> <lgl> #> 1    30     2 Mood       0.05 NA    #>  #> Estimate of power: 0.857 #> 95% Confidence Interval: [0.850, 0.864]    p_scale(30, scale=2, parent=parent, df=3) |> Spower() #>  #> Execution time (H:M:S): 00:00:22 #> Design conditions:  #>  #> # A tibble: 1 × 5 #>       n scale    df sig.level power #>   <dbl> <dbl> <dbl>     <dbl> <lgl> #> 1    30     2     3      0.05 NA    #>  #> Estimate of power: 0.900 #> 95% Confidence Interval: [0.894, 0.906]   p_scale(30, scale=2, test='Mood', parent=parent, df=3) |> Spower() #>  #> Execution time (H:M:S): 00:00:02 #> Design conditions:  #>  #> # A tibble: 1 × 6 #>       n scale test     df sig.level power #>   <dbl> <dbl> <chr> <dbl>     <dbl> <lgl> #> 1    30     2 Mood      3      0.05 NA    #>  #> Estimate of power: 0.947 #> 95% Confidence Interval: [0.942, 0.951]  # }"},{"path":"https://philchalmers.github.io/Spower/reference/p_shapiro.test.html","id":null,"dir":"Reference","previous_headings":"","what":"p-value from Shapiro-Wilk Normality Test simulation — p_shapiro.test","title":"p-value from Shapiro-Wilk Normality Test simulation — p_shapiro.test","text":"Generates univariate distributional data returns p-value assess null population follows Gaussian distribution shape. Uses shapiro.test.","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_shapiro.test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"p-value from Shapiro-Wilk Normality Test simulation — p_shapiro.test","text":"","code":"p_shapiro.test(dist, return_analysis = FALSE)"},{"path":"https://philchalmers.github.io/Spower/reference/p_shapiro.test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"p-value from Shapiro-Wilk Normality Test simulation — p_shapiro.test","text":"dist expression used generate required sample data return_analysis logical; return analysis object extraction customization?","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_shapiro.test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"p-value from Shapiro-Wilk Normality Test simulation — p_shapiro.test","text":"single p-value","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_shapiro.test.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"p-value from Shapiro-Wilk Normality Test simulation — p_shapiro.test","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_shapiro.test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"p-value from Shapiro-Wilk Normality Test simulation — p_shapiro.test","text":"","code":"# 50 observations drawn from normal distribution (null is true) p_shapiro.test(rnorm(50)) #> [1] 0.6486032  # return analysis object p_shapiro.test(rnorm(50), TRUE) #>  #> \tShapiro-Wilk normality test #>  #> data:  dist #> W = 0.97102, p-value = 0.2546 #>   # 50 observations from slightly skewed chi-squared distribution (power) p_shapiro.test(rchisq(50, df=100)) #> [1] 0.03912372  # \\donttest{     # empirical Type I error rate estimate     p_shapiro.test(rnorm(50)) |> Spower() #>  #> Execution time (H:M:S): 00:00:02 #> Design conditions:  #>  #> # A tibble: 1 × 2 #>   sig.level power #>       <dbl> <lgl> #> 1      0.05 NA    #>  #> Estimate of power: 0.047 #> 95% Confidence Interval: [0.043, 0.051]      # power     p_shapiro.test(rchisq(50, df=100)) |> Spower() #>  #> Execution time (H:M:S): 00:00:02 #> Design conditions:  #>  #> # A tibble: 1 × 2 #>   sig.level power #>       <dbl> <lgl> #> 1      0.05 NA    #>  #> Estimate of power: 0.097 #> 95% Confidence Interval: [0.092, 0.103] # }"},{"path":"https://philchalmers.github.io/Spower/reference/p_slr.html","id":null,"dir":"Reference","previous_headings":"","what":"p-value from simple linear regression model simulation — p_slr","title":"p-value from simple linear regression model simulation — p_slr","text":"p-values associated simple linear regression model, \\(y = \\beta_0 + \\beta_1 X + \\epsilon\\). Focus slope/intercept behavior model.","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_slr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"p-value from simple linear regression model simulation — p_slr","text":"","code":"p_slr(   n,   beta,   sd_x,   sd_y,   beta0 = 0,   test = \"x = 0\",   gen_fun = gen_slr,   return_analysis = FALSE,   ... )  gen_slr(n, beta, sd_x, sd_y, ...)"},{"path":"https://philchalmers.github.io/Spower/reference/p_slr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"p-value from simple linear regression model simulation — p_slr","text":"n sample size beta slope parameter sd_x standard deviation IV sd_y standard deviation DV beta0 null value test test test evaluate using lht. Default evaluates null hypothesis slope equal 0 gen_fun function used generate required X-Y data. Object returned must data.frame columns 'y' 'x'. Default uses gen_slr. User defined version function must include argument ... return_analysis logical; return analysis object extraction customization? ... additional arguments passed gen_fun. used unless customized gen_fun defined","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_slr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"p-value from simple linear regression model simulation — p_slr","text":"single p-value","code":""},{"path":[]},{"path":"https://philchalmers.github.io/Spower/reference/p_slr.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"p-value from simple linear regression model simulation — p_slr","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_slr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"p-value from simple linear regression model simulation — p_slr","text":"","code":"p_slr(n=100, beta = -0.0667, sd_x = 7.5, sd_y = 4) #> [1] 0.5339516  if (FALSE) { # \\dontrun{ p_slr(n=100, beta = -0.0667, sd_x = 7.5, sd_y = 4) |> Spower() } # }"},{"path":"https://philchalmers.github.io/Spower/reference/p_t.test.html","id":null,"dir":"Reference","previous_headings":"","what":"p-value from independent/paired samples t-test simulation — p_t.test","title":"p-value from independent/paired samples t-test simulation — p_t.test","text":"Generates one two sets continuous data group-level data according Cohen's effect size 'd', returns p-value. data associated t-test assume conditional observations normally distributed equal variance default, however may modified.","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_t.test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"p-value from independent/paired samples t-test simulation — p_t.test","text":"","code":"p_t.test(   n,   d,   mu = 0,   r = NULL,   type = \"two.sample\",   n2_n1 = 1,   two.tailed = TRUE,   var.equal = TRUE,   means = NULL,   sds = NULL,   conf.level = 0.95,   gen_fun = gen_t.test,   return_analysis = FALSE,   ... )  gen_t.test(   n,   d,   n2_n1 = 1,   r = NULL,   type = \"two.sample\",   means = NULL,   sds = NULL,   ... )"},{"path":"https://philchalmers.github.io/Spower/reference/p_t.test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"p-value from independent/paired samples t-test simulation — p_t.test","text":"n sample size per group, assumed equal across groups. paired samples corresponds number pairs (hence, half number data points observed) d Cohen's standardized effect size d. generated data standardized mean appears first group (two-sample)/first time point (paired samples) mu population mean test r (optional) instead specifying d specify point-biserial correlation. Internally transformed suitable d value power computations type type t-test use; can 'two.sample', 'one.sample', 'paired' n2_n1 allocation ratio reflecting size ratio. Default 1 sets groups size. applicable type = 'two.sample' two.tailed logical; two-tailed one-tailed test used? var.equal logical; use classical Welch corrected t-test? means (optional) vector means group. specified input d ignored sds (optional) vector SDs group. specified d used set vector 1's conf.level confidence interval level passed t.test gen_fun function used generate required two-sample data. Object returned must list containing one (one-sample) two (independent samples/paired samples) elements, numeric vectors. Default uses gen_t.test generate conditionally Gaussian distributed samples. User defined version function must include argument ... return_analysis logical; return analysis object extraction customization? ... additional arguments passed gen_fun. used unless customized gen_fun defined","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_t.test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"p-value from independent/paired samples t-test simulation — p_t.test","text":"single p-value","code":""},{"path":[]},{"path":"https://philchalmers.github.io/Spower/reference/p_t.test.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"p-value from independent/paired samples t-test simulation — p_t.test","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_t.test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"p-value from independent/paired samples t-test simulation — p_t.test","text":"","code":"# sample size of 50 per group, \"medium\" effect size p_t.test(n=50, d=0.5) #> [1] 0.005589963  # point-biserial correlation effect size p_t.test(n=50, r=.3) #> [1] 0.004396717  # second group 2x as large as the first group p_t.test(n=50, d=0.5, n2_n1 = 2) #> [1] 0.03033605  # specify mean/SDs explicitly p_t.test(n=50, means = c(0,1), sds = c(2,2)) #> [1] 0.009252317  # paired and one-sample tests p_t.test(n=50, d=0.5, type = 'paired') # n = number of pairs #> [1] 0.06232847 p_t.test(n=50, d=0.5, type = 'one.sample') #> [1] 0.0007065882  # return analysis object p_t.test(n=50, d=0.5, return_analysis=TRUE) #>  #> \tTwo Sample t-test #>  #> data:  dat[[1]] and dat[[2]] #> t = 2.0981, df = 98, p-value = 0.03846 #> alternative hypothesis: true difference in means is not equal to 0 #> 95 percent confidence interval: #>  0.02490457 0.89441223 #> sample estimates: #>  mean of x  mean of y  #> 0.54009219 0.08043378  #>   # \\donttest{   # compare simulated results to pwr package    pwr::pwr.t.test(d=0.2, n=60, sig.level=0.10,              type=\"one.sample\", alternative=\"two.sided\") #>  #>      One-sample t test power calculation  #>  #>               n = 60 #>               d = 0.2 #>       sig.level = 0.1 #>           power = 0.4555818 #>     alternative = two.sided #>    p_t.test(n=60, d=0.2, type = 'one.sample', two.tailed=TRUE) |>          Spower(sig.level=.10) #>  #> Execution time (H:M:S): 00:00:02 #> Design conditions:  #>  #> # A tibble: 1 × 6 #>       n     d type       two.tailed sig.level power #>   <dbl> <dbl> <chr>      <lgl>          <dbl> <lgl> #> 1    60   0.2 one.sample TRUE             0.1 NA    #>  #> Estimate of power: 0.451 #> 95% Confidence Interval: [0.441, 0.460]    pwr::pwr.t.test(d=0.3, power=0.80, type=\"two.sample\",                   alternative=\"greater\") #>  #>      Two-sample t test power calculation  #>  #>               n = 138.0716 #>               d = 0.3 #>       sig.level = 0.05 #>           power = 0.8 #>     alternative = greater #>  #> NOTE: n is number in *each* group #>    p_t.test(n=NA, d=0.3, type='two.sample', two.tailed=FALSE) |>          Spower(power=0.80, interval=c(10,200)) #>  #> Execution time (H:M:S): 00:00:20 #> Design conditions:  #>  #> # A tibble: 1 × 6 #>       n     d type       two.tailed sig.level power #>   <dbl> <dbl> <chr>      <lgl>          <dbl> <dbl> #> 1    NA   0.3 two.sample FALSE           0.05   0.8 #>  #> Estimate of n: 136.9 #> 95% Predicted Confidence Interval: [135.2, 138.7]  # }   ###### Custom data generation function  # Generate data such that: #   - group 1 is from a negatively distribution (reversed X2(10)), #   - group 2 is from a positively skewed distribution (X2(5)) #   - groups have equal variance, but differ by d = 0.5  args(gen_t.test)   ## can use these arguments as a basis, though must include ... #> function (n, d, n2_n1 = 1, r = NULL, type = \"two.sample\", means = NULL,  #>     sds = NULL, ...)  #> NULL  # arguments df1 and df2 added; unused arguments caught within ... my.gen_fun <- function(n, d, df1, df2, ...){     group1 <- -1 * rchisq(n, df=df1)        group2 <- rchisq(n, df=df2)        # scale groups first given moments of the chi-square distribution,        #   then add std mean difference        group1 <- ((group1 + df1) / sqrt(2*df1))        group2 <- ((group2 - df2) / sqrt(2*df2)) + d        dat <- list(group1, group2)        dat }  # check the sample data properties dat <- my.gen_fun(n=10000, d=.5, df1=10, df2=5) sapply(dat, mean) #> [1] -0.00159157  0.49555302 sapply(dat, sd) #> [1] 0.9914658 0.9927854  p_t.test(n=100, d=0.5, gen_fun=my.gen_fun, df1=10, df2=5) #> [1] 0.004709083  # \\donttest{    # power given Gaussian distributions   p_t.test(n=100, d=0.5) |> Spower(replications=30000) #>  #> Execution time (H:M:S): 00:00:08 #> Design conditions:  #>  #> # A tibble: 1 × 4 #>       n     d sig.level power #>   <dbl> <dbl>     <dbl> <lgl> #> 1   100   0.5      0.05 NA    #>  #> Estimate of power: 0.942 #> 95% Confidence Interval: [0.939, 0.944]    # estimate power given the customized data generating function   p_t.test(n=100, d=0.5, gen_fun=my.gen_fun, df1=10, df2=5) |>     Spower(replications=30000) #>  #> Execution time (H:M:S): 00:00:09 #> Design conditions:  #>  #> # A tibble: 1 × 6 #>       n     d   df1   df2 sig.level power #>   <dbl> <dbl> <dbl> <dbl>     <dbl> <lgl> #> 1   100   0.5    10     5      0.05 NA    #>  #> Estimate of power: 0.959 #> 95% Confidence Interval: [0.957, 0.961]    # evaluate Type I error rate to see if liberal/conservative given   # assumption violations (should be close to alpha/sig.level)   p_t.test(n=100, d=0, gen_fun=my.gen_fun, df1=10, df2=5) |>     Spower(replications=30000) #>  #> Execution time (H:M:S): 00:00:09 #> Design conditions:  #>  #> # A tibble: 1 × 6 #>       n     d   df1   df2 sig.level power #>   <dbl> <dbl> <dbl> <dbl>     <dbl> <lgl> #> 1   100     0    10     5      0.05 NA    #>  #> Estimate of power: 0.051 #> 95% Confidence Interval: [0.049, 0.054]  # }"},{"path":"https://philchalmers.github.io/Spower/reference/p_var.test.html","id":null,"dir":"Reference","previous_headings":"","what":"p-value from variance test simulation — p_var.test","title":"p-value from variance test simulation — p_var.test","text":"Generates one sets continuous data group-level data perform variance test, return p-value. two-samples investigated var.test function used, otherwise functions EnvStats package used.","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_var.test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"p-value from variance test simulation — p_var.test","text":"","code":"p_var.test(   n,   vars,   n.ratios = rep(1, length(vars)),   sigma2 = 1,   two.tailed = TRUE,   test = \"Levene\",   correct = TRUE,   gen_fun = gen_var.test,   return_analysis = FALSE,   ... )  gen_var.test(n, vars, n.ratios = rep(1, length(vars)), ...)"},{"path":"https://philchalmers.github.io/Spower/reference/p_var.test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"p-value from variance test simulation — p_var.test","text":"n sample size per group, assumed equal across groups vars vector variances use group; length 1 one-sample tests n.ratios allocation ratios reflecting sample size ratios. Default 1 sets groups size (n * n.ratio) sigma2 population variance test one-sample test two.tailed logical; two-tailed one-tailed test used? test type test use multi-sample applications. Can either 'Levene' (default), 'Bartlett', 'Fligner' correct logical; use correction test = 'Bartlett'? gen_fun function used generate required discrete data. Object returned must matrix k rows k columns counts. Default uses gen_var.test. User defined version function must include argument ... return_analysis logical; return analysis object extraction customization? ... additional arguments passed gen_fun. used unless customized gen_fun defined","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_var.test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"p-value from variance test simulation — p_var.test","text":"single p-value","code":""},{"path":[]},{"path":"https://philchalmers.github.io/Spower/reference/p_var.test.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"p-value from variance test simulation — p_var.test","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_var.test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"p-value from variance test simulation — p_var.test","text":"","code":"# one sample p_var.test(100, vars=10, sigma2=9) #> [1] 0.4967746  # return analysis object p_var.test(100, vars=10, sigma2=9, return_analysis = TRUE) #> $statistic #> Chi-Squared  #>     96.5513  #>  #> $parameters #> df  #> 99  #>  #> $p.value #> [1] 0.8981661 #>  #> $estimate #> variance  #> 8.777391  #>  #> $null.value #> variance  #>        9  #>  #> $alternative #> [1] \"two.sided\" #>  #> $method #> [1] \"Chi-Squared Test on Variance\" #>  #> $data.name #> [1] \"dat$DV\" #>  #> $conf.int #>       LCL       UCL  #>  6.766456 11.844996  #> attr(,\"conf.level\") #> [1] 0.95 #>  #> attr(,\"class\") #> [1] \"htestEnvStats\"  # three sample p_var.test(100, vars=c(10, 9, 11)) #> [1] 0.2669294 p_var.test(100, vars=c(10, 9, 11), test = 'Fligner') #> [1] 0.2789629 p_var.test(100, vars=c(10, 9, 11), test = 'Bartlett') #> [1] 0.02818948  # \\donttest{   # power to detect three-group variance differences   p_var.test(n=100, vars=c(10,9,11)) |> Spower() #>  #> Execution time (H:M:S): 00:00:31 #> Design conditions:  #>  #> # A tibble: 1 × 3 #>       n sig.level power #>   <dbl>     <dbl> <lgl> #> 1   100      0.05 NA    #>  #> Estimate of power: 0.120 #> 95% Confidence Interval: [0.114, 0.127]    # sample size per group to achieve 80% power   p_var.test(n=NA, vars=c(10,9,11)) |>          Spower(power=.80, interval=c(100, 1000)) #>  #> Execution time (H:M:S): 00:04:35 #> Design conditions:  #>  #> # A tibble: 1 × 3 #>       n sig.level power #>   <dbl>     <dbl> <dbl> #> 1    NA      0.05   0.8 #>  #> Estimate of n: 999.0 #> 95% Predicted Confidence Interval: [NA, NA] # }"},{"path":"https://philchalmers.github.io/Spower/reference/p_wilcox.test.html","id":null,"dir":"Reference","previous_headings":"","what":"p-value from Wilcoxon (signed rank) test simulation — p_wilcox.test","title":"p-value from Wilcoxon (signed rank) test simulation — p_wilcox.test","text":"Simulates data given one (Wilcoxon) two (Mann-Whitney) parent distributions returns p-value. Can also used power analyses related sign tests.","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_wilcox.test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"p-value from Wilcoxon (signed rank) test simulation — p_wilcox.test","text":"","code":"p_wilcox.test(   n,   d,   n2_n1 = 1,   mu = 0,   type = c(\"two.sample\", \"one.sample\", \"paired\"),   exact = NULL,   correct = TRUE,   two.tailed = TRUE,   parent1 = function(n, d) rnorm(n, d, 1),   parent2 = function(n, d) rnorm(n, 0, 1),   return_analysis = FALSE )"},{"path":"https://philchalmers.github.io/Spower/reference/p_wilcox.test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"p-value from Wilcoxon (signed rank) test simulation — p_wilcox.test","text":"n sample size per group. paired samples corresponds number pairings (hence, half data points observed) d effect size passed parent functions n2_n1 sample size ratio mu parameter used form null hypothesis type type analysis use (two-sample, one-sample, paired) exact logical indicating whether exact p-value computed correct logical indicating whether apply continuity correction normal approximation p-value two.tailed logical; use two-tailed test? parent1 data generation function first group. Ideally SDs = 1 d reflects standardized difference parent2 parent1, second group return_analysis logical; return analysis object extraction customization?","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_wilcox.test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"p-value from Wilcoxon (signed rank) test simulation — p_wilcox.test","text":"single p-value","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_wilcox.test.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"p-value from Wilcoxon (signed rank) test simulation — p_wilcox.test","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/Spower/reference/p_wilcox.test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"p-value from Wilcoxon (signed rank) test simulation — p_wilcox.test","text":"","code":"# with normal distributions defaults d is standardized p_wilcox.test(100, .5) #> [1] 0.05843708 p_wilcox.test(100, .5, type = 'paired')  # n = number of pairs #> [1] 0.003608025 p_wilcox.test(100, .5, type = 'one.sample') #> [1] 6.937087e-06  # return analysis object p_wilcox.test(100, .5, return_analysis = TRUE) #>  #> \tWilcoxon rank sum test with continuity correction #>  #> data:  dat1 and dat2 #> W = 6026, p-value = 0.01222 #> alternative hypothesis: true location shift is not equal to 0 #>   # using chi-squared distributions (standardizing to 0-1) p_wilcox.test(100, .5, type = 'one.sample',    parent1 = function(n, d) rchisq(n, df=10) - 10 + d) #> [1] 0.06972141 p_wilcox.test(100, .5,    parent1 = function(n, d) (rchisq(n, df=10) - 10)/sqrt(20) + d,    parent2 = function(n, d) (rchisq(n, df=10) - 10)/sqrt(20)) #> [1] 0.008169853"},{"path":"https://philchalmers.github.io/Spower/reference/update.html","id":null,"dir":"Reference","previous_headings":"","what":"Update compromise or prospective/post-hoc power analysis without re-simulating — update.Spower","title":"Update compromise or prospective/post-hoc power analysis without re-simulating — update.Spower","text":"power compromise analysis performed Spower function can used update compromise power criteria without need re-simulating experiment. compromise analyses beta_alpha criteria must supplied, prospective/post-hoc power analyses sig.level must supplied.","code":""},{"path":"https://philchalmers.github.io/Spower/reference/update.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update compromise or prospective/post-hoc power analysis without re-simulating — update.Spower","text":"","code":"# S3 method for class 'Spower' update(object, sig.level = 0.05, beta_alpha = NULL, predCI = 0.95, ...)"},{"path":"https://philchalmers.github.io/Spower/reference/update.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update compromise or prospective/post-hoc power analysis without re-simulating — update.Spower","text":"object object returned Spower power estimated bete_alpha criteria supplied sig.level Type error rate (alpha) beta_alpha Type II/Type error ratio predCI confidence interval precision (see Spower similar input) ... arguments passed","code":""},{"path":"https://philchalmers.github.io/Spower/reference/update.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Update compromise or prospective/post-hoc power analysis without re-simulating — update.Spower","text":"object class Spower updated information","code":""},{"path":"https://philchalmers.github.io/Spower/reference/update.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Update compromise or prospective/post-hoc power analysis without re-simulating — update.Spower","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/Spower/reference/update.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Update compromise or prospective/post-hoc power analysis without re-simulating — update.Spower","text":"","code":"# \\donttest{  ######## ## Prospective power analysis update  # Estimate power using sig.level = .05 (default) out <- p_t.test(n = 50, d = .5) |> Spower()  # update power estimate given sig.level=.01 and .20 update(out, sig.level=.01) #>  #> Execution time (H:M:S): 00:00:02 #> Design conditions:  #>  #> # A tibble: 1 × 4 #>       n     d sig.level power #>   <dbl> <dbl>     <dbl> <lgl> #> 1    50   0.5      0.01 NA    #>  #> Estimate of power: 0.460 #> 95% Confidence Interval: [0.447, 0.468] update(out, sig.level=.20) #>  #> Execution time (H:M:S): 00:00:02 #> Design conditions:  #>  #> # A tibble: 1 × 4 #>       n     d sig.level power #>   <dbl> <dbl>     <dbl> <lgl> #> 1    50   0.5       0.2 NA    #>  #> Estimate of power: 0.892 #> 95% Confidence Interval: [0.888, 1.000]   ######## ## Compromise analysis update  # Solve beta/alpha ratio to specific error trade-off constant out <- p_t.test(n = 50, d = .5) |> Spower(beta_alpha = 2)  # update beta_alpha criteria without re-simulating update(out, beta_alpha=4) #>  #> Execution time (H:M:S): 00:00:02 #> Design conditions:  #>  #> # A tibble: 1 × 5 #>       n     d sig.level power beta_alpha #>   <dbl> <dbl>     <dbl> <lgl>      <dbl> #> 1    50   0.5        NA NA             4 #>  #> Estimate of Type I error rate (alpha/sig.level): 0.065 #> 95% Confidence Interval: [0.060, 0.070] #>  #> Estimate of power (1-beta): 0.739 #> 95% Confidence Interval: [0.730, 0.748]  # also works if compromise not initially run but prospective/post-hoc power was out <- p_t.test(n = 50, d = .5) |> Spower() update(out, beta_alpha=4) #>  #> Execution time (H:M:S): 00:00:02 #> Design conditions:  #>  #> # A tibble: 1 × 5 #>       n     d sig.level power beta_alpha #>   <dbl> <dbl>     <dbl> <lgl>      <dbl> #> 1    50   0.5        NA NA             4 #>  #> Estimate of Type I error rate (alpha/sig.level): 0.066 #> 95% Confidence Interval: [0.061, 0.071] #>  #> Estimate of power (1-beta): 0.737 #> 95% Confidence Interval: [0.729, 0.746]  # }"}]
